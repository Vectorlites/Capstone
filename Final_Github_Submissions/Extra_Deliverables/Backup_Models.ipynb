{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kavithaki/Downloads/Capstone/news.csv', delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>2020-03-27 08:00:00</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>https://www.cbc.ca/news/health/covid-19-drug-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>2020-03-27 01:45:00</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/north/yukon-cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Associated Press']</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>2020-03-26 05:13:00</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>https://www.cbc.ca/news/world/senate-coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>2020-03-27 00:36:00</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>https://www.cbc.ca/news/health/coronavirus-tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>2020-03-26 20:57:00</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>https://www.cbc.ca/news/the-latest-on-the-coro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   authors  \\\n",
       "0           0              ['Cbc News']   \n",
       "1           1              ['Cbc News']   \n",
       "2           2  ['The Associated Press']   \n",
       "3           3              ['Cbc News']   \n",
       "4           4              ['Cbc News']   \n",
       "\n",
       "                                               title         publish_date  \\\n",
       "0  Coronavirus a 'wake-up call' for Canada's pres...  2020-03-27 08:00:00   \n",
       "1  Yukon gov't names 2 possible sources of corona...  2020-03-27 01:45:00   \n",
       "2  U.S. Senate passes $2T coronavirus relief package  2020-03-26 05:13:00   \n",
       "3  Coronavirus: The latest in drug treatment and ...  2020-03-27 00:36:00   \n",
       "4  The latest on the coronavirus outbreak for Mar...  2020-03-26 20:57:00   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.cbc.ca/news/health/covid-19-drug-s...  \n",
       "1  https://www.cbc.ca/news/canada/north/yukon-cor...  \n",
       "2  https://www.cbc.ca/news/world/senate-coronavir...  \n",
       "3  https://www.cbc.ca/news/health/coronavirus-tre...  \n",
       "4  https://www.cbc.ca/news/the-latest-on-the-coro...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3566.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2455.649748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1298.529450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1473.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2496.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3569.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4608.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  3566.000000\n",
       "mean   2455.649748\n",
       "std    1298.529450\n",
       "min       0.000000\n",
       "25%    1473.250000\n",
       "50%    2496.500000\n",
       "75%    3569.750000\n",
       "max    4608.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 0\",'publish_date','url'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['The Associated Press']</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    authors  \\\n",
       "0              ['Cbc News']   \n",
       "1              ['Cbc News']   \n",
       "2  ['The Associated Press']   \n",
       "3              ['Cbc News']   \n",
       "4              ['Cbc News']   \n",
       "\n",
       "                                               title  \\\n",
       "0  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1  Yukon gov't names 2 possible sources of corona...   \n",
       "2  U.S. Senate passes $2T coronavirus relief package   \n",
       "3  Coronavirus: The latest in drug treatment and ...   \n",
       "4  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['authors'] = df['authors'].str.strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Cbc News'</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Cbc News'</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'The Associated Press'</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Cbc News'</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Cbc News'</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  authors                                              title  \\\n",
       "0              'Cbc News'  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              'Cbc News'  Yukon gov't names 2 possible sources of corona...   \n",
       "2  'The Associated Press'  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              'Cbc News'  Coronavirus: The latest in drug treatment and ...   \n",
       "4              'Cbc News'  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['authors'] = df['authors'].str.strip('  ''')\n",
    "df['authors'] = df.authors.str.replace(\"[({':]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              Cbc News  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              Cbc News  Yukon gov't names 2 possible sources of corona...   \n",
       "2  The Associated Press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              Cbc News  Coronavirus: The latest in drug treatment and ...   \n",
       "4              Cbc News  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['authors'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data has 3566 rows and 4 columns\n"
     ]
    }
   ],
   "source": [
    "# What is the shape of the dataset?\n",
    "\n",
    "print(\"Input data has {} rows and {} columns\".format(len(df), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3566 rows, 1168 are CBC News, 178 are Associated Press\n"
     ]
    }
   ],
   "source": [
    "# How many News Authors are there? Considering Authors as Label.\n",
    "\n",
    "print(\"Out of {} rows, {} are CBC News, {} are Associated Press\".format(len(df),\n",
    "                                                       len(df[df['authors']=='Cbc News']),\n",
    "                                                       len(df[df['authors']=='The Associated Press'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null in label: 0\n",
      "Number of null in text: 0\n"
     ]
    }
   ],
   "source": [
    "# How much missing data is there?\n",
    "\n",
    "print(\"Number of null in label: {}\".format(df['authors'].isnull().sum()))\n",
    "print(\"Number of null in text: {}\".format(df['text'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Basics: Implementing a pipeline to clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing text data\n",
    "\n",
    "Cleaning up the text data is necessary to highlight attributes. These would be loaded to machine learning system to pick up on. Cleaning (or pre-processing) the data typically consists of a number of steps:\n",
    "1. **Remove punctuation**\n",
    "2. **Tokenization**\n",
    "3. **Remove stopwords**\n",
    "4. **Lemmatize/Stem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              Cbc News  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              Cbc News  Yukon gov't names 2 possible sources of corona...   \n",
       "2  The Associated Press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              Cbc News  Coronavirus: The latest in drug treatment and ...   \n",
       "4              Cbc News  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_clean'] = df['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              Cbc News  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              Cbc News  Yukon gov't names 2 possible sources of corona...   \n",
       "2  The Associated Press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              Cbc News  Coronavirus: The latest in drug treatment and ...   \n",
       "4              Cbc News  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_tokenized'] = df['body_text_clean'].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              Cbc News  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              Cbc News  Yukon gov't names 2 possible sources of corona...   \n",
       "2  The Associated Press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              Cbc News  Coronavirus: The latest in drug treatment and ...   \n",
       "4              Cbc News  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \n",
       "0  [canadian, pharmacies, are, limiting, how, muc...  \n",
       "1  [the, yukon, government, has, identified, two,...  \n",
       "2  [the, senate, late, wednesday, passed, an, unp...  \n",
       "3  [scientists, around, the, world, are, racing, ...  \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "#stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_nostop'] = df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "      <td>[scientists, around, world, racing, find, nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "      <td>[, trudeau, says, rules, quarantine, act, enfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              Cbc News  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              Cbc News  Yukon gov't names 2 possible sources of corona...   \n",
       "2  The Associated Press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              Cbc News  Coronavirus: The latest in drug treatment and ...   \n",
       "4              Cbc News  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "3  [scientists, around, the, world, are, racing, ...   \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...   \n",
       "\n",
       "                                    body_text_nostop  \n",
       "0  [canadian, pharmacies, limiting, much, medicat...  \n",
       "1  [yukon, government, identified, two, places, w...  \n",
       "2  [senate, late, wednesday, passed, unparalleled...  \n",
       "3  [scientists, around, world, racing, find, nove...  \n",
       "4  [, trudeau, says, rules, quarantine, act, enfo...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental Data Cleaning: Using Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "ps = nltk.PorterStemmer()   # Test out Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grow\n",
      "grow\n",
      "grow\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('grows'))\n",
    "print(ps.stem('growing'))\n",
    "print(ps.stem('grow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "runner\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('run'))\n",
    "print(ps.stem('running'))\n",
    "print(ps.stem('runner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_stemmed'] = df['body_text_nostop'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['authors']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplemental Data Cleaning: Using a Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()\n",
    "import nltk\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()   # https://wordnet.princeton.edu/\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "mean\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('meanness'))\n",
    "print(ps.stem('meaning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanness\n",
      "meaning\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('meanness'))\n",
    "print(wn.lemmatize('meaning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_lemmatized'] = df['body_text_nostop'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying punctuation, Tokenization, Remove stopwords, Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doubt:\n",
    "\n",
    "3 types of vectorization or 4 Types ?\n",
    "\n",
    "1. count Vectorization\n",
    "2. N-gram Vectorization\n",
    "3. TF-IDF \n",
    "4. Bag-Of-words Model\n",
    "\n",
    "Bag-of-words model:\n",
    "1.\tCount how many times does a word occur in each message (Known as term frequency) (TF)\n",
    "2.\tWeigh the counts, so that frequent tokens get lower weight (inverse document frequency)- (IDF)\n",
    "3.\tNormalize the vectors to unit length, to abstract from the original text length (L2 norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorization \n",
    "\n",
    "Creates a document-term matrix where the entry of each cell will be a count of the number of times that word occurred in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3566, 31399)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=clean_text)  # call the function clean_text. \n",
    "X_counts = count_vect.fit_transform(df['text'])\n",
    "\n",
    "# X_counts is the vectorized version of the data.\n",
    "\n",
    "print(X_counts.shape)\n",
    "#print(count_vect.get_feature_names())  # get_feature_names() prints all the unique words that are found in all of the text messages.\n",
    "\n",
    "# (3566, 31399) : 3566 text messages, across this 3566 text messages there are 31399 unique words.\n",
    "# It means the document term matrix consists of 3566 rows and 31399 columns.\n",
    "\n",
    "# Each row : Text message and the column will have unique words of this text message.\n",
    "\n",
    "# get_feature_names() : means the numbers are names of the columns. We can remove the numbers and change it to names.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2951)\n",
      "CountVectorizer(analyzer=<function clean_text at 0x1a229fe268>, binary=False,\n",
      "                decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "                encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "                max_features=None, min_df=1, ngram_range=(1, 1),\n",
      "                preprocessor=None, stop_words=None, strip_accents=None,\n",
      "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
      "                vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# Apply CountVectorizer to smaller sample\n",
    "\n",
    "data_sample = df[0:20]\n",
    "\n",
    "count_vect_sample = CountVectorizer(analyzer=clean_text)\n",
    "X_counts_sample = count_vect_sample.fit_transform(data_sample['text'])\n",
    "print(X_counts_sample.shape)\n",
    "#print(count_vect_sample.get_feature_names())\n",
    "\n",
    "# (20, 2951) : 20 rows and 2951 columns.\n",
    "# There are new feature names. \n",
    "# \n",
    "# \n",
    "print(count_vect_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The raw data output of the count vector is called as the Sparse Vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x2951 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7096 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizers output sparse matrices\n",
    "#Sparse Matrix: A matrix in which most entries are 0. In the interest of efficient storage, \n",
    "#    a sparse matrix will be stored by only storing the locations of the non-zero elements.\n",
    "\n",
    "X_counts_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2941</th>\n",
       "      <th>2942</th>\n",
       "      <th>2943</th>\n",
       "      <th>2944</th>\n",
       "      <th>2945</th>\n",
       "      <th>2946</th>\n",
       "      <th>2947</th>\n",
       "      <th>2948</th>\n",
       "      <th>2949</th>\n",
       "      <th>2950</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã 2951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6     7     8     9     ...  2941  \\\n",
       "0      1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4      1     1     0     0     0     0     0     0     0     0  ...     1   \n",
       "5      0     0     1     0     0     0     0     0     0     0  ...     0   \n",
       "6      1     0     0     0     1     1     1     0     1     1  ...     1   \n",
       "7      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "8      0     0     0     0     0     0     0     0     0     2  ...     0   \n",
       "9      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "10     1     0     0     0     0     0     0     0     3     0  ...     0   \n",
       "11     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "12     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "13     0     0     0     1     0     0     0     0     0     0  ...     1   \n",
       "14     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "15     0     0     0     0     0     0     0     0     0     0  ...     1   \n",
       "16     0     0     0     0     0     0     0     0     1     0  ...     0   \n",
       "17     0     0     0     0     0     0     0     0     8     0  ...    12   \n",
       "18     0     0     0     0     1     0     0     1     0     1  ...     0   \n",
       "19     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "    2942  2943  2944  2945  2946  2947  2948  2949  2950  \n",
       "0      0     0     0     0     0     0     0     0     0  \n",
       "1      0     0     4     0     0     0     0     0     1  \n",
       "2      0     0     0     0     0     0     0     0     0  \n",
       "3      0     0     0     0     2     0     0     0     0  \n",
       "4      2     0     0     0     0     0     0     0     0  \n",
       "5      0     0     0     0     0     0     0     0     0  \n",
       "6      0     0     0     0     0     1     0     1     0  \n",
       "7      0     0     0     0     0     0     0     0     0  \n",
       "8      0     0     0     0     0     0     0     0     0  \n",
       "9      0     0     0     0     0     0     0     0     0  \n",
       "10     0     0     0     0     0     0     0     0     0  \n",
       "11     0     0     0     0     0     0     0     0     0  \n",
       "12     0     0     0     0     0     0     0     0     0  \n",
       "13     0     0     0     1     0     0     0     0     0  \n",
       "14     0     0     0     0     0     0     0     0     0  \n",
       "15     0     0     0     0     0     0     0     0     1  \n",
       "16     0     0     0     0     0     0     0     0     0  \n",
       "17     1     0     0     0     0     0     0     0     0  \n",
       "18     0     1     0     0     0     0     2     0     0  \n",
       "19     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[20 rows x 2951 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts_df = pd.DataFrame(X_counts_sample.toarray())\n",
    "X_counts_df\n",
    "\n",
    "# This is the document term Matrix. It has 2951 columns and 20 rows. \n",
    "# Values are numbered from 0 to 191 in the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>025</th>\n",
       "      <th>026</th>\n",
       "      <th>042</th>\n",
       "      <th>049</th>\n",
       "      <th>057</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>youv</th>\n",
       "      <th>yuje</th>\n",
       "      <th>yukon</th>\n",
       "      <th>z</th>\n",
       "      <th>zarychanski</th>\n",
       "      <th>zibi</th>\n",
       "      <th>ziomek</th>\n",
       "      <th>zmiyiwski</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã 2951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       000  025  026  042  049  057  1  10  100  ...  your  youv  yuje  yukon  \\\n",
       "0   1    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "1   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      4   \n",
       "2   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "3   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "4   1    1    0    0    0    0    0  0   0    0  ...     1     2     0      0   \n",
       "5   0    0    1    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "6   1    0    0    0    1    1    1  0   1    1  ...     1     0     0      0   \n",
       "7   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "8   0    0    0    0    0    0    0  0   0    2  ...     0     0     0      0   \n",
       "9   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "10  1    0    0    0    0    0    0  0   3    0  ...     0     0     0      0   \n",
       "11  0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "12  1    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "13  0    0    0    1    0    0    0  0   0    0  ...     1     0     0      0   \n",
       "14  1    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "15  0    0    0    0    0    0    0  0   0    0  ...     1     0     0      0   \n",
       "16  0    0    0    0    0    0    0  0   1    0  ...     0     0     0      0   \n",
       "17  0    0    0    0    0    0    0  0   8    0  ...    12     1     0      0   \n",
       "18  0    0    0    0    1    0    0  1   0    1  ...     0     0     1      0   \n",
       "19  0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "\n",
       "    z  zarychanski  zibi  ziomek  zmiyiwski  zone  \n",
       "0   0            0     0       0          0     0  \n",
       "1   0            0     0       0          0     1  \n",
       "2   0            0     0       0          0     0  \n",
       "3   0            2     0       0          0     0  \n",
       "4   0            0     0       0          0     0  \n",
       "5   0            0     0       0          0     0  \n",
       "6   0            0     1       0          1     0  \n",
       "7   0            0     0       0          0     0  \n",
       "8   0            0     0       0          0     0  \n",
       "9   0            0     0       0          0     0  \n",
       "10  0            0     0       0          0     0  \n",
       "11  0            0     0       0          0     0  \n",
       "12  0            0     0       0          0     0  \n",
       "13  1            0     0       0          0     0  \n",
       "14  0            0     0       0          0     0  \n",
       "15  0            0     0       0          0     1  \n",
       "16  0            0     0       0          0     0  \n",
       "17  0            0     0       0          0     0  \n",
       "18  0            0     0       2          0     0  \n",
       "19  0            0     0       0          0     0  \n",
       "\n",
       "[20 rows x 2951 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts_df.columns = count_vect_sample.get_feature_names()  # Assigning the feature names to the columns\n",
    "X_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17331\n"
     ]
    }
   ],
   "source": [
    "# Might take awhile...\n",
    "train_data = df[0:1000]\n",
    "bow_transformer = CountVectorizer(analyzer=clean_text).fit(train_data['text'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "newstest1 = train_data['text'][3]\n",
    "#print(newstest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowtest1 = bow_transformer.transform([newstest1])\n",
    "print(bowtest1)\n",
    "print(bowtest1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(bow_transformer.get_feature_names())\n",
    "#print(bow_transformer.get_feature_names()[9570])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_bows = bow_transformer.transform(train_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (1000, 17331)\n",
      "Amount of Non-Zero occurences:  260806\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', news_bows.shape)\n",
    "print('Amount of Non-Zero occurences: ', news_bows.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * news_bows.nnz / (news_bows.shape[0] * news_bows.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(news_bows)\n",
    "tfidf4 = tfidf_transformer.transform(bowtest1)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17331)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(news_bows)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(messages_tfidf, train_data['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: Cbc News\n",
      "expected: Cbc News\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', spam_detect_model.predict(tfidf4)[0])\n",
    "print('expected:', train_data.authors[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a classification to predict CBC News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' '' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' '' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' '' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' '' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' '' '' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " '' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' '' 'Cbc News' 'Cbc News' '' '' '' 'Cbc News'\n",
      " '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " '' 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detect_model.predict(messages_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                            precision    recall  f1-score   support\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.80      0.51      0.62       270\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                 \"Rosemary Barton Is CbcS Chief Political Correspondent\", Based In Ottawa.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                \"Ryan Cooke Works For Cbc Out Of Its Bureau In St. JohnS.\", Read More Articles This Author       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                         \"Tori Weldon Is A Reporter Based In Moncton. SheS Been Working For The Cbc Since\"       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                          Adam Carter Is A Newfoundlander Who Now Calls Toronto Home. He Enjoys A Good Story, Playing Loud Music. You Can Follow Him On Twitter, Adamcartercbc Or Drop Him An Email At Adam.Carter Cbc.Ca.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                             Adam Hunter Is The Provincial Affairs Reporter At Cbc Saskatchewan, Based In Regina. He Has Been With Cbc For Years. He Hosts The Cbc Podcast On The Ledge. Follow Him On Twitter, Ahiddycbc. Contact Him, Adam.Hunter Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                              Alanna Petroff Is A Freelance Reporter Based In London. She Has Covered Business, Economic, International News For The Past Decade At Outlets Such As Reuters, Cnn, The Bbc.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                        Alex Soloducha Is A Reporter For Cbc Saskatchewan.       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                                                                   Alicia Bridges Is A Digital, Broadcast Journalist At Cbc Saskatoon. Email Her At Alicia.Bridges Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                         American Politics Contributor, Keith Boag Writes About American Politics, Issues That Shape The American Experience. Keith Was Based For Several Years In Los Angeles, Now, In Retirement After A Long Career With Cbc News, Continues To Live In Washington, D.C. Earlier, Keith Reported Ottawa, Where He Served As Chief Political Correspondent For Cbc News.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                         Andrea Bellemare Is A Reporter, Producer With Cbc News Who Currently Focuses On Disinformation, Tech, Privacy., She Helped Launch The New Cbc Kitchener-Waterloo Radio Station In, Reported For Cbc Montreal, Produced Radio Docs For Cbc Radio. She Has Also Reported For The Wire Service Agence France-Presse.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                Angela Gemmill Is A Cbc Journalist Who Has Covered News In Sudbury, Ont., For Years. Connect With Her On Twitter, Angelagemmill. Send Story Ideas To Angela.Gemmill Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                             Anjuli Patil Is A Reporter, \"Occasional Video Journalist With Cbc Nova ScotiaS Digital Team.\"       0.00      0.00      0.00         2\n",
      "                                                                                                                   Ap Journalist, Heidi Atter Is A Journalist Working In Regina. She Started With Cbc Saskatchewan After A Successful Internship, Has A Passion For Character-Driven Stories. Heidi Has Worked As A Reporter, Web Writer, Associate Producer, Show Director So Far, Has Worked In Edmonton, At The Wainwright Military Base, In Adazi, Latvia. Story Ideas       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                               Ariana Kelland Is A Reporter With The Cbc Newfoundland, \"Labrador Bureau In St. JohnS.\", More This Author, Follow Ariana Kelland On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                  Asia Correspondent, \"SaÅ¡a Petricic Is The CbcS Asia Correspondent\", Based In Beijing. He Has Covered China As Well As Reported North, South Korea. He Previously Reported On The Middle East, Jerusalem, Through The Arab Spring, The Syrian Civil War. He Has Filed Stories Every Continent For Cbc News. Instagram, More SaÅ¡a Petricic       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                  Associate Producer Technician, Danelle Cloutier Is An Associate Producer, Audio Technician In Current Affairs At Cbc Manitoba. She Has A Background In Audio Engineering       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                        Bill Graveland Is A Calgary-Based Reporter For The Canadian Press.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                       Brian Rodgers Is A Videojournalist, Producer With Cbc Saskatchewan.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                 Briar Stewart Is A Senior Reporter With Cbc News., For More Than A Decade, She Has Been Covering Stories For Television, Radio, Online., She Is Based In Vancouver, Can Be Reached At Briar.Stewart Cbc.Ca, Or On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                    Bridget Yard Is A Video Journalist Based In Saskatoon. She Has Also Worked For Cbc In Fredericton, Bathurst, Follow Bridget On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                     Bryce Hoye Is An Award-Winning Journalist, Science Writer With A Background In Wildlife Biology, Interests In Courts, Social Justice, Health, More. He Is The Prairie Rep For Outcbc. Story Idea, Email Bryce.Hoye Cbc.Ca., Email, Bryce.Hoye Cbc.Ca, More Bryce Hoye       0.00      0.00      0.00         1\n",
      "                                                                            Business Columnist, Don Pittis Was A Forest Firefighter, \"A Ranger In CanadaS High Arctic Islands. After Moving Into Journalism\", He Was Principal Business Reporter For Radio Television Hong Kong Before The Handover To China. He Has Produced, Reported For The Cbc In Saskatchewan, Toronto, \"The Bbc In London. He Is Currently Senior Producer At CbcS Business Unit.\", More Don Pittis       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                         Business Reporter, Sophia Harris Covers Business, Consumer News., Contact, Sophia.Harris Cbc.Ca, More This Author       0.00      0.00      0.00         7\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                        Cbc Communications       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                            Cbc Investigates, Katie Nicholson Is A Senior Reporter With Cbc Investigates Based In Toronto.       0.00      0.00      0.00         1\n",
      "                                                                                                                                             Cbc Investigative Journalist, Jonathon Gatehouse Has Covered News, Politics At Home, Abroad, Reporting Dozens Of Countries. He Has Also Written Extensively About Sports, Covering Seven Olympic Games, Authoring A Best-Selling Book On The Business Of Pro-Hockey. He Works For The National Investigative Unit In Toronto.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Cbc News       0.38      1.00      0.55       318\n",
      "                                                                                                                                                                                    Cbc News New York, \"Steven DSouza Is A Gemini-Nominated Journalist Based In New York City. He Has Reported Internationally The Papal Conclave In Rome\", The World Cup In Brazil, He Spent Eight Years In Toronto Covering Stories Like The Protests, The Rob Ford Crack Video Scandal.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                               Cbc News, \"David Cochrane Is A Senior Reporter In CbcS Parliamentary Bureau. He Previously Wrote For Cbc Newfoundland\", Follow David Cochrane On Twitter, Read More Articles David Cochrane       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                      Cbc Reporter, Brady Strachan Is A Cbc Reporter Based In Kelowna, B.C. Besides Kelowna, Strachan Has Covered Stories For Cbc News In Winnipeg, Brandon, Vancouver, Internationally. Follow His Tweets       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                              Cbc Staff, Alvin Yu Splits His Time Along The Corridor As A Reporter For Cbc London, Associate Producer For Cbc Toronto, The National. Yu Set His Sights On Journalism Early - As A Kid He Would Anchor The News In The Shower, Hoping One Day To Make It To The Big Screen.       0.00      0.00      0.00         5\n",
      "                                                                                                                                                                                                                                                                                                                                City Hall Reporter, Lauren Pelley Is A Cbc Reporter In Toronto Covering City Hall, Municipal Affairs. Contact Her At, Lauren.Pelley Cbc.Ca       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                         Colleen M. Flood Is Director Of The Centre For Health Law, Policy, Ethics, University Research Chair At The University Of Ottawa.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                           Dan Mcgarvey Is A Mobile Journalist Focused On Filing Stories Remotely For Cbc Calgary S Web, Radio, Tv, Social Media Platforms, Only Using An Iphone, Mobile Tech. You Can Email Story Ideas, Tips To Dan At, Dan.Mcgarvey Cbc.Ca Or Tweet Him       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                             Dan Zakreski Is A Reporter For Cbc Saskatoon.       0.00      0.00      0.00         3\n",
      "Defence, Murray Brewster Is Senior Defence Writer For Cbc News, Based In Ottawa. He Has Covered The Canadian Military, Foreign Policy Parliament Hill For Over A Decade. Among Other Assignments, He Spent A Total Of Months On The Ground Covering The Afghan War For The Canadian Press. Prior To That, He Covered Defence Issues, Politics For Cp In Nova Scotia For Years, Was Bureau Chief For Standard Broadcast News In Ottawa., Follow, Murray_Brewster On Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                             Dr. Vivek Goel Was The Founding Head Of Public Health Ontario, Set Up In Response To The Sars Crisis. He Is Currently A Professor At The University Of Toronto S Dalla Lana School Of Public Health, Vice-President Of Research, Innovation, Strategic Initiatives At U Of T.       0.00      0.00      0.00         1\n",
      "                                                                                                                                        Drew Anderson Is A Web Journalist At Cbc Calgary. Like Almost Every Journalist Working Today, \"HeS Won A Few Awards. HeS Also A Third-Generation Calgarian.\", You Can Follow Him On Twitter, Drewpanderson. Contact Him In Confidence At Drew.Anderson Cbc.Ca. Signal Contact Upon Request. Cbc Secure Drop, Www.Cbc.Ca Securedrop       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                   Elizabeth Chiu Is A Reporter In Nova Scotia, Hosts Atlantic Tonight On Saturdays At P.M., P.M. In Newfoundland. If You Have A Story Idea For Her, Contact Her At Elizabeth.Chiu Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                 Erik White Is A Cbc Journalist Based In Sudbury. He Covers A Wide Range Of Stories About Northern Ontario. Connect With Him On Twitter, Erikjwhite. Send Story Ideas To Erik.White Cbc.Ca       0.00      0.00      0.00         5\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                       Franca G. Mignacca Is A Journalist At Cbc Montreal.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                     Hadeel Ibrahim Is A Cbc Reporter Based Out Of Saint John. She Can Be Reached At Hadeel.Ibrahim Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                   Health Writer, Amina Zafar Has Covered Health, Medical, Science News At Cbc Since She Has A Degree In Environmental Science, \"A MasterS In Journalism.\"       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                       Holly Conners Is A Reporter, Current Affairs Producer Who Has Been With Cbc Cape Breton Since, Contact Her At Holly.Conners Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                  Host Of Afternoon Drive, \"Chris Dela Torre Is The Host Of Afternoon Drive On Cbc Radio One In Southwestern Ontario. HeS Worked As A Host\", Reporter, Producer In Several Cities Across Canada, Has Hosted Several Cbc Network Programs, Such As Q, Dnto, The Story Here.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                 Ian Froese Is A Reporter With Cbc Manitoba. He Has Previously Worked For Newspapers In Brandon, Steinbach. Story Idea, Email, Ian.Froese Cbc.Ca., Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                     Investigative Journalist, \"Timothy Sawa Works For CbcS Investigative Unit\", The Fifth Estate, Has Been An Investigative Journalist At Cbc News For More Than A Decade. He Has Produced Investigations Looking At Police Corruption, Sexual Abuse In Public Institutions, Offshore Tax Evasion., Cbc News Investigates       0.00      0.00      0.00         1\n",
      "                   Investigative Reporter, Cbc Manitoba I-Team, Caroline Began Her Career Co-Hosting An Internet Radio Talk Show In Toronto, Then Worked At Various Stations In Oshawa, Sudbury, Toronto Before Landing In Winnipeg In Since Joining Cbc Manitoba As A Reporter In, She Has Won An Award For Her Work On Crowded Jails, \"Her Investigation Into Tina FontaineS Death Led To Changes In The Child Welfare System. Email\", Caroline.Barghout Cbc.Ca, Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                              Investigative Reporter, Jennie Russell Is A Reporter With Cbc Investigates, The Award-Winning Investigative Unit Of Cbc Edmonton. Jennie Specializes In Accountability Journalism, Her Work Has Been Widely Credited With Forcing Transparency, Democratic Change In Alberta. Contact Jennie At Jennie.Russell Cbc.Ca, Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                               Jack Julian Joined Cbc Nova Scotia As An Arts Reporter In His News Career Began On The Morning Of Sept., Following The Crash Of Swissair He Is Now A Data Journalist In Halifax, You Can Reach Him At, Email At Jack.Julian Cbc.Ca Or Follow Him On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                 Jackie Mckay Is A MÃ©tis Journalist Working For Cbc In Nunavut. She Has Worked As A Reporter In Thunder Bay, Yellowknife, Whitehorse, Iqaluit. Jackie Also Worked On Cbc Radio One Shows Including The Current, Metro Morning After Graduating Ryerson University In Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                        Jason Viau Is A Video Journalist, Tv Host, Radio Newsreader At Cbc Windsor. He Was Born In North Bay, But Has Lived In Windsor For Most Of His Life. Since Graduating St. Clair College, \"HeS Worked In Print\", Tv, Radio. Email Him At Jason.Viau Cbc.Ca, Follow Jason On Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                      Jim Agapito Is A Filipino Filmmaker Winnipeg. Jim Writes, Boxes, Takes Photos, Sings In A Punk Band.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                         Joe Tunney Reports For Cbc News In Ottawa. He Can Be Reached At Joe.Tunney Cbc.Ca       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                                                                            Joel Ballard Is A Reporter With The Cbc In Vancouver. You Can Reach Him At Joel.Ballard Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                  Joel Joined Cbc Calgary In Reach Him Email At Joel.Dryden Cbc.Ca, Follow Joel On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                              Jonathan Montpetit Is A Journalist With Cbc Montreal., Follow Him On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                            Jorge Barrera Is A Caracas-Born, Award-Winning Journalist Who Has Worked Across The Country, \"Internationally. He Works For CbcS Indigenous Unit Based Out Of Ottawa. Follow Him On Twitter\", Jorgebarrera Or Email Him Jorge.Barrera Cbc.Ca., Follow, Jorgebarrera On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                               Leah Hendry Is A Tv, Radio, Online Journalist With Cbc Montreal Investigates. Contact Her Via Our Confidential Tipline, Or On Email At Montrealinvestigates Cbc.Ca., Follow Leah On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                            Lenard Monkman Is Anishinaabe Lake Manitoba First Nation, Treaty Territory. He Is The Co-Founder Of Red Rising Magazine, \"Has Been An Associate Producer With The CbcS Indigenous Unit For Three Years. Follow Him On Twitter\"       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                            Lien Yeung Hosts Cbc Vancouver News Weekends. As A Multimedia Reporter, She Has Covered Stories Locally, Nationally Coast To Coast On Television, Radio, Social Media. You Can Reach Her On Instagram Or Twitter, Lienyeung Or Via Email At Lien.Yeung Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                Lucie Edwardson Is A Reporter With Cbc Calgary, Currently Focused On Bringing You Stories Related To Education In Alberta. In She Headed A Pop-Up Bureau In Lethbridge, Alta . Her Experience Includes Newspaper, Online, Tv, Radio. Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                    Mandy Luk Is A Senior Producer With Cbc News. She Holds A Journalism Degree The Chinese University Of Hong Kong, \"A MasterS Degree In Economics The University Of Toronto. Programs She Has Worked For Include Cbc News Network\", The National, Cross Country Checkup.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                Mark Gollom Is A Toronto-Based Reporter With Cbc News. He Covers Canadian, U.S. Politics, Current Affairs.       0.00      0.00      0.00         5\n",
      "                                                                                                                                                                                                                                                               Medical Science, Kelly Crowe Is A Science Correspondent For Cbc News. She Joined Cbc In, Has Spent Years Reporting On A Wide Range Of National News, Current Affairs, With A Particular Interest In Science       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                            Moscow Correspondent, Chris Brown Is A Foreign Correspondent Based In The Cbc S Moscow Bureau. Previously A National Reporter For Cbc News On Radio, Tv, Online, Chris Has A Passion For Great Stories, Has Travelled All Over Canada, The World To Find Them.       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                     Natalia Is A Multi-Platform Journalist In Ottawa. She Has Also Worked For Cbc In P.E.I., Newfoundland       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                Nicholas Frew Is An Online Reporter Based In Winnipeg. Hailing Newfoundland, Frew Moved To Halifax To Attend Journalism School Before Moving To Winnipeg. Prior To Joining Cbc Manitoba, Frew Interned At The Winnipeg Free Press. Story Idea, Email At Nick.Frew Cbc.Ca, Email, Nick.Frew Cbc.Ca, Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                           Nicola Macleod Is A Reporter With Cbc In P.E.I.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                       Parliament Hill Bureau, Aaron Wherry Has Covered Parliament Hill Since, \"Has Written For MacleanS\", The National Post, The Globe, Mail. He Is The Author Of Promise, Peril, \"A Book About Justin TrudeauS Years In Power.\", Follow Aaron On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                Parliamentary Bureau, John Paul, J.P., \"Tasker Is A Reporter In The CbcS Parliamentary Bureau In Ottawa. He Can Be Reached At John.Tasker Cbc.Ca.\", Follow J.P. On Twitter       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                   Paul Withers Is An Award-Winning Journalist Whose Career Started In The As A Cartoonist. He Has Been Covering Nova Scotia Politics For More Than Years.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                             Politics, Ãric Grenier Is A Senior Writer, \"The CbcS Polls Analyst. He Was The Founder Of Threehundredeight.Com\", Has Written For The Globe, Mail, Huffington Post Canada, The Hill Times, Le Devoir, L ActualitÃ©., Read More Cbcnews.Ca Columns Ãric Grenier       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                            Preston Mulligan Has Been A Reporter In The Maritimes For More Than Years. Along With His Reporting Gig, \"He Also Hosts Cbc RadioS Sunday Phone-In Show\", Maritime Connection.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                        Prince Edward Island, Wayne Thibodeau Is A Reporter Editor With Cbc Prince Edward Island. He Has Worked As A Reporter, Editor, Photographer, Video Journalist In Print, Digital, Tv For More Than Years. He Can Be Reached At Wayne.Thibodeau Cbc.Ca, Follow, Jwaynecbc On Twitter       0.00      0.00      0.00         2\n",
      "                                                                               Producer, Cbc News Business, James Dunne Researches, Produces, Writes Stories For The Business Unit At Cbc News. He Has A Decade Of Experience In Business Programming, Including On The Shows Venture, Fortune Hunters. An Award-Winning Videojournalist, \"HeS Also Worked On Special Projects\", As The Late Lineup Editor For The World At Six On Cbc Radio One., James Dunne On Linkedin       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                Producer, The Fifth Estate, Scott Anderson Is A Producer At The Fifth Estate. He Has Been An Investigative Journalist In Both Print, Broadcast. He Has Covered Stories At City Hall, Across The Country, Around The World.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                      Provincial Affairs Reporter Covering The B.C. Legislature. Anything Political, Tanya.Fletcher Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                  Provincial Affairs Reporter, Mike Crawley Is Provincial Affairs Reporter In Ontario For Cbc News. He Has Won Awards For His Reporting On The Ehealth Spending Scandal, \"Flaws In OntarioS Welfare-Payment Computer System. Before Joining The Cbc In\", Mike Filed Stories Countries In Africa As A Freelance Journalist, Worked As A Newspaper Reporter In B.C., Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                            Rachel Ward Is A Journalist With Cbc Calgary. You Can Reach Her With Questions Or Story Ideas At Rachel.Ward Cbc.Ca., Follow Rachel On Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                           Rafferty Baker Is A Video Journalist With Cbc News, Based In Vancouver. You Can Find His Stories On Cbc Radio, Television, Online At Cbc.Ca Bc.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                          RenÃ©e Is A Cbc Correspondent Based In London, U.K., She Has Spent A Decade With The Organization In A Number Of Roles, Including Senior Business Reporter, Weekend News Anchor, Television, Radio Reporter, Associate Producer, Program Director       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                            Reporter Associate Producer, Emily Pasiuk Is A Reporter For Cbc Saskatchewan, \"An Associate Producer For The Morning Edition. SheS Based In Regina. She Has Also Reported At Ctv Saskatoon\", Written For Global Regina. Reach Her At Emily.Pasiuk Cbc.Ca., Find Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                        Reporter Editor, \"Elizabeth Fraser Is A Reporter Editor With Cbc New Brunswick Based In Fredericton. SheS Originally Manitoba. Story Tip\", Elizabeth.Fraser Cbc.Ca       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                         Reporter Editor, Alex Is A Reporter Living In Halifax. Send Her Story Ideas At Alex.Cooke Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                       Reporter Editor, Bobhristova Is A Reporter Editor With Cbc Hamilton. Email, Bobby.Hristova Cbc.Ca, Follow, Bobbyhristova On Twitter       0.00      0.00      0.00         5\n",
      "                                                                                                                                                            Reporter Editor, Darren Bernhardt Spent The First Dozen Years Of His Journalism Career In Newspapers, First At The Regina Leader-Post Then The Saskatoon Starphoenix. He Has Been With Cbc Manitoba Since, Specializes In Offbeat, Local History Stories, Features. Story Idea, Email, Darren.Bernhardt Cbc.Ca       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                               Reporter Editor, Jennifer La Grassa Is A Reporter Editor For Cbc Hamilton. Email, Jennifer.Lagrassa Cbc.Ca, Follow, Jennlagrassa On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                 Reporter Editor, Tom Ayers Has Been A Reporter, Editor For More Than Years. He Has Spent The Last Years Covering Cape Breton, Nova Scotia Stories. You Can Reach Him At Tom.Ayers Cbc.Ca.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                         Reporter The Canadian Press, Stephanie Taylor Is A Canadian Press Reporter Based In Saskatchewan.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                       Reporter, Web Writer For Cbc Saskatoon, Story Tips, Ideas Welcomed At Guy.Quenneville Cbc.Ca, Follow Guy On Twitter       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                           Sam Samson Is A Multimedia Journalist Who Has Worked For Cbc In Manitoba, Ontario As A Reporter, Associate Producer. Before Working For Cbc, She Studied Journalism, Communications In Winnipeg. You Can Get In Touch On Twitter, Cbcsamsamson Or Email Samantha.Samson Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                Sanjay Maru Is A Reporter At Cbc Windsor. Email Him At Sanjay.Maru Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                 Sarah Leavitt Is A Journalist With Cbc Montreal., Follow Sarah On Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                             Sarah Rieger Joined Cbc Calgary As An Online Journalist In You Can Reach Her Email At Sarah.Rieger Cbc.Ca., Follow Sarah On Twitter, Read More Articles Sarah       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                        Science, Technology Writer, Emily Chung Covers Science, Technology For Cbc News. She Has Previously Worked As A Digital Journalist For Cbc Ottawa, \"As An Occasional Producer At CbcS Quirks\", Quarks. She Has A Phd In Chemistry.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                      Senior Producer Western Digital Business Unit, \"Tony Seskus Is Senior Producer With CbcS Western Business Unit In Calgary. HeS Written For Newspapers\", Wire Services For More Than Years On Three Continents. In Calgary, Tony Has Reported On The Energy Sector, Federal Politics.       0.00      0.00      0.00         2\n",
      "                                                                                                 Senior Reporter, Award-Winning Reporter Elizabeth Thompson Covers Parliament Hill. A Veteran Of The Montreal Gazette, Sun Media, Ipolitics, \"She Currently Works With The CbcS Ottawa Bureau\", Specializing In Investigative Reporting, Data Journalism. She Can Be Reached At, Elizabeth.Thompson Cbc.Ca., More Elizabeth Thompson, Follow Elizabeth Thompson On Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                              Senior Reporter, Bonnie Allen Is A Senior Reporter For Cbc News Based In Saskatchewan. Before Returning To Canada In, Allen Spent Four Years Reporting Across Africa, Including Libya, South Sudan, Liberia, \"Sierra Leone. She Holds A MasterS In International Human Rights Law The University Of Oxford.\"       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                           Senior Reporter, Julie Ireton Is A Senior Reporter Who Works On Investigations, \"Enterprise News Features At Cbc Ottawa. SheS Also The Host Of The New Cbc Investigative Podcast\", The Band Played On. You Can Reach Her At Julie.Ireton Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                  Senior Writer, \"Adam Miller Is Senior Digital Writer With Cbc News. HeS Covered Health\", Politics, Breaking News Extensively In Canada, In Addition To Several Years Reporting On News, Current Affairs Throughout Asia.       0.00      0.00      0.00         8\n",
      "                                                                                                                                                                                                                                                                                                                  Senior Writer, \"Kathleen Harris Is A Senior Writer In The CbcS Parliament Hill Bureau. She Covers Politics\", Immigration, Justice, Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                   Senior Writer, Pete Evans Is The Senior Business Writer For Cbcnews.Ca. Prior To Coming To The Cbc, His Work Has Appeared In The Globe, Mail, The Financial Post, The Toronto Star, Canadian Business Magazine, Believe It Or Not, Circuits Assembly Magazine., Twitter       0.00      0.00      0.00         8\n",
      "                                                                                                                                                                                                                                                                                                            Shaina Luck Covers Everything Court To City Council. Her Favourite Stories Are About Ordinary People In Extraordinary Circumstances. Email, Shaina.Luck Cbc.Ca       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                          Shane Magee Is A Moncton-Based Reporter For Cbc.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                            Taryn Grant Is A Halifax-Based Reporter For Cbc Nova Scotia. Get In Touch With Her Email At Taryn.Grant Cbc.Ca       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                      The Associated Press       0.00      0.00      0.00       100\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                        The Canadian Press       0.00      0.00      0.00        28\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                           Thomson Reuters       0.00      0.00      0.00        61\n",
      "                                                                                                                                                                                                                                                                                                                                                          Tony Davis Grew Up On P.E.I., Studied Journalism At Holland College. He Can Be Contacted At Anthony.Davis Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                            Tory Gillis Began Work As A Journalist With Cbc Saskatchewan In You Can Hear Her Deliver The Afternoon News On Weekdays On Cbc Radio One In Saskatchewan. She Has Also Worked As A Reporter, \"As An Associate Producer On Cbc SaskatchewanS Radio Shows\", The Morning Edition, Bluesky, The Afternoon Edition.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                Video Journalist, \"Colin Butler Is A Veteran Cbc Reporter WhoS Worked In Moncton\", Saint John, Fredericton, Toronto, Kitchener-Waterloo, Hamilton, London, Ont. Email, Colin.Butler Cbc.Ca       0.00      0.00      0.00         6\n",
      "                                                                                                                                                                                                                                     Web Writer, \"Creeden Martell Is A Cree Journalist The Waterhen Lake First Nation. He Works For Cbc Saskatchewan In Regina. He Has Also Written For The University Of ReginaS Jschool\", The Saskatoon Starphoenix, Vice News., Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                           Web Writer, Sam Juric Is A Journalist With Cbc P.E.I., Can Be Reached At Samantha.Juric Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                       Winnipeg Free Press       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                           Yvette Brend Is A Cbc Vancouver Journalist. Yvette.Brend Cbc.Ca       0.00      0.00      0.00         3\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  accuracy                           0.46      1000\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                 macro avg       0.01      0.01      0.01      1000\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                              weighted avg       0.34      0.46      0.34      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(train_data['authors'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data  = df[1001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.punkt import PunktLanguageVars\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "      <td>[canadian, pharmacy, limiting, much, medicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "      <td>[yukon, government, identified, two, place, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "      <td>[senat, late, wednesday, pass, unparallel, 22,...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              Cbc News  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              Cbc News  Yukon gov't names 2 possible sources of corona...   \n",
       "2  The Associated Press  U.S. Senate passes $2T coronavirus relief package   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "2  [senate, late, wednesday, passed, unparalleled...   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...   \n",
       "1  [yukon, govern, identifi, two, place, whitehor...   \n",
       "2  [senat, late, wednesday, pass, unparallel, 22,...   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [canadian, pharmacy, limiting, much, medicatio...  \n",
       "1  [yukon, government, identified, two, place, wh...  \n",
       "2  [senate, late, wednesday, passed, unparalleled...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['body_text_lemmatized'].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_specials_string = re.sub('[!#?,.:\";]', '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_specials_string=no_specials_string.replace('[','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=PunktLanguageVars()\n",
    "tokens=p.word_tokenize(no_specials_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korea wednesday\n",
      "wednesday declared\n",
      "declared formal\n",
      "formal en\n",
      "en 3562\n",
      "3562 spread\n",
      "spread mers\n",
      "mers coronavirus\n",
      "coronavirus infection\n",
      "infection hospita\n",
      "hospita 3563\n",
      "3563 relic\n",
      "relic bygone\n",
      "bygone era\n",
      "era wealthy\n",
      "wealthy nova\n",
      "nova scotians\n",
      "scotians 3564\n",
      "3564 camel\n",
      "camel implicated\n",
      "implicated middle\n",
      "middle eastern\n",
      "eastern respirato\n",
      "respirato 3565\n",
      "3565 world\n",
      "world health\n",
      "health organizationled\n",
      "organizationled group\n",
      "group expert\n"
     ]
    }
   ],
   "source": [
    "# See the last 10 pairs\n",
    "for i in range(len(tokens)-30, len(tokens)-1):\n",
    "    print(tokens[i], tokens[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24322\n",
      "17594\n",
      "[('small', 'west'), ('ontario', 'city'), ('four', '1196'), ('canadian', 'tourist'), ('people', 'novel'), ('morning', 'day'), ('unit', 'wechu'), ('temporarily', 'amid'), ('1500bed', 'facil'), ('died', 'bea')]\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [(tokens[i], tokens[i+1]) for i in range(len(tokens)-1)]\n",
    "print(len(word_pairs))\n",
    "\n",
    "gram2 = set(word_pairs)\n",
    "print(len(gram2))\n",
    "\n",
    "# Print 20 elements from gram2\n",
    "gram2_iter = iter(gram2)\n",
    "print([next(gram2_iter) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 3566), ('covid19', 321), ('health', 318), ('say', 254), ('case', 222), ('new', 190), ('coronavirus', 174), ('government', 129), ('canadian', 128), ('canada', 126), ('official', 117), ('public', 117), ('latest', 110), ('confirmed', 105), ('first', 103), ('people', 103), ('alberta', 98), ('two', 95), ('ontario', 93), ('bc', 85)]\n"
     ]
    }
   ],
   "source": [
    "gram1 = dict()\n",
    "\n",
    "# Populate 1-gram dictionary\n",
    "for tokens in tokens:\n",
    "    if tokens in gram1:\n",
    "        gram1[tokens] += 1\n",
    "    else:\n",
    "        gram1[tokens] = 1 # Start a new entry with 1 count since saw it for the first time.\n",
    "\n",
    "# Turn into a list of (word, count) sorted by count from most to least\n",
    "gram1 = sorted(gram1.items(), key=lambda tokens:tokens[1],reverse=True)\n",
    "#gram1 = sorted(gram1.items(), key=lambda (word, count): -count)\n",
    "\n",
    "\n",
    "# Print top 20 most frequent words\n",
    "print(gram1[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('case', 'covid19'), 99), (('health', 'official'), 83), (('public', 'health'), 73), (('nova', 'scotia'), 54), (('new', 'case'), 49), (('good', 'morning'), 42), (('morning', 'daily'), 42), (('daily', 'news'), 42), (('news', 'roundup'), 42), (('roundup', 'everythi'), 42), (('confirmed', 'case'), 39), (('prime', 'minister'), 37), (('new', 'brunswick'), 36), (('world', 'health'), 35), (('novel', 'coronavirus'), 32), (('health', 'officer'), 32), (('federal', 'government'), 29), (('chief', 'public'), 29), (('health', 'organization'), 29), (('minister', 'justin'), 28), (('justin', 'trudeau'), 27), (('tested', 'positive'), 25), (('covid19', 'pandemic'), 24), (('health', 'minister'), 24), (('northwest', 'territory'), 24), (('coronavirus', 'outbreak'), 22), (('chief', 'medical'), 22), (('thunder', 'bay'), 22), (('officer', 'dr'), 21), (('cruise', 'ship'), 21), (('around', 'world'), 20), (('provincial', 'health'), 20), (('case', 'coronavirus'), 19), (('first', 'nation'), 19), (('british', 'columbia'), 19), (('social', 'distancing'), 19), (('state', 'emergency'), 18), (('health', 'unit'), 18), (('medical', 'officer'), 18), (('covid19', 'case'), 17), (('spread', 'covid19'), 17), (('healthcare', 'worker'), 16), (('newfoundland', 'labrador'), 16), (('update', 'march'), 15), (('presumptive', 'case'), 15), (('pei', 'chief'), 15), (('dr', 'bonnie'), 14), (('coronavirus', 'case'), 14), (('official', 'say'), 14), (('declared', 'state'), 14), (('stock', 'market'), 13), (('grocery', 'store'), 13), (('death', 'toll'), 13), (('new', 'coronavirus'), 13), (('covid19', 'confirmed'), 13), (('health', 'authority'), 13), (('recent', 'development'), 12), (('two', 'new'), 12), (('column', 'opinion'), 12), (('government', 'announced'), 12)]\n"
     ]
    }
   ],
   "source": [
    "gram2 = dict()\n",
    "\n",
    "# Populate 2-gram dictionary\n",
    "for i in range(len(tokens)-1):\n",
    "    key = (tokens[i], tokens[i+1])\n",
    "    if key in gram2:\n",
    "        gram2[key] += 1\n",
    "    else:\n",
    "        gram2[key] = 1\n",
    "\n",
    "# Turn into a list of (word, count) sorted by count from most to least\n",
    "\n",
    "gram2 = sorted(gram2.items(), key=lambda key:key[1],reverse=True)\n",
    "#gram2 = sorted(gram2.items(), key=lambda (_, count): -count)\n",
    "\n",
    "# Print top 20 most frequent words\n",
    "print(gram2[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=bigrams(tokens)\n",
    "[x for x in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=trigrams(tokens)\n",
    "[x for x in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "five_gram=ngrams(tokens,7)\n",
    "[x for x in five_gram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889\n"
     ]
    }
   ],
   "source": [
    "start_word = tokens[len(tokens)//4]\n",
    "print(start_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start word: 889\n",
      "2-gram sentence: \"\n",
      "889\n",
      "medical\n",
      "officer\n",
      "dr\n",
      "bonnie\n",
      "henr\n",
      "912\n",
      "154resident\n",
      "care\n",
      "home\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "def get2GramSentence(word, n = 500):\n",
    "    for i in range(n):\n",
    "        print(word)\n",
    "        # Find Next word\n",
    "        word = next((element[0][1] for element in gram2 if element[0][0] == word), None)\n",
    "        if not word:\n",
    "            break\n",
    "\n",
    "word = start_word\n",
    "print(\"Start word: %s\" % word)\n",
    "\n",
    "print(\"2-gram sentence: \\\"\")\n",
    "get2GramSentence(word, 10)\n",
    "print(\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def weighted_choice(choices):\n",
    "   total = sum(w for c, w in choices)\n",
    "   r = random.uniform(0, total)\n",
    "   upto = 0\n",
    "   for c, w in choices:\n",
    "      if upto + w > r:\n",
    "         return c\n",
    "      upto += w\n",
    "    \n",
    "def get2GramSentenceRandom(word, n = 50):\n",
    "    for i in range(n):\n",
    "        print(word)\n",
    "        # Get all possible elements ((first word, second word), frequency)\n",
    "        choices = [element for element in gram2 if element[0][0] == word]\n",
    "        if not choices:\n",
    "            break\n",
    "        \n",
    "        # Choose a pair with weighted probability from the choice list\n",
    "        word = weighted_choice(choices)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start word: and\n",
      "2-gram sentence: \"\n",
      "and\n",
      "\"\n",
      "Start word: he\n",
      "2-gram sentence: \"\n",
      "he\n",
      "h\n",
      "1842\n",
      "people\n",
      "rent\n",
      "\"\n",
      "Start word: she\n",
      "2-gram sentence: \"\n",
      "she\n",
      "\"\n",
      "Start word: when\n",
      "2-gram sentence: \"\n",
      "when\n",
      "\"\n",
      "Start word: minister\n",
      "2-gram sentence: \"\n",
      "minister\n",
      "jim\n",
      "zakreski\n",
      "stuck\n",
      "morocco\n",
      "\"\n",
      "Start word: never\n",
      "2-gram sentence: \"\n",
      "never\n",
      "imagined\n",
      "t\n",
      "1080\n",
      "fort\n",
      "\"\n",
      "Start word: i\n",
      "2-gram sentence: \"\n",
      "i\n",
      "2211\n",
      "habitat\n",
      "humanity\n",
      "edmonton\n",
      "\"\n",
      "Start word: how\n",
      "2-gram sentence: \"\n",
      "how\n",
      "1726\n",
      "u\n",
      "1767\n",
      "windsoressex\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for word in ['and', 'he', 'she', 'when', 'minister', 'never', 'i', 'how']:\n",
    "    print(\"Start word: %s\" % word)\n",
    "\n",
    "    print(\"2-gram sentence: \\\"\")\n",
    "    get2GramSentenceRandom(word, 5)\n",
    "    print(\"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install TensorFlow Library Work Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "var = 0\n",
    "def countWords(text):\n",
    "    v = 0\n",
    "    for i in text:\n",
    "        v = v + 1\n",
    "    print(v)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1502567"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemmed vectors are taken as input. \n",
    "# Article size: 5 articles are taken.\n",
    "\n",
    "articles = df.body_text_stemmed.tolist()\n",
    "for article in articles:\n",
    "    for word in article:\n",
    "        words.append(word)\n",
    "        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pharmaci'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only unique words.\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31399"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words) # gives the total number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31399"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "int2word = {}\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31399"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word2int['pharmaci'])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTF = []\n",
    "\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "# based on the window size, the neighbouring word or context words is considered for the current word.\n",
    "# So if the window size is 2, the surrounding words which are at a distance of two words from the current word is processed.\n",
    "\n",
    "for article in articles[0:5]:\n",
    "    for word_index, word in enumerate(article):\n",
    "        for nb_word in article[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(article)) + 1] : \n",
    "            if nb_word != word:\n",
    "                dataTF.append([word, nb_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['canadian', 'pharmaci'],\n",
       " ['canadian', 'limit'],\n",
       " ['pharmaci', 'canadian'],\n",
       " ['pharmaci', 'limit'],\n",
       " ['pharmaci', 'much']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTF[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['canadian', 'pharmaci']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['canadian', 'limit']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTF[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6994"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int[\"canadian\"]  # word2int[ data_word[0] ] = word2int[\"canadian\"] = word2int[dataTF[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30122"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int[\"pharmaci\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17536"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int['covid19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31399"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)     # Initializing the temp array with Zeros till the vocab size. like [ 0 0 0]\n",
    "    temp[data_point_index] = 1    # assigning one value to the data point index. \n",
    "    return temp\n",
    "x_train = [] # input word\n",
    "y_train = [] # output word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_word in dataTF:\n",
    "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n",
    "# convert them to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9272, 31399) (9272, 31399)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# meaning 9272 training points, where each point has 1101 dimensions\n",
    "# or 9272 rows and each row has 1101 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Run this in order to make tensor flow placeholder run on the machine\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_4:0' shape=(?, 31399) dtype=float32>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_5:0' shape=(?, 31399) dtype=float32>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 5 # you can choose your own number\n",
    "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM])) #bias\n",
    "hidden_representation = tf.add(tf.matmul(x,W1), b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
    "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Started at 10.30 AM\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) #make sure you do this!\n",
    "# define the loss function:\n",
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
    "# define the training step:\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
    "n_iters = 10000\n",
    "# train for n_iter iterations\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
    "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Of Tensor Flow\n",
    "loss is :  15.396786\n",
    "loss is :  15.060417\n",
    "loss is :  14.7789545\n",
    "loss is :  14.543843\n",
    "loss is :  14.347865\n",
    "loss is :  14.184861\n",
    "loss is :  14.049553\n",
    "loss is :  13.937419\n",
    "loss is :  13.8446045\n",
    "loss is :  13.767849\n",
    "loss is :  13.704401\n",
    "loss is :  13.651961\n",
    "loss is :  13.6086\n",
    "loss is :  13.572725\n",
    "loss is :  13.543006\n",
    "loss is :  13.518352\n",
    "loss is :  13.497851\n",
    "loss is :  13.480762\n",
    "loss is :  13.466468\n",
    "loss is :  13.454465\n",
    "loss is :  13.444339\n",
    "loss is :  13.435751\n",
    "loss is :  13.428419\n",
    "loss is :  13.422116\n",
    "loss is :  13.4166565\n",
    "loss is :  13.411886\n",
    "loss is :  13.407679\n",
    "loss is :  13.403934\n",
    "loss is :  13.400566\n",
    "loss is :  13.397502\n",
    "loss is :  13.3947\n",
    "loss is :  13.3920965\n",
    "loss is :  13.389667\n",
    "loss is :  13.387376\n",
    "loss is :  13.385196\n",
    "loss is :  13.383113\n",
    "loss is :  13.381103\n",
    "loss is :  13.379161\n",
    "loss is :  13.377268\n",
    "loss is :  13.375417\n",
    "loss is :  13.373605\n",
    "loss is :  13.371823\n",
    "loss is :  13.370061\n",
    "loss is :  13.368324\n",
    "loss is :  13.366601\n",
    "loss is :  13.364895\n",
    "loss is :  13.363197\n",
    "loss is :  13.361516\n",
    "loss is :  13.3598385\n",
    "loss is :  13.358171\n",
    "loss is :  13.356513\n",
    "loss is :  13.354857\n",
    "loss is :  13.353209\n",
    "loss is :  13.351566\n",
    "loss is :  13.349928\n",
    "loss is :  13.3482895\n",
    "loss is :  13.346659\n",
    "loss is :  13.345029\n",
    "loss is :  13.343404\n",
    "loss is :  13.341783\n",
    "loss is :  13.340164\n",
    "loss is :  13.338547\n",
    "loss is :  13.336933\n",
    "loss is :  13.335324\n",
    "loss is :  13.333714\n",
    "loss is :  13.332111\n",
    "loss is :  13.330507\n",
    "loss is :  13.328906\n",
    "loss is :  13.32731\n",
    "loss is :  13.325712\n",
    "loss is :  13.32412\n",
    "loss is :  13.322529\n",
    "loss is :  13.320941\n",
    "loss is :  13.319354\n",
    "loss is :  13.317769\n",
    "loss is :  13.316189\n",
    "loss is :  13.314609\n",
    "loss is :  13.31303\n",
    "loss is :  13.311455\n",
    "loss is :  13.309883\n",
    "loss is :  13.3083105\n",
    "loss is :  13.306741\n",
    "loss is :  13.305176\n",
    "loss is :  13.303611\n",
    "loss is :  13.302046\n",
    "loss is :  13.300488\n",
    "loss is :  13.298933\n",
    "loss is :  13.297376\n",
    "loss is :  13.295823\n",
    "loss is :  13.294272\n",
    "loss is :  13.292721\n",
    "loss is :  13.291174\n",
    "loss is :  13.28963\n",
    "loss is :  13.288084\n",
    "loss is :  13.286546\n",
    "loss is :  13.2850065\n",
    "loss is :  13.283467\n",
    "loss is :  13.281934\n",
    "loss is :  13.2804\n",
    "loss is :  13.278869\n",
    "loss is :  13.277342\n",
    "loss is :  13.275815\n",
    "loss is :  13.274288\n",
    "loss is :  13.272765\n",
    "loss is :  13.271243\n",
    "loss is :  13.269726\n",
    "loss is :  13.268209\n",
    "loss is :  13.266695\n",
    "loss is :  13.265182\n",
    "loss is :  13.263668\n",
    "loss is :  13.262158\n",
    "loss is :  13.260655\n",
    "loss is :  13.259147\n",
    "loss is :  13.257643\n",
    "loss is :  13.256142\n",
    "loss is :  13.2546425\n",
    "loss is :  13.253143\n",
    "loss is :  13.251648\n",
    "loss is :  13.250155\n",
    "loss is :  13.248662\n",
    "loss is :  13.247171\n",
    "loss is :  13.245683\n",
    "loss is :  13.244196\n",
    "loss is :  13.242712\n",
    "loss is :  13.241231\n",
    "loss is :  13.239747\n",
    "loss is :  13.23827\n",
    "loss is :  13.23679\n",
    "loss is :  13.235315\n",
    "loss is :  13.23384\n",
    "loss is :  13.23237\n",
    "loss is :  13.230898\n",
    "loss is :  13.22943\n",
    "loss is :  13.2279625\n",
    "loss is :  13.226497\n",
    "loss is :  13.225033\n",
    "loss is :  13.223573\n",
    "loss is :  13.222114\n",
    "loss is :  13.220656\n",
    "loss is :  13.2192\n",
    "loss is :  13.217744\n",
    "loss is :  13.216292\n",
    "loss is :  13.214839\n",
    "loss is :  13.213389\n",
    "loss is :  13.211946\n",
    "loss is :  13.210498\n",
    "loss is :  13.209052\n",
    "loss is :  13.207609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Articles = 100, Window Size = 5\n",
    "# Started at 12.55 AM\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74582875  0.7793943   0.07386164  0.15888414 -1.0550942 ]\n",
      " [ 0.98273414  0.0811931   0.0202823   0.3914135  -0.6963007 ]\n",
      " [ 0.01152561 -0.315974   -0.21288878  0.15460855  0.8525657 ]\n",
      " ...\n",
      " [-0.5787782   2.55173    -0.3985736   0.58246446  0.26849777]\n",
      " [-0.8640642   0.09151337  0.37342748  0.8094642   0.5006471 ]\n",
      " [ 2.7362478  -0.53771824 -1.2462976   1.5780292  -0.5305438 ]]\n",
      "----------\n",
      "[0.2118817  0.09580352 0.28877154 0.22681047 0.16917028]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(W1))\n",
    "print('----------')\n",
    "print(sess.run(b1))\n",
    "print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = sess.run(W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(vec1, vec2):\n",
    "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
    "def find_closest(word_index, vectors):\n",
    "    min_dist = 10000 # to act like positive infinity\n",
    "    min_index = -1\n",
    "    query_vector = vectors[word_index]\n",
    "    for index, vector in enumerate(vectors):\n",
    "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
    "            min_dist = euclidean_dist(vector, query_vector)\n",
    "            min_index = index\n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packag\n",
      "disappoint\n",
      "follow\n"
     ]
    }
   ],
   "source": [
    "# We will now query these vectors with âkingâ, âqueenâ and âroyalâ\n",
    "print(int2word[find_closest(word2int['canadian'], vectors)])\n",
    "print(int2word[find_closest(word2int['pharmaci'], vectors)])\n",
    "print(int2word[find_closest(word2int['covid19'], vectors)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "for word in words:\n",
    "    print(word, vectors[word2int[word]][1])\n",
    "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output\n",
    "\n",
    "-3.8947728\n",
    "face -15.572499\n",
    "anim 1.0498935\n",
    "analysi -27.109291\n",
    "market 22.697393\n",
    "ship 2.409625\n",
    "1000 16.15856\n",
    "could 9.423725\n",
    "critic 33.66415\n",
    "remot -1.252983\n",
    "leader 4.5464296\n",
    "tumult -13.851024\n",
    "afford -8.124293\n",
    "entertain -0.89187616\n",
    "warn -9.086381\n",
    "forc -7.2234974\n",
    "cap -25.375395\n",
    "respiratori -10.305653\n",
    "toxic 9.459612\n",
    "10000 33.244785\n",
    "spong -28.22298\n",
    "start 24.725822\n",
    "justin -29.294842\n",
    "anyth -17.52146\n",
    "basebal 28.959248\n",
    "initi 29.42309\n",
    "addit -10.913372\n",
    "brief 16.302504\n",
    "option -16.439035\n",
    "specialist 28.440205\n",
    "coronaviru 16.817432\n",
    "pressur 25.393217\n",
    "view -2.5587611\n",
    "ordersanyon -17.755936\n",
    "six 30.785965\n",
    "kanopi -1.4266641\n",
    "dispens 21.57296\n",
    "deputi 17.981155\n",
    "equal -1.5556762\n",
    "blast -10.843041\n",
    "stress -16.035044\n",
    "right -19.541338\n",
    "spiral 18.063726\n",
    "wish -11.98849\n",
    "treatment -31.669596\n",
    "biotech 26.972506\n",
    "whose -35.80998\n",
    "alcohol 6.4318314\n",
    "settl 0.11116588\n",
    "trick 19.133835\n",
    "journal 22.785318\n",
    "suppli 21.73817\n",
    "work 26.32507\n",
    "permanent 16.523457\n",
    "confin 29.671194\n",
    "break 27.993616\n",
    "attent -20.050459\n",
    "appear -5.8178678\n",
    "600 -9.580401\n",
    "world 17.346323\n",
    "show 31.455109\n",
    "late 32.553104\n",
    "urg -11.114392\n",
    "reason 30.615229\n",
    "chang -33.11709\n",
    "ongo 17.960701\n",
    "downtim 6.918359\n",
    "death 23.673939\n",
    "real -10.1678295\n",
    "15 6.459705\n",
    "indigen 5.1748877\n",
    "outsid 16.793238\n",
    "aid -33.100456\n",
    "prioriti 10.72185\n",
    "build -6.19005\n",
    "new 23.305\n",
    "wave -4.552723\n",
    "accord -5.7945614\n",
    "handl -18.53722\n",
    "player -18.449028\n",
    "fear -29.932814\n",
    "recal -7.2523494\n",
    "stockpil -34.20797\n",
    "steven -5.2140117\n",
    "activ -17.218107\n",
    "effect -5.9528055\n",
    "plasma -6.820815\n",
    "got -31.68079\n",
    "groceri -6.2828646\n",
    "took 25.35496\n",
    "herb 27.751522\n",
    "school -15.071505\n",
    "liber 32.577076\n",
    "provid 0.48099956\n",
    "academi -17.981722\n",
    "system -7.9690113\n",
    "chri 3.4714596\n",
    "whether -19.074064\n",
    "plu -33.59223\n",
    "rama 1.66822\n",
    "unparallel 22.030396\n",
    "confid -35.85128\n",
    "serious 3.6065392\n",
    "frequenc 1.5122845\n",
    "deliv 30.648716\n",
    "daili -18.07945\n",
    "medicin 9.691555\n",
    "told -34.343742\n",
    "cent -12.515008\n",
    "parti 6.5599093\n",
    "militari 11.418939\n",
    "assur -18.601418\n",
    "closer -35.06082\n",
    "abroad 20.77212\n",
    "wipe 3.5424101\n",
    "america -15.642555\n",
    "26 26.71067\n",
    "rule 4.8976274\n",
    "stori 4.9675593\n",
    "rather 31.700907\n",
    "thursday -15.517552\n",
    "countri -18.377651\n",
    "uber -33.360844\n",
    "flood 4.161202\n",
    "chines -15.07502\n",
    "guojian -7.276832\n",
    "program 4.5937657\n",
    "usual 19.12232\n",
    "recess -18.57307\n",
    "stay 16.364798\n",
    "hrefhttpstwittercomhashtagcovid19srchashamprefsrctwsrc5etfwcovid19a -15.826045\n",
    "away 2.6416929\n",
    "clinic 16.153465\n",
    "modifi 21.104181\n",
    "professor 13.609203\n",
    "23 0.5475135\n",
    "dr -28.544533\n",
    "arduou -21.093592\n",
    "via -25.529757\n",
    "colleg -7.9589224\n",
    "mutual 32.850803\n",
    "detect -14.391002\n",
    "someth -1.5780535\n",
    "hadfield -15.724577\n",
    "along 32.149727\n",
    "2000 -14.118692\n",
    "social -1.7205174\n",
    "must -17.4777\n",
    "either -7.8551292\n",
    "367 1.3996584\n",
    "match 2.6769483\n",
    "money -16.381195\n",
    "act -6.646839\n",
    "18775366837 28.494816\n",
    "youv -14.823979\n",
    "move 7.4113984\n",
    "differ 28.505821\n",
    "hrefhttpstwittercommountsinainycrefsrctwsrc5etfwmountsinainyca -18.377415\n",
    "minist -4.8454866\n",
    "hoard 17.616692\n",
    "fortun 2.2432811\n",
    "fight -19.75196\n",
    "pandem 16.249748\n",
    "soap -5.8119373\n",
    "addon -33.815514\n",
    "werent 31.607344\n",
    "greatest 32.458065\n",
    "chief -17.533113\n",
    "ever -3.5584967\n",
    "practic -1.9969277\n",
    "reveal -2.2101555\n",
    "showcas -25.922194\n",
    "tag -5.367168\n",
    "62 -18.013254\n",
    "latex -33.90543\n",
    "identifi -16.346977\n",
    "delay 8.912364\n",
    "jason -16.257595\n",
    "advertis 14.312098\n",
    "spring -7.7615986\n",
    "low -19.035254\n",
    "apart 22.99572\n",
    "reach -16.431496\n",
    "toronto 29.867691\n",
    "test 16.216919\n",
    "array 33.434837\n",
    "came 27.12673\n",
    "like 25.374546\n",
    "exist -32.648\n",
    "opportun -18.46584\n",
    "disinfect 8.601661\n",
    "maneuv 15.75424\n",
    "confront 31.294985\n",
    "territori 24.755753\n",
    "kid -2.8793895\n",
    "date -15.290702\n",
    "500 -20.949568\n",
    "infus 30.395721\n",
    "offici 0.5206058\n",
    "local -25.90369\n",
    "proven 29.734962\n",
    "need 23.562151\n",
    "recogn 1.2393029\n",
    "shortag 1.4261906\n",
    "primarili 4.46437\n",
    "us 20.738022\n",
    "say 25.030178\n",
    "lie -12.1113205\n",
    "phone 5.980362\n",
    "nation -18.386213\n",
    "place -12.425347\n",
    "member -14.507787\n",
    "visitor 23.279999\n",
    "fail -1.6972376\n",
    "distanc -14.240138\n",
    "capitol 9.671462\n",
    "indic -18.721016\n",
    "thing 9.457739\n",
    "month -11.505751\n",
    "ad -16.911913\n",
    "stairway -9.22552\n",
    "trust 26.276707\n",
    "recov -1.3804914\n",
    "tax -27.33242\n",
    "recreat -1.5652854\n",
    "europ 4.714832\n",
    "sheer -8.944153\n",
    "trillion 25.066608\n",
    "mediterranean -19.332047\n",
    "chronic 26.829876\n",
    "govern 2.1987731\n",
    "claim -14.970053\n",
    "pig -29.800701\n",
    "go -30.346943\n",
    "organ -19.54984\n",
    "march 19.418058\n",
    "canada 21.11102\n",
    "would 20.612234\n",
    "grow 32.779957\n",
    "measur 1.4026223\n",
    "annual 5.3779836\n",
    "entir 30.04874\n",
    "domin -14.088696\n",
    "httpswwwcbccanewsentertainmentfreefamilystreamingcovid19stayathome15509556 7.5320745\n",
    "tea -4.6992326\n",
    "cardiac -10.922562\n",
    "paid 28.698858\n",
    "near -18.204117\n",
    "therapist 18.23942\n",
    "size -8.60597\n",
    "promin -5.460238\n",
    "risk -33.25693\n",
    "hotspot 1.7265948\n",
    "york 11.529317\n",
    "sweep -4.938977\n",
    "strict 33.19513\n",
    "yukon 17.443993\n",
    "someon -18.454906\n",
    "20 -16.262749\n",
    "viru -5.558914\n",
    "arthriti -3.9727733\n",
    "drive 30.3938\n",
    "trial -33.926437\n",
    "ventil 27.491957\n",
    "mitig 5.0479207\n",
    "tadrou -17.076666\n",
    "driver 22.351284\n",
    "share 0.08465342\n",
    "furlough -3.3723373\n",
    "grim 0.12969416\n",
    "22 29.0373\n",
    "polic -13.798709\n",
    "compani 25.436533\n",
    "find 2.6911027\n",
    "import -2.68041\n",
    "inform -4.635953\n",
    "border 17.768269\n",
    "far 17.443775\n",
    "institut -2.6355493\n",
    "trevor -7.1767035\n",
    "avail 20.119516\n",
    "toll 16.71203\n",
    "progress 23.30644\n",
    "lawmak 27.457792\n",
    "riskiest -13.785322\n",
    "timet 8.806904\n",
    "amount -14.117776\n",
    "possibl -24.220577\n",
    "circul -14.931178\n",
    "lifetim -33.333652\n",
    "current -16.542831\n",
    "louisiana -6.005495\n",
    "mental -18.7818\n",
    "network 21.860498\n",
    "pelosi -25.626558\n",
    "though 3.6115518\n",
    "produc 0.878551\n",
    "mnuchin -18.406988\n",
    "20000 -11.885727\n",
    "nanci -25.963097\n",
    "crossbord 1.8401834\n",
    "wholesal -15.559371\n",
    "negoti -14.6727915\n",
    "firststag 23.551878\n",
    "nonessenti -11.521752\n",
    "product 15.479489\n",
    "expect -18.310598\n",
    "titl -20.017532\n",
    "univers -16.355003\n",
    "cuomo -4.197407\n",
    "alberta -28.425741\n",
    "pend -19.618538\n",
    "payrol 6.151725\n",
    "uncheck -29.204702\n",
    "kill -18.635353\n",
    "canadian 19.94369\n",
    "enact -19.276293\n",
    "polit -8.237077\n",
    "travel 26.902248\n",
    "desper 23.313187\n",
    "float 17.22472\n",
    "region -10.492998\n",
    "approv 14.796206\n",
    "loan -3.054853\n",
    "caution 32.23266\n",
    "economi 17.71659\n",
    "huge -27.986616\n",
    "process -6.5082216\n",
    "even -4.6037507\n",
    "assiniboin -25.640913\n",
    "alaska 5.837435\n",
    "inhal -32.89969\n",
    "individu 29.165283\n",
    "servic -5.079104\n",
    "weve 27.589882\n",
    "hrefhttpstcobpsb2husqrhttpstcobpsb2husqra -30.941404\n",
    "final 11.496814\n",
    "impact 2.0386727\n",
    "clean -1.4072748\n",
    "open 33.302288\n",
    "hydroxychloroquin 11.439013\n",
    "that -4.829257\n",
    "premier 17.12394\n",
    "blood 15.6708355\n",
    "close -31.733343\n",
    "last -18.31042\n",
    "emerg -12.7511015\n",
    "minor -8.204013\n",
    "controversi 16.057272\n",
    "classic 5.797779\n",
    "medic 1.2536595\n",
    "one 25.598104\n",
    "report 16.371956\n",
    "malaria -5.2234235\n",
    "payment -18.905922\n",
    "treasuri 30.77355\n",
    "unemploy 17.250877\n",
    "illeg -26.622173\n",
    "prescript -12.787328\n",
    "inflammatori 27.236485\n",
    "speaker -9.514521\n",
    "respons -1.3081603\n",
    "criteria 23.683147\n",
    "damag -16.342306\n",
    "certainli -15.140767\n",
    "hypertens 29.825144\n",
    "treat 14.620481\n",
    "8891kilometrelong -5.402519\n",
    "amid -15.941983\n",
    "riskier -1.3305794\n",
    "winnipeg -3.3831804\n",
    "increasingli 5.8020163\n",
    "retent -10.107691\n",
    "million 6.6984973\n",
    "investig -3.774707\n",
    "ocasiocortez -17.58061\n",
    "surfac -16.212107\n",
    "trudeau 20.085588\n",
    "use 32.079464\n",
    "laid 7.810582\n",
    "well 13.411316\n",
    "scatter -4.356191\n",
    "wealth -7.974658\n",
    "drugmak -9.57427\n",
    "news 4.5450816\n",
    "time -17.152477\n",
    "small -9.6388035\n",
    "set 1.0846041\n",
    "race 16.559793\n",
    "readili -26.202202\n",
    "research -27.32291\n",
    "prior -6.947305\n",
    "sourc 16.442179\n",
    "anoth -18.342169\n",
    "2400 -26.849384\n",
    "nearli 26.804974\n",
    "tradit -11.560839\n",
    "tension -17.200674\n",
    "written 3.860871\n",
    "offic 10.911667\n",
    "transfer -8.507994\n",
    "decad -12.514435\n",
    "rocket -8.660947\n",
    "disappoint -20.440636\n",
    "access 2.0908635\n",
    "coverag 7.6388507\n",
    "trip 18.667084\n",
    "strongli 10.676129\n",
    "effort -19.150816\n",
    "power -5.6368117\n",
    "case 21.211636\n",
    "billion -9.948006\n",
    "announc 11.562534\n",
    "abl -17.50064\n",
    "partner 32.63433\n",
    "secretari 32.103817\n",
    "space 31.642511\n",
    "faucet 0.48586193\n",
    "life 6.113346\n",
    "went -2.674951\n",
    "infect 25.652922\n",
    "fallout 8.567117\n",
    "tom 7.7804418\n",
    "third 28.632456\n",
    "director -9.109525\n",
    "80 -9.717181\n",
    "tend -19.607021\n",
    "precaut -12.160216\n",
    "avoid -26.596395\n",
    "engulf 28.344849\n",
    "north 19.567972\n",
    "washington -1.5562186\n",
    "imag -36.839283\n",
    "miss -11.289054\n",
    "conjunct -32.73305\n",
    "hiscox -8.655226\n",
    "tubi -12.842979\n",
    "democrat 3.7125235\n",
    "doctor -20.127865\n",
    "dental 3.7006128\n",
    "ground 15.512758\n",
    "275 -30.433779\n",
    "order -13.194137\n",
    "mice -12.688151\n",
    "sunday -13.423932\n",
    "present -34.14183\n",
    "meant -25.309553\n",
    "seen -18.869022\n",
    "huang 25.42939\n",
    "caus -5.8687363\n",
    "educ 15.788202\n",
    "benefit -14.34495\n",
    "think 25.698496\n",
    "worker 19.70712\n",
    "failur -13.601567\n",
    "acupunctur 23.224648\n",
    "behÃ§et -17.70636\n",
    "fiveday 28.206226\n",
    "airlin 0.7400691\n",
    "4 -12.35232\n",
    "peopl 16.857944\n",
    "acetaminophen 30.838657\n",
    "enrich 8.436592\n",
    "bureau 19.11621\n",
    "media -2.4767628\n",
    "part -3.6305208\n",
    "potenti 1.4640381\n",
    "soar -15.0428505\n",
    "guarante -9.471508\n",
    "onetim 9.439838\n",
    "pharmaci -20.315845\n",
    "lupu 31.432587\n",
    "roussycbc -9.014131\n",
    "wont 16.123583\n",
    "saskatoon 22.10305\n",
    "disrupt 3.423729\n",
    "purpos -17.713696\n",
    "unfold 2.9799395\n",
    "idl 28.615005\n",
    "associ -9.08896\n",
    "atop -14.4117985\n",
    "repurpos 0.7455985\n",
    "sensor 24.996725\n",
    "fund 25.563194\n",
    "pay -10.325695\n",
    "packag 19.600466\n",
    "provinci 1.7944487\n",
    "commun -16.70147\n",
    "involv -0.06718115\n",
    "mcgill 2.28947\n",
    "anybodi 19.193462\n",
    "commerc 18.114134\n",
    "children -14.95899\n",
    "ardent 3.6228259\n",
    "protect -35.020664\n",
    "relief 27.568869\n",
    "agenc 17.759882\n",
    "period 18.634798\n",
    "mayb -4.7147384\n",
    "cart -17.49977\n",
    "mlb 28.375269\n",
    "acceler 20.963974\n",
    "ask -20.624182\n",
    "gareth 25.832184\n",
    "troop 24.955914\n",
    "159 16.86389\n",
    "live -11.585336\n",
    "shot 5.08312\n",
    "cash 2.3218265\n",
    "stayathom 6.3452897\n",
    "child -1.215031\n",
    "elia -6.8393126\n",
    "particip -5.063104\n",
    "kaiser 28.417892\n",
    "white -32.74773\n",
    "china 17.03693\n",
    "craft -9.231749\n",
    "tukkercbc 8.064554\n",
    "congress -15.45315\n",
    "mani 10.0599785\n",
    "leagu -0.9899088\n",
    "actual -30.129282\n",
    "destin 25.80644\n",
    "game -31.313816\n",
    "physician 5.1861663\n",
    "rescu 4.920507\n",
    "ford -29.27632\n",
    "send 27.479183\n",
    "learn 28.1085\n",
    "wors -33.739296\n",
    "challeng -14.534145\n",
    "still -2.0695899\n",
    "clear -9.29977\n",
    "remov -16.09877\n",
    "17 -13.991721\n",
    "step 33.758762\n",
    "gig -5.2130976\n",
    "promis -8.12028\n",
    "cloth -4.2516284\n",
    "profession -31.001968\n",
    "respond 33.51765\n",
    "000 6.885783\n",
    "50 3.2419953\n",
    "infecti -2.964026\n",
    "rough 31.75429\n",
    "spent 23.008886\n",
    "uniqu -3.4245002\n",
    "squar 5.748646\n",
    "histor 0.6784004\n",
    "return 19.683466\n",
    "sombr 30.972498\n",
    "marri -29.646135\n",
    "intend -36.512665\n",
    "top -15.116587\n",
    "free -13.922956\n",
    "worri -27.444128\n",
    "believ -10.416401\n",
    "content -17.25126\n",
    "state 33.46067\n",
    "feder -19.055223\n",
    "enforc -2.5882108\n",
    "earn -6.9162116\n",
    "disclos -9.742575\n",
    "stimul 3.29236\n",
    "choos 6.142628\n",
    "grew 18.159847\n",
    "get 21.488766\n",
    "road -17.526188\n",
    "three 18.180328\n",
    "morn -13.076427\n",
    "manitoba -26.843935\n",
    "station 17.782831\n",
    "unlimit 24.616518\n",
    "dig -15.673651\n",
    "safeti -9.106284\n",
    "may -15.547993\n",
    "made 23.914413\n",
    "film 29.972021\n",
    "side -14.680193\n",
    "foolish -30.685654\n",
    "permit 7.95462\n",
    "job 21.46437\n",
    "demand -2.3249133\n",
    "andrew -24.162825\n",
    "seri 4.118215\n",
    "intern 16.57349\n",
    "idea 12.4947405\n",
    "colchicin -34.10447\n",
    "hidden 32.3176\n",
    "recent 30.71777\n",
    "today -13.223642\n",
    "expos -29.24593\n",
    "none -12.78919\n",
    "realiti -10.450256\n",
    "legisl 16.483448\n",
    "help 21.488348\n",
    "timelin 22.356125\n",
    "further -14.464768\n",
    "ont -22.135565\n",
    "optimist -12.8739\n",
    "sar -13.187524\n",
    "doorknob 30.176352\n",
    "lab -9.858175\n",
    "inclus 11.9714575\n",
    "sprawl 1.3591675\n",
    "latest -8.484853\n",
    "interview -33.06669\n",
    "peter -12.711999\n",
    "zone -15.945154\n",
    "intercept 10.1022005\n",
    "16 -17.719698\n",
    "alexandria -9.238867\n",
    "2nd 24.92055\n",
    "danger -8.9199915\n",
    "refillsnew 0.1466083\n",
    "studi 22.260529\n",
    "difficulti -17.035416\n",
    "implement -16.934446\n",
    "plastic -23.792915\n",
    "coronavirus 4.4263544\n",
    "click 1.2136499\n",
    "forth -16.833132\n",
    "publichealth -10.391845\n",
    "incent -8.150625\n",
    "lin -18.83995\n",
    "way 23.866896\n",
    "digit 33.97264\n",
    "ensur 30.867874\n",
    "duffin 31.266972\n",
    "paul -15.649566\n",
    "ryan 12.042307\n",
    "hill -25.355774\n",
    "quarantin -13.13255\n",
    "four -7.6349006\n",
    "covid19 18.344332\n",
    "exhaust 4.5867405\n",
    "spread -11.870212\n",
    "export 19.234625\n",
    "hope -18.223974\n",
    "theyr -17.240114\n",
    "eye 15.5648365\n",
    "antibodyrich 24.956993\n",
    "necessari -33.222885\n",
    "isol -6.804373\n",
    "unlik -13.460129\n",
    "among 16.327162\n",
    "selfisol 31.839714\n",
    "virus 3.8275561\n",
    "friday 5.3864594\n",
    "american 1.5239727\n",
    "internet 23.784576\n",
    "fever -18.992514\n",
    "talk 23.51098\n",
    "subscript 24.351318\n",
    "agent 0.7456504\n",
    "presid 29.976793\n",
    "porou -4.6514935\n",
    "insist 1.61358\n",
    "cough 17.395372\n",
    "senat 14.755989\n",
    "speed -6.961537\n",
    "water -19.963717\n",
    "stand 16.42913\n",
    "select -14.9763565\n",
    "long 25.808804\n",
    "volunt 5.544979\n",
    "goe -11.571717\n",
    "react 27.233957\n",
    "plasmapheresi -6.6998863\n",
    "stuff 30.563356\n",
    "adsupport -21.027283\n",
    "alreadi 20.635565\n",
    "releas -1.3038877\n",
    "control -1.7891725\n",
    "togeth -10.464483\n",
    "season 2.647071\n",
    "keep 23.590977\n",
    "adult -18.934694\n",
    "healthi -20.580042\n",
    "tell 24.264835\n",
    "employe 29.623692\n",
    "variou 1.334846\n",
    "regulatori -8.150837\n",
    "object 30.260185\n",
    "chamber -22.964468\n",
    "im -12.537375\n",
    "rise -15.6260195\n",
    "migrant 6.194014\n",
    "read 26.863983\n",
    "given -20.151218\n",
    "diseas 14.212749\n",
    "130 26.54631\n",
    "halt 10.528675\n",
    "dont -32.117283\n",
    "minnesota 23.251085\n",
    "slow -14.41109\n",
    "experiment 31.699501\n",
    "vast -21.986443\n",
    "sinc -27.039385\n",
    "later -13.250293\n",
    "origin 4.528752\n",
    "heavili -1.1339645\n",
    "drug -30.093702\n",
    "epidemiologist -33.36337\n",
    "gener 21.261997\n",
    "mouth -22.516342\n",
    "scientist -35.873505\n",
    "subscrib 4.737094\n",
    "larger -12.482239\n",
    "ka -3.9261026\n",
    "recommend 18.843178\n",
    "doug -19.647247\n",
    "antibiot -17.249355\n",
    "antibodi -16.374819\n",
    "afloat 16.075285\n",
    "toilet 2.8550787\n",
    "also 20.672037\n",
    "vulner -32.548874\n",
    "see -13.120522\n",
    "ban 33.431263\n",
    "subject 29.791315\n",
    "ottawa 30.45169\n",
    "best -12.205437\n",
    "anticip -21.21187\n",
    "much 3.9843097\n",
    "misgiv -6.95119\n",
    "conserv 0.660898\n",
    "coupl 2.0004418\n",
    "sport -12.3013735\n",
    "herd 20.390612\n",
    "inflamm 11.29848\n",
    "address 1.2051905\n",
    "context -26.786682\n",
    "queen -15.342745\n",
    "around 22.91658\n",
    "although -9.324275\n",
    "earli 5.9822173\n",
    "copleygetti 28.424747\n",
    "catalogu -16.895721\n",
    "writer -15.799599\n",
    "symptom -5.26743\n",
    "wednesday 5.244253\n",
    "bordercross -34.23805\n",
    "montreal -30.304932\n",
    "concern 19.15063\n",
    "tri 29.185349\n",
    "paychequ -2.4197903\n",
    "industri -7.688231\n",
    "sign 6.134816\n",
    "arent 27.364927\n",
    "freeland -34.784477\n",
    "drama -17.578344\n",
    "manufactur 11.111184\n",
    "remain 4.3483324\n",
    "becom -19.61015\n",
    "worldwid 34.01367\n",
    "pass -12.60759\n",
    "quickli 18.36034\n",
    "budget -13.933162\n",
    "6000 28.87408\n",
    "cbc -0.5986937\n",
    "platform 26.129534\n",
    "goahead -27.707893\n",
    "seriou -19.5339\n",
    "curiou -18.991585\n",
    "requir -10.158467\n",
    "salari -12.165679\n",
    "pharmaceut -18.890993\n",
    "expand 18.505241\n",
    "launch -11.064249\n",
    "safe -16.512468\n",
    "articl -15.061017\n",
    "allow -30.296923\n",
    "unauthor 24.05967\n",
    "mcconnel -14.80554\n",
    "action 15.632787\n",
    "811 -26.356482\n",
    "crisi -29.367746\n",
    "fingertip -11.899186\n",
    "kenney -7.4881864\n",
    "year -6.3183413\n",
    "45 -33.815784\n",
    "goal -6.741038\n",
    "residenti -9.245554\n",
    "restless -0.3423008\n",
    "come 2.450402\n",
    "daybreak 6.2411795\n",
    "india 8.033243\n",
    "interact -19.476255\n",
    "unnecessari 28.023136\n",
    "center 25.6469\n",
    "frequent -3.6357782\n",
    "expert -17.763004\n",
    "pharmacist -9.224574\n",
    "major -9.467506\n",
    "difficult 5.3674173\n",
    "mina -24.782946\n",
    "number -18.047256\n",
    "posit -15.072075\n",
    "supplier -13.66142\n",
    "scene -16.243608\n",
    "shut 4.4828553\n",
    "econom 31.867954\n",
    "copay -16.440952\n",
    "popul 11.821174\n",
    "retain -26.41266\n",
    "battl -9.307753\n",
    "drink 24.95379\n",
    "cannot 21.799768\n",
    "vaccin 17.66803\n",
    "public 23.523039\n",
    "eventu -5.0493736\n",
    "150000 11.814204\n",
    "begin -5.1323147\n",
    "trade -9.847184\n",
    "sick -3.5123818\n",
    "cover 31.386969\n",
    "track -11.5770645\n",
    "blend 26.81797\n",
    "mislead 4.4110937\n",
    "here 22.17565\n",
    "focus -20.241213\n",
    "outbreak 3.22317\n",
    "per 15.683399\n",
    "base -18.966576\n",
    "compli 19.06111\n",
    "14 -16.657051\n",
    "secur -4.1326256\n",
    "rheumatoid -36.39707\n",
    "ill -2.0389738\n",
    "second 26.279608\n",
    "cattl 29.944613\n",
    "whitehors 21.54646\n",
    "centuryold 8.104972\n",
    "astronaut -31.792763\n",
    "broad 28.730446\n",
    "8 27.615168\n",
    "4000 5.9088907\n",
    "unwash -29.632307\n",
    "includ 15.738359\n",
    "burden -35.552666\n",
    "quebec 28.910887\n",
    "spokesperson 18.724125\n",
    "prevent -17.98592\n",
    "april -28.35252\n",
    "fee 27.535082\n",
    "deal 5.777824\n",
    "especi 14.885817\n",
    "old 29.056107\n",
    "hurt 10.017166\n",
    "unclear -1.3694985\n",
    "request 23.889174\n",
    "rich 7.2149005\n",
    "back 33.600864\n",
    "essenti 29.069126\n",
    "misinform 10.14035\n",
    "glove 32.008663\n",
    "globe 34.785057\n",
    "encourag -34.277042\n",
    "parent -3.536217\n",
    "watch 3.7644677\n",
    "wasnt -29.145367\n",
    "expertis 33.435978\n",
    "prepar 10.283645\n",
    "despit -0.68040794\n",
    "herbal 16.936924\n",
    "propos -13.624949\n",
    "big -0.78120065\n",
    "13 21.351345\n",
    "sanit 2.8905737\n",
    "famili 7.733819\n",
    "anyon 31.139454\n",
    "refil 8.370261\n",
    "church 22.483494\n",
    "subsid -34.44644\n",
    "often 13.764066\n",
    "gov 28.65405\n",
    "lifesav -4.639816\n",
    "know -27.59845\n",
    "price -8.054366\n",
    "cure -29.481346\n",
    "monitor 0.61042094\n",
    "mount 1.0475926\n",
    "call -30.506243\n",
    "voic 5.099595\n",
    "unanim 14.831766\n",
    "meet -32.234203\n",
    "die 31.628153\n",
    "hasnt -35.461697\n",
    "despond -12.301587\n",
    "stop 14.90086\n",
    "short -31.722277\n",
    "bill 4.2003856\n",
    "administ 5.3417273\n",
    "comput -19.578548\n",
    "zarychanski -0.21901968\n",
    "might -32.34897\n",
    "lot 1.5671622\n",
    "limit 30.26902\n",
    "inexpens -30.355667\n",
    "smooth 3.2745845\n",
    "familyfriendli 26.140095\n",
    "attribut -18.723997\n",
    "breath -18.894825\n",
    "heart 0.36949787\n",
    "end 10.95723\n",
    "take -29.96544\n",
    "complic -18.103033\n",
    "knowledg -3.050934\n",
    "therapi -11.793388\n",
    "lung -17.852203\n",
    "certain 16.126308\n",
    "rapid -36.470036\n",
    "chain -0.77275074\n",
    "kingston -0.7317434\n",
    "documentari 28.66791\n",
    "signal -9.543333\n",
    "75000 5.5050864\n",
    "steer 26.053679\n",
    "relationship 29.910303\n",
    "mitch -18.396368\n",
    "hand 17.889376\n",
    "kilometr -12.469393\n",
    "ahead -8.72563\n",
    "nair 10.77036\n",
    "patch -1.6968119\n",
    "librari 33.811916\n",
    "make 5.173717\n",
    "matter -13.675254\n",
    "nose 3.0385387\n",
    "ontario 3.0072162\n",
    "largest 9.694927\n",
    "agreement -7.2701316\n",
    "sold -19.529985\n",
    "confirm -11.897038\n",
    "ingredi 17.147892\n",
    "bipartisan 14.044764\n",
    "scienc -30.571108\n",
    "1325 -27.245216\n",
    "ignor 6.285882\n",
    "full 28.405983\n",
    "oppos 20.146822\n",
    "hous 28.82809\n",
    "depth 23.73648\n",
    "trump 19.270702\n",
    "give 0.6376863\n",
    "client 30.96847\n",
    "mar 22.707613\n",
    "other 28.161776\n",
    "almost 21.076271\n",
    "histori -12.609159\n",
    "patient 1.3026972\n",
    "mind -7.947359\n",
    "1218 20.46387\n",
    "camera -18.869518\n",
    "wakeup 20.871012\n",
    "neutral -34.64673\n",
    "earlier -23.897842\n",
    "wide -6.950249\n",
    "gear -4.478115\n",
    "factori 2.2868881\n",
    "jacalyn -28.048223\n",
    "9 33.362488\n",
    "acupuncturist -8.176975\n",
    "magnitud -5.988417\n",
    "brinecbc -33.27124\n",
    "said 17.39328\n",
    "antiinflammatori -22.947401\n",
    "person -19.428497\n",
    "human 1.0708736\n",
    "donald -24.96009\n",
    "realli -30.17023\n",
    "exposur -27.117147\n",
    "25 -5.7458334\n",
    "half 4.743243\n",
    "creat 29.06485\n",
    "fals 24.280756\n",
    "particular 24.644295\n",
    "discuss 9.227274\n",
    "bethani -28.798447\n",
    "manag 31.334667\n",
    "newslett -10.167983\n",
    "reduc -3.3735647\n",
    "store -10.999636\n",
    "first -2.2421536\n",
    "lowwag -1.7452968\n",
    "seemingli -11.568828\n",
    "recruit 25.62768\n",
    "follow 17.88647\n",
    "instead -17.405798\n",
    "40 -31.37228\n",
    "brunswick 8.790305\n",
    "urgent -6.471865\n",
    "home -20.5244\n",
    "decis 6.060975\n",
    "leav -5.321039\n",
    "jeanclaud -14.657361\n",
    "mandatori -6.825587\n",
    "sooner -6.605658\n",
    "30day -10.321042\n",
    "estim 27.61538\n",
    "brennerreut 29.074606\n",
    "gout -28.299522\n",
    "site -30.819107\n",
    "command -7.1687274\n",
    "signatur -23.548916\n",
    "tardif 4.812214\n",
    "clerk 30.466366\n",
    "increas -30.816761\n",
    "visit 22.687803\n",
    "park 22.307154\n",
    "email 24.190449\n",
    "credit -13.54431\n",
    "week -30.555353\n",
    "spend -6.1079745\n",
    "coppercontain -7.6975765\n",
    "chrystia -19.266233\n",
    "irregular 5.5015306\n",
    "plenti -5.1321707\n",
    "highway 22.413334\n",
    "behind 29.070435\n",
    "1609 -14.774031\n",
    "60 27.938046\n",
    "question -7.1137476\n",
    "republican 1.6452045\n",
    "antimicrobi 34.40666\n",
    "1200 8.837398\n",
    "paper -28.604992\n",
    "provinc 0.5809646\n",
    "financ -18.38561\n",
    "enough -9.909388\n",
    "busi 24.163889\n",
    "whatev -2.5424306\n",
    "sight -19.674543\n",
    "your 18.52019\n",
    "replac -28.019009\n",
    "wash 21.883062\n",
    "sever 32.7655\n",
    "psycholog -24.89329\n",
    "swung 6.229654\n",
    "centr -4.050283\n",
    "least -15.235255\n",
    "piec 34.152798\n",
    "covidcbcca 9.591919\n",
    "sinai 15.828254\n",
    "direct -1.7521113\n",
    "introduc 19.7038\n",
    "distributor -21.228828\n",
    "foreign -5.485772\n",
    "food 2.229073\n",
    "surviv 30.724573\n",
    "chuck -6.7475853\n",
    "provis -10.015209\n",
    "transmiss -26.797262\n",
    "health 20.447643\n",
    "democraticcontrol -24.001017\n",
    "novel -2.789692\n",
    "hospit 21.681131\n",
    "prime -3.9378242\n",
    "patent -10.645904\n",
    "invinc -1.9859153\n",
    "heather -5.82365\n",
    "success 12.691189\n",
    "signific -6.309644\n",
    "pandemiccovid19 3.6164627\n",
    "schumer 34.168423\n",
    "metal 27.123547\n",
    "touch 18.728933\n",
    "underscor 8.796048\n",
    "known -32.88112\n",
    "sideeffect -5.6260023\n",
    "hrefhttpstcogpehoheem6pictwittercomgpehoheem6amdashicahnmountsinai -8.377054\n",
    "continu 3.2851818\n",
    "evict 28.703934\n",
    "look -13.939879\n",
    "longterm 0.16669647\n",
    "rush -12.778448\n",
    "guidelin 2.6124458\n",
    "develop -10.575764\n",
    "care 2.903183\n",
    "across -2.1147811\n",
    "defer -0.49456954\n",
    "vote 32.918488\n",
    "anywher 0.4651918\n",
    "880page -2.5608847\n",
    "day 23.556643\n",
    "mean -35.344666\n",
    "seattl 20.575691\n",
    "technolog -11.521113\n",
    "stream -17.302238\n",
    "offer 11.357911\n",
    "two -17.67875\n",
    "age 33.14762\n",
    "run 32.636024\n",
    "immun -14.33609\n",
    "sell 22.773413\n",
    "board 6.589963\n",
    "attend -8.9534855\n",
    "without 18.203278\n",
    "rep 22.762814\n",
    "passag -29.84073\n",
    "<Figure size 640x480 with 1 Axes>\n",
    "1\n",
    "â\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have is unsupervised.therefore, we employed the unsupervised Machine Learning Type. \n",
    "Deriving the structure from data where we dont know the effect of any of the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the content of the text, grouping the texts together in distinct folders. \n",
    "* Like cbc news text : in one folder.\n",
    "* Associated Press News text : in second folder\n",
    "* freelancer news : In 3rd Folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unsupervised Learning Technique on News.csv\n",
    "If the model can identify that these 30 to 40 texts are in regard to symptoms of COVID\n",
    "and other ones are in regard to economic effects of COVID in certain regions and then we can group them into certain\n",
    "bundles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification Problems: we use three main performance metrics.\n",
    "    1. Accuracy = No.of predicted correctly/Total number of observations\n",
    "    2. Precision = No. of predicted as cbc news that are actually cbc/total no. predicted as cbc\n",
    "    3. Recall = No. of predicted as cbc news that are actually cbc/ total no. that are actually cbc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier Attributes & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_estimator_type', '_get_param_names', '_get_tags', '_make_estimator', '_more_tags', '_required_parameters', '_set_oob_score', '_validate_X_predict', '_validate_estimator', '_validate_y_class_weight', 'apply', 'decision_path', 'feature_importances_', 'fit', 'get_params', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params']\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))\n",
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier through Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "# n_jobs=-1 : By building indiviual decision trees to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=5)\n",
    "# Hyperparameter n_splits = so there are 5 subsets. \n",
    "# In 1st itertion model will train on first 4 and evaluate the 5th subset.\n",
    "# In 2nd itertion model will train on 2,3,4,5 and evaluate the 1st subset and so on. ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "      <td>[senat, late, wednesday, pass, unparallel, 22,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "      <td>[scientists, around, world, racing, find, nove...</td>\n",
       "      <td>[scientist, around, world, race, find, novel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "      <td>[, trudeau, says, rules, quarantine, act, enfo...</td>\n",
       "      <td>[, trudeau, say, rule, quarantin, act, enforc,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3               cbc  Coronavirus: The latest in drug treatment and ...   \n",
       "4               cbc  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  Â    Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "3  [scientists, around, the, world, are, racing, ...   \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "2  [senate, late, wednesday, passed, unparalleled...   \n",
       "3  [scientists, around, world, racing, find, nove...   \n",
       "4  [, trudeau, says, rules, quarantine, act, enfo...   \n",
       "\n",
       "                                   body_text_stemmed  \n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...  \n",
       "1  [yukon, govern, identifi, two, place, whitehor...  \n",
       "2  [senat, late, wednesday, pass, unparallel, 22,...  \n",
       "3  [scientist, around, world, race, find, novel, ...  \n",
       "4  [, trudeau, say, rule, quarantin, act, enforc,...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/washingtongold/fake-vs-real-news/data\n",
    "# https://www.kaggle.com/ryanxjhan/cbc-news-coronavirus-articles-march-26\n",
    "\n",
    "true = pd.read_csv('True.csv')\n",
    "false = pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Yearâ...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obamaâs Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Yearâ...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obamaâs Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "true['true'] = 1\n",
    "false['true'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  true  \n",
       "0  December 31, 2017      1  \n",
       "1  December 29, 2017      1  \n",
       "2  December 31, 2017      1  \n",
       "3  December 30, 2017      1  \n",
       "4  December 29, 2017      1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([true,false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(sentence):\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_news = pd.read_csv('news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_news['cleaned'] = corona_news['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ''.join(data['cleaned'].tolist()).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list1\n",
    "# So this list has the text of true and false news i.e the real news and fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
