{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news.csv', delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>2020-03-27 08:00:00</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>https://www.cbc.ca/news/health/covid-19-drug-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>2020-03-27 01:45:00</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/north/yukon-cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Associated Press']</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>2020-03-26 05:13:00</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>https://www.cbc.ca/news/world/senate-coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>2020-03-27 00:36:00</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>https://www.cbc.ca/news/health/coronavirus-tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>2020-03-26 20:57:00</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>https://www.cbc.ca/news/the-latest-on-the-coro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   authors  \\\n",
       "0           0              ['Cbc News']   \n",
       "1           1              ['Cbc News']   \n",
       "2           2  ['The Associated Press']   \n",
       "3           3              ['Cbc News']   \n",
       "4           4              ['Cbc News']   \n",
       "\n",
       "                                               title         publish_date  \\\n",
       "0  Coronavirus a 'wake-up call' for Canada's pres...  2020-03-27 08:00:00   \n",
       "1  Yukon gov't names 2 possible sources of corona...  2020-03-27 01:45:00   \n",
       "2  U.S. Senate passes $2T coronavirus relief package  2020-03-26 05:13:00   \n",
       "3  Coronavirus: The latest in drug treatment and ...  2020-03-27 00:36:00   \n",
       "4  The latest on the coronavirus outbreak for Mar...  2020-03-26 20:57:00   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.cbc.ca/news/health/covid-19-drug-s...  \n",
       "1  https://www.cbc.ca/news/canada/north/yukon-cor...  \n",
       "2  https://www.cbc.ca/news/world/senate-coronavir...  \n",
       "3  https://www.cbc.ca/news/health/coronavirus-tre...  \n",
       "4  https://www.cbc.ca/news/the-latest-on-the-coro...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3566, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3566.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2455.649748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1298.529450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1473.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2496.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3569.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4608.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  3566.000000\n",
       "mean   2455.649748\n",
       "std    1298.529450\n",
       "min       0.000000\n",
       "25%    1473.250000\n",
       "50%    2496.500000\n",
       "75%    3569.750000\n",
       "max    4608.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 0\",'publish_date','url'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['The Associated Press']</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    authors  \\\n",
       "0              ['Cbc News']   \n",
       "1              ['Cbc News']   \n",
       "2  ['The Associated Press']   \n",
       "3              ['Cbc News']   \n",
       "4              ['Cbc News']   \n",
       "\n",
       "                                               title  \\\n",
       "0  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1  Yukon gov't names 2 possible sources of corona...   \n",
       "2  U.S. Senate passes $2T coronavirus relief package   \n",
       "3  Coronavirus: The latest in drug treatment and ...   \n",
       "4  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4      Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['authors'] = df['authors'].str.strip('[]')\n",
    "df['authors'] = df['authors'].str.strip('  ''')\n",
    "df['authors'] = df.authors.str.replace(\"[({':]\", \"\")\n",
    "df['authors'] = df['authors'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              cbc news  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              cbc news  Yukon gov't names 2 possible sources of corona...   \n",
       "2  the associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              cbc news  Coronavirus: The latest in drug treatment and ...   \n",
       "4              cbc news  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4      Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cbc News', 'The Associated Press',\n",
       "       'Mark Gollom Is A Toronto-Based Reporter With Cbc News. He Covers Canadian, U.S. Politics, Current Affairs.',\n",
       "       'Thomson Reuters',\n",
       "       'Leah Hendry Is A Tv, Radio, Online Journalist With Cbc Montreal Investigates. Contact Her Via Our Confidential Tipline, Or On Email At Montrealinvestigates Cbc.Ca., Follow Leah On Twitter',\n",
       "       'Reporter, Web Writer For Cbc Saskatoon, Story Tips, Ideas Welcomed At Guy.Quenneville Cbc.Ca, Follow Guy On Twitter',\n",
       "       'Jorge Barrera Is A Caracas-Born, Award-Winning Journalist Who Has Worked Across The Country, \"Internationally. He Works For CbcS Indigenous Unit Based Out Of Ottawa. Follow Him On Twitter\", Jorgebarrera Or Email Him Jorge.Barrera Cbc.Ca., Follow, Jorgebarrera On Twitter',\n",
       "       'Colleen M. Flood Is Director Of The Centre For Health Law, Policy, Ethics, University Research Chair At The University Of Ottawa.',\n",
       "       'Producer, Cbc News Business, James Dunne Researches, Produces, Writes Stories For The Business Unit At Cbc News. He Has A Decade Of Experience In Business Programming, Including On The Shows Venture, Fortune Hunters. An Award-Winning Videojournalist, \"HeS Also Worked On Special Projects\", As The Late Lineup Editor For The World At Six On Cbc Radio One., James Dunne On Linkedin',\n",
       "       'Dan Mcgarvey Is A Mobile Journalist Focused On Filing Stories Remotely For Cbc Calgary S Web, Radio, Tv, Social Media Platforms, Only Using An Iphone, Mobile Tech. You Can Email Story Ideas, Tips To Dan At, Dan.Mcgarvey Cbc.Ca Or Tweet Him',\n",
       "       'Cbc News New York, \"Steven DSouza Is A Gemini-Nominated Journalist Based In New York City. He Has Reported Internationally The Papal Conclave In Rome\", The World Cup In Brazil, He Spent Eight Years In Toronto Covering Stories Like The Protests, The Rob Ford Crack Video Scandal.',\n",
       "       '',\n",
       "       'Investigative Reporter, Cbc Manitoba I-Team, Caroline Began Her Career Co-Hosting An Internet Radio Talk Show In Toronto, Then Worked At Various Stations In Oshawa, Sudbury, Toronto Before Landing In Winnipeg In Since Joining Cbc Manitoba As A Reporter In, She Has Won An Award For Her Work On Crowded Jails, \"Her Investigation Into Tina FontaineS Death Led To Changes In The Child Welfare System. Email\", Caroline.Barghout Cbc.Ca, Twitter',\n",
       "       'Hadeel Ibrahim Is A Cbc Reporter Based Out Of Saint John. She Can Be Reached At Hadeel.Ibrahim Cbc.Ca',\n",
       "       'Science, Technology Writer, Emily Chung Covers Science, Technology For Cbc News. She Has Previously Worked As A Digital Journalist For Cbc Ottawa, \"As An Occasional Producer At CbcS Quirks\", Quarks. She Has A Phd In Chemistry.',\n",
       "       'Investigative Journalist, \"Timothy Sawa Works For CbcS Investigative Unit\", The Fifth Estate, Has Been An Investigative Journalist At Cbc News For More Than A Decade. He Has Produced Investigations Looking At Police Corruption, Sexual Abuse In Public Institutions, Offshore Tax Evasion., Cbc News Investigates',\n",
       "       'Sam Samson Is A Multimedia Journalist Who Has Worked For Cbc In Manitoba, Ontario As A Reporter, Associate Producer. Before Working For Cbc, She Studied Journalism, Communications In Winnipeg. You Can Get In Touch On Twitter, Cbcsamsamson Or Email Samantha.Samson Cbc.Ca.',\n",
       "       'Senior Writer, Pete Evans Is The Senior Business Writer For Cbcnews.Ca. Prior To Coming To The Cbc, His Work Has Appeared In The Globe, Mail, The Financial Post, The Toronto Star, Canadian Business Magazine, Believe It Or Not, Circuits Assembly Magazine., Twitter',\n",
       "       'Business Reporter, Sophia Harris Covers Business, Consumer News., Contact, Sophia.Harris Cbc.Ca, More This Author',\n",
       "       'The Canadian Press',\n",
       "       'Andrea Bellemare Is A Reporter, Producer With Cbc News Who Currently Focuses On Disinformation, Tech, Privacy., She Helped Launch The New Cbc Kitchener-Waterloo Radio Station In, Reported For Cbc Montreal, Produced Radio Docs For Cbc Radio. She Has Also Reported For The Wire Service Agence France-Presse.',\n",
       "       'Web Writer, \"Creeden Martell Is A Cree Journalist The Waterhen Lake First Nation. He Works For Cbc Saskatchewan In Regina. He Has Also Written For The University Of ReginaS Jschool\", The Saskatoon Starphoenix, Vice News., Twitter',\n",
       "       'Reporter The Canadian Press, Stephanie Taylor Is A Canadian Press Reporter Based In Saskatchewan.',\n",
       "       'Asia Correspondent, \"Saša Petricic Is The CbcS Asia Correspondent\", Based In Beijing. He Has Covered China As Well As Reported North, South Korea. He Previously Reported On The Middle East, Jerusalem, Through The Arab Spring, The Syrian Civil War. He Has Filed Stories Every Continent For Cbc News. Instagram, More Saša Petricic',\n",
       "       'American Politics Contributor, Keith Boag Writes About American Politics, Issues That Shape The American Experience. Keith Was Based For Several Years In Los Angeles, Now, In Retirement After A Long Career With Cbc News, Continues To Live In Washington, D.C. Earlier, Keith Reported Ottawa, Where He Served As Chief Political Correspondent For Cbc News.',\n",
       "       'Video Journalist, \"Colin Butler Is A Veteran Cbc Reporter WhoS Worked In Moncton\", Saint John, Fredericton, Toronto, Kitchener-Waterloo, Hamilton, London, Ont. Email, Colin.Butler Cbc.Ca',\n",
       "       'Nicholas Frew Is An Online Reporter Based In Winnipeg. Hailing Newfoundland, Frew Moved To Halifax To Attend Journalism School Before Moving To Winnipeg. Prior To Joining Cbc Manitoba, Frew Interned At The Winnipeg Free Press. Story Idea, Email At Nick.Frew Cbc.Ca, Email, Nick.Frew Cbc.Ca, Twitter',\n",
       "       'Senior Reporter, Julie Ireton Is A Senior Reporter Who Works On Investigations, \"Enterprise News Features At Cbc Ottawa. SheS Also The Host Of The New Cbc Investigative Podcast\", The Band Played On. You Can Reach Her At Julie.Ireton Cbc.Ca',\n",
       "       'Sarah Rieger Joined Cbc Calgary As An Online Journalist In You Can Reach Her Email At Sarah.Rieger Cbc.Ca., Follow Sarah On Twitter, Read More Articles Sarah',\n",
       "       'Winnipeg Free Press',\n",
       "       'Defence, Murray Brewster Is Senior Defence Writer For Cbc News, Based In Ottawa. He Has Covered The Canadian Military, Foreign Policy Parliament Hill For Over A Decade. Among Other Assignments, He Spent A Total Of Months On The Ground Covering The Afghan War For The Canadian Press. Prior To That, He Covered Defence Issues, Politics For Cp In Nova Scotia For Years, Was Bureau Chief For Standard Broadcast News In Ottawa., Follow, Murray_Brewster On Twitter',\n",
       "       'Host Of Afternoon Drive, \"Chris Dela Torre Is The Host Of Afternoon Drive On Cbc Radio One In Southwestern Ontario. HeS Worked As A Host\", Reporter, Producer In Several Cities Across Canada, Has Hosted Several Cbc Network Programs, Such As Q, Dnto, The Story Here.',\n",
       "       'Politics, Éric Grenier Is A Senior Writer, \"The CbcS Polls Analyst. He Was The Founder Of Threehundredeight.Com\", Has Written For The Globe, Mail, Huffington Post Canada, The Hill Times, Le Devoir, L Actualité., Read More Cbcnews.Ca Columns Éric Grenier',\n",
       "       'Tory Gillis Began Work As A Journalist With Cbc Saskatchewan In You Can Hear Her Deliver The Afternoon News On Weekdays On Cbc Radio One In Saskatchewan. She Has Also Worked As A Reporter, \"As An Associate Producer On Cbc SaskatchewanS Radio Shows\", The Morning Edition, Bluesky, The Afternoon Edition.',\n",
       "       'Senior Writer, \"Adam Miller Is Senior Digital Writer With Cbc News. HeS Covered Health\", Politics, Breaking News Extensively In Canada, In Addition To Several Years Reporting On News, Current Affairs Throughout Asia.',\n",
       "       'Dan Zakreski Is A Reporter For Cbc Saskatoon.',\n",
       "       'Moscow Correspondent, Chris Brown Is A Foreign Correspondent Based In The Cbc S Moscow Bureau. Previously A National Reporter For Cbc News On Radio, Tv, Online, Chris Has A Passion For Great Stories, Has Travelled All Over Canada, The World To Find Them.',\n",
       "       'Senior Producer Western Digital Business Unit, \"Tony Seskus Is Senior Producer With CbcS Western Business Unit In Calgary. HeS Written For Newspapers\", Wire Services For More Than Years On Three Continents. In Calgary, Tony Has Reported On The Energy Sector, Federal Politics.',\n",
       "       'Ian Froese Is A Reporter With Cbc Manitoba. He Has Previously Worked For Newspapers In Brandon, Steinbach. Story Idea, Email, Ian.Froese Cbc.Ca., Twitter',\n",
       "       'Reporter Associate Producer, Emily Pasiuk Is A Reporter For Cbc Saskatchewan, \"An Associate Producer For The Morning Edition. SheS Based In Regina. She Has Also Reported At Ctv Saskatoon\", Written For Global Regina. Reach Her At Emily.Pasiuk Cbc.Ca., Find Her On Twitter',\n",
       "       'Jim Agapito Is A Filipino Filmmaker Winnipeg. Jim Writes, Boxes, Takes Photos, Sings In A Punk Band.',\n",
       "       'Reporter Editor, Darren Bernhardt Spent The First Dozen Years Of His Journalism Career In Newspapers, First At The Regina Leader-Post Then The Saskatoon Starphoenix. He Has Been With Cbc Manitoba Since, Specializes In Offbeat, Local History Stories, Features. Story Idea, Email, Darren.Bernhardt Cbc.Ca',\n",
       "       'Senior Writer, \"Kathleen Harris Is A Senior Writer In The CbcS Parliament Hill Bureau. She Covers Politics\", Immigration, Justice, Follow Her On Twitter',\n",
       "       'Cbc Communications',\n",
       "       'Sarah Leavitt Is A Journalist With Cbc Montreal., Follow Sarah On Twitter',\n",
       "       'Cbc Investigative Journalist, Jonathon Gatehouse Has Covered News, Politics At Home, Abroad, Reporting Dozens Of Countries. He Has Also Written Extensively About Sports, Covering Seven Olympic Games, Authoring A Best-Selling Book On The Business Of Pro-Hockey. He Works For The National Investigative Unit In Toronto.',\n",
       "       'Reporter Editor, Bobhristova Is A Reporter Editor With Cbc Hamilton. Email, Bobby.Hristova Cbc.Ca, Follow, Bobbyhristova On Twitter',\n",
       "       'Rafferty Baker Is A Video Journalist With Cbc News, Based In Vancouver. You Can Find His Stories On Cbc Radio, Television, Online At Cbc.Ca Bc.',\n",
       "       'Adam Carter Is A Newfoundlander Who Now Calls Toronto Home. He Enjoys A Good Story, Playing Loud Music. You Can Follow Him On Twitter, Adamcartercbc Or Drop Him An Email At Adam.Carter Cbc.Ca.',\n",
       "       'Lenard Monkman Is Anishinaabe Lake Manitoba First Nation, Treaty Territory. He Is The Co-Founder Of Red Rising Magazine, \"Has Been An Associate Producer With The CbcS Indigenous Unit For Three Years. Follow Him On Twitter\"',\n",
       "       'Briar Stewart Is A Senior Reporter With Cbc News., For More Than A Decade, She Has Been Covering Stories For Television, Radio, Online., She Is Based In Vancouver, Can Be Reached At Briar.Stewart Cbc.Ca, Or On Twitter',\n",
       "       'Web Writer, Sam Juric Is A Journalist With Cbc P.E.I., Can Be Reached At Samantha.Juric Cbc.Ca.',\n",
       "       'Provincial Affairs Reporter Covering The B.C. Legislature. Anything Political, Tanya.Fletcher Cbc.Ca',\n",
       "       'Provincial Affairs Reporter, Mike Crawley Is Provincial Affairs Reporter In Ontario For Cbc News. He Has Won Awards For His Reporting On The Ehealth Spending Scandal, \"Flaws In OntarioS Welfare-Payment Computer System. Before Joining The Cbc In\", Mike Filed Stories Countries In Africa As A Freelance Journalist, Worked As A Newspaper Reporter In B.C., Twitter',\n",
       "       'Natalia Is A Multi-Platform Journalist In Ottawa. She Has Also Worked For Cbc In P.E.I., Newfoundland',\n",
       "       'Parliamentary Bureau, John Paul, J.P., \"Tasker Is A Reporter In The CbcS Parliamentary Bureau In Ottawa. He Can Be Reached At John.Tasker Cbc.Ca.\", Follow J.P. On Twitter',\n",
       "       'Cbc Staff, Alvin Yu Splits His Time Along The Corridor As A Reporter For Cbc London, Associate Producer For Cbc Toronto, The National. Yu Set His Sights On Journalism Early - As A Kid He Would Anchor The News In The Shower, Hoping One Day To Make It To The Big Screen.',\n",
       "       'Reporter Editor, \"Elizabeth Fraser Is A Reporter Editor With Cbc New Brunswick Based In Fredericton. SheS Originally Manitoba. Story Tip\", Elizabeth.Fraser Cbc.Ca',\n",
       "       'Sanjay Maru Is A Reporter At Cbc Windsor. Email Him At Sanjay.Maru Cbc.Ca.',\n",
       "       'Yvette Brend Is A Cbc Vancouver Journalist. Yvette.Brend Cbc.Ca',\n",
       "       'Rachel Ward Is A Journalist With Cbc Calgary. You Can Reach Her With Questions Or Story Ideas At Rachel.Ward Cbc.Ca., Follow Rachel On Twitter',\n",
       "       'Adam Hunter Is The Provincial Affairs Reporter At Cbc Saskatchewan, Based In Regina. He Has Been With Cbc For Years. He Hosts The Cbc Podcast On The Ledge. Follow Him On Twitter, Ahiddycbc. Contact Him, Adam.Hunter Cbc.Ca',\n",
       "       'Medical Science, Kelly Crowe Is A Science Correspondent For Cbc News. She Joined Cbc In, Has Spent Years Reporting On A Wide Range Of National News, Current Affairs, With A Particular Interest In Science',\n",
       "       'Cbc News, \"David Cochrane Is A Senior Reporter In CbcS Parliamentary Bureau. He Previously Wrote For Cbc Newfoundland\", Follow David Cochrane On Twitter, Read More Articles David Cochrane',\n",
       "       'Paul Withers Is An Award-Winning Journalist Whose Career Started In The As A Cartoonist. He Has Been Covering Nova Scotia Politics For More Than Years.',\n",
       "       'Alex Soloducha Is A Reporter For Cbc Saskatchewan.',\n",
       "       'Brian Rodgers Is A Videojournalist, Producer With Cbc Saskatchewan.',\n",
       "       'Joe Tunney Reports For Cbc News In Ottawa. He Can Be Reached At Joe.Tunney Cbc.Ca',\n",
       "       'Shane Magee Is A Moncton-Based Reporter For Cbc.',\n",
       "       'Jonathan Montpetit Is A Journalist With Cbc Montreal., Follow Him On Twitter',\n",
       "       'Holly Conners Is A Reporter, Current Affairs Producer Who Has Been With Cbc Cape Breton Since, Contact Her At Holly.Conners Cbc.Ca.',\n",
       "       'Prince Edward Island, Wayne Thibodeau Is A Reporter Editor With Cbc Prince Edward Island. He Has Worked As A Reporter, Editor, Photographer, Video Journalist In Print, Digital, Tv For More Than Years. He Can Be Reached At Wayne.Thibodeau Cbc.Ca, Follow, Jwaynecbc On Twitter',\n",
       "       'Shaina Luck Covers Everything Court To City Council. Her Favourite Stories Are About Ordinary People In Extraordinary Circumstances. Email, Shaina.Luck Cbc.Ca',\n",
       "       'Bill Graveland Is A Calgary-Based Reporter For The Canadian Press.',\n",
       "       'Tony Davis Grew Up On P.E.I., Studied Journalism At Holland College. He Can Be Contacted At Anthony.Davis Cbc.Ca',\n",
       "       'Renée Is A Cbc Correspondent Based In London, U.K., She Has Spent A Decade With The Organization In A Number Of Roles, Including Senior Business Reporter, Weekend News Anchor, Television, Radio Reporter, Associate Producer, Program Director',\n",
       "       'Bridget Yard Is A Video Journalist Based In Saskatoon. She Has Also Worked For Cbc In Fredericton, Bathurst, Follow Bridget On Twitter',\n",
       "       'Nicola Macleod Is A Reporter With Cbc In P.E.I.',\n",
       "       'Cbc Reporter, Brady Strachan Is A Cbc Reporter Based In Kelowna, B.C. Besides Kelowna, Strachan Has Covered Stories For Cbc News In Winnipeg, Brandon, Vancouver, Internationally. Follow His Tweets',\n",
       "       'Business Columnist, Don Pittis Was A Forest Firefighter, \"A Ranger In CanadaS High Arctic Islands. After Moving Into Journalism\", He Was Principal Business Reporter For Radio Television Hong Kong Before The Handover To China. He Has Produced, Reported For The Cbc In Saskatchewan, Toronto, \"The Bbc In London. He Is Currently Senior Producer At CbcS Business Unit.\", More Don Pittis',\n",
       "       'Reporter Editor, Alex Is A Reporter Living In Halifax. Send Her Story Ideas At Alex.Cooke Cbc.Ca.',\n",
       "       'Preston Mulligan Has Been A Reporter In The Maritimes For More Than Years. Along With His Reporting Gig, \"He Also Hosts Cbc RadioS Sunday Phone-In Show\", Maritime Connection.',\n",
       "       'Erik White Is A Cbc Journalist Based In Sudbury. He Covers A Wide Range Of Stories About Northern Ontario. Connect With Him On Twitter, Erikjwhite. Send Story Ideas To Erik.White Cbc.Ca',\n",
       "       'Associate Producer Technician, Danelle Cloutier Is An Associate Producer, Audio Technician In Current Affairs At Cbc Manitoba. She Has A Background In Audio Engineering',\n",
       "       'Alanna Petroff Is A Freelance Reporter Based In London. She Has Covered Business, Economic, International News For The Past Decade At Outlets Such As Reuters, Cnn, The Bbc.',\n",
       "       'Lien Yeung Hosts Cbc Vancouver News Weekends. As A Multimedia Reporter, She Has Covered Stories Locally, Nationally Coast To Coast On Television, Radio, Social Media. You Can Reach Her On Instagram Or Twitter, Lienyeung Or Via Email At Lien.Yeung Cbc.Ca.',\n",
       "       'Jason Viau Is A Video Journalist, Tv Host, Radio Newsreader At Cbc Windsor. He Was Born In North Bay, But Has Lived In Windsor For Most Of His Life. Since Graduating St. Clair College, \"HeS Worked In Print\", Tv, Radio. Email Him At Jason.Viau Cbc.Ca, Follow Jason On Twitter',\n",
       "       'Jack Julian Joined Cbc Nova Scotia As An Arts Reporter In His News Career Began On The Morning Of Sept., Following The Crash Of Swissair He Is Now A Data Journalist In Halifax, You Can Reach Him At, Email At Jack.Julian Cbc.Ca Or Follow Him On Twitter',\n",
       "       'Health Writer, Amina Zafar Has Covered Health, Medical, Science News At Cbc Since She Has A Degree In Environmental Science, \"A MasterS In Journalism.\"',\n",
       "       'Reporter Editor, Tom Ayers Has Been A Reporter, Editor For More Than Years. He Has Spent The Last Years Covering Cape Breton, Nova Scotia Stories. You Can Reach Him At Tom.Ayers Cbc.Ca.',\n",
       "       'City Hall Reporter, Lauren Pelley Is A Cbc Reporter In Toronto Covering City Hall, Municipal Affairs. Contact Her At, Lauren.Pelley Cbc.Ca',\n",
       "       'Mandy Luk Is A Senior Producer With Cbc News. She Holds A Journalism Degree The Chinese University Of Hong Kong, \"A MasterS Degree In Economics The University Of Toronto. Programs She Has Worked For Include Cbc News Network\", The National, Cross Country Checkup.',\n",
       "       'Dr. Vivek Goel Was The Founding Head Of Public Health Ontario, Set Up In Response To The Sars Crisis. He Is Currently A Professor At The University Of Toronto S Dalla Lana School Of Public Health, Vice-President Of Research, Innovation, Strategic Initiatives At U Of T.',\n",
       "       '\"Rosemary Barton Is CbcS Chief Political Correspondent\", Based In Ottawa.',\n",
       "       'Senior Reporter, Bonnie Allen Is A Senior Reporter For Cbc News Based In Saskatchewan. Before Returning To Canada In, Allen Spent Four Years Reporting Across Africa, Including Libya, South Sudan, Liberia, \"Sierra Leone. She Holds A MasterS In International Human Rights Law The University Of Oxford.\"',\n",
       "       'Joel Ballard Is A Reporter With The Cbc In Vancouver. You Can Reach Him At Joel.Ballard Cbc.Ca',\n",
       "       'Franca G. Mignacca Is A Journalist At Cbc Montreal.',\n",
       "       'Cbc Investigates, Katie Nicholson Is A Senior Reporter With Cbc Investigates Based In Toronto.',\n",
       "       'Alicia Bridges Is A Digital, Broadcast Journalist At Cbc Saskatoon. Email Her At Alicia.Bridges Cbc.Ca.',\n",
       "       'Taryn Grant Is A Halifax-Based Reporter For Cbc Nova Scotia. Get In Touch With Her Email At Taryn.Grant Cbc.Ca',\n",
       "       'Anjuli Patil Is A Reporter, \"Occasional Video Journalist With Cbc Nova ScotiaS Digital Team.\"',\n",
       "       '\"Ryan Cooke Works For Cbc Out Of Its Bureau In St. JohnS.\", Read More Articles This Author',\n",
       "       'Producer, The Fifth Estate, Scott Anderson Is A Producer At The Fifth Estate. He Has Been An Investigative Journalist In Both Print, Broadcast. He Has Covered Stories At City Hall, Across The Country, Around The World.',\n",
       "       'Angela Gemmill Is A Cbc Journalist Who Has Covered News In Sudbury, Ont., For Years. Connect With Her On Twitter, Angelagemmill. Send Story Ideas To Angela.Gemmill Cbc.Ca',\n",
       "       'Drew Anderson Is A Web Journalist At Cbc Calgary. Like Almost Every Journalist Working Today, \"HeS Won A Few Awards. HeS Also A Third-Generation Calgarian.\", You Can Follow Him On Twitter, Drewpanderson. Contact Him In Confidence At Drew.Anderson Cbc.Ca. Signal Contact Upon Request. Cbc Secure Drop, Www.Cbc.Ca Securedrop',\n",
       "       'Joel Joined Cbc Calgary In Reach Him Email At Joel.Dryden Cbc.Ca, Follow Joel On Twitter',\n",
       "       'Ap Journalist, Heidi Atter Is A Journalist Working In Regina. She Started With Cbc Saskatchewan After A Successful Internship, Has A Passion For Character-Driven Stories. Heidi Has Worked As A Reporter, Web Writer, Associate Producer, Show Director So Far, Has Worked In Edmonton, At The Wainwright Military Base, In Adazi, Latvia. Story Ideas',\n",
       "       'Investigative Reporter, Jennie Russell Is A Reporter With Cbc Investigates, The Award-Winning Investigative Unit Of Cbc Edmonton. Jennie Specializes In Accountability Journalism, Her Work Has Been Widely Credited With Forcing Transparency, Democratic Change In Alberta. Contact Jennie At Jennie.Russell Cbc.Ca, Follow Her On Twitter',\n",
       "       'Parliament Hill Bureau, Aaron Wherry Has Covered Parliament Hill Since, \"Has Written For MacleanS\", The National Post, The Globe, Mail. He Is The Author Of Promise, Peril, \"A Book About Justin TrudeauS Years In Power.\", Follow Aaron On Twitter',\n",
       "       'Bryce Hoye Is An Award-Winning Journalist, Science Writer With A Background In Wildlife Biology, Interests In Courts, Social Justice, Health, More. He Is The Prairie Rep For Outcbc. Story Idea, Email Bryce.Hoye Cbc.Ca., Email, Bryce.Hoye Cbc.Ca, More Bryce Hoye',\n",
       "       'Jackie Mckay Is A Métis Journalist Working For Cbc In Nunavut. She Has Worked As A Reporter In Thunder Bay, Yellowknife, Whitehorse, Iqaluit. Jackie Also Worked On Cbc Radio One Shows Including The Current, Metro Morning After Graduating Ryerson University In Follow Her On Twitter',\n",
       "       'Lucie Edwardson Is A Reporter With Cbc Calgary, Currently Focused On Bringing You Stories Related To Education In Alberta. In She Headed A Pop-Up Bureau In Lethbridge, Alta . Her Experience Includes Newspaper, Online, Tv, Radio. Follow Her On Twitter',\n",
       "       '\"Tori Weldon Is A Reporter Based In Moncton. SheS Been Working For The Cbc Since\"',\n",
       "       'Senior Reporter, Award-Winning Reporter Elizabeth Thompson Covers Parliament Hill. A Veteran Of The Montreal Gazette, Sun Media, Ipolitics, \"She Currently Works With The CbcS Ottawa Bureau\", Specializing In Investigative Reporting, Data Journalism. She Can Be Reached At, Elizabeth.Thompson Cbc.Ca., More Elizabeth Thompson, Follow Elizabeth Thompson On Twitter',\n",
       "       'Ariana Kelland Is A Reporter With The Cbc Newfoundland, \"Labrador Bureau In St. JohnS.\", More This Author, Follow Ariana Kelland On Twitter',\n",
       "       'Reporter Editor, Jennifer La Grassa Is A Reporter Editor For Cbc Hamilton. Email, Jennifer.Lagrassa Cbc.Ca, Follow, Jennlagrassa On Twitter',\n",
       "       'Elizabeth Chiu Is A Reporter In Nova Scotia, Hosts Atlantic Tonight On Saturdays At P.M., P.M. In Newfoundland. If You Have A Story Idea For Her, Contact Her At Elizabeth.Chiu Cbc.Ca.',\n",
       "       'Reporter, Cbc Toronto, Natalie Is A Storyteller Who Spent The Last Few Years In Montreal Covering Everything Politics To Corruption, Student Protests. Now That She S Back In Her Hometown Of Toronto, She Is Eagerly Rediscovering What Makes This City Tick, Has A Personal Interest In Real Estate, Investigative Journalism. When She S Not Reporting You Can Find Her At A Yoga Studio Or Exploring Queen St. Contact Natalie, Natalie.Nanowski Cbc.Ca',\n",
       "       'Michelle Ghoussoub Is A Journalist With Cbc News In Vancouver. She Has Previously Reported In Lebanon, Chile. Reach Her At Michelle.Ghoussoub Cbc.Ca Or On Twitter',\n",
       "       'Jessica Doria-Brown Is A Videojournalist With Cbc In P.E.I., Originally Toronto, Jessica Has Worked For Cbc In Newfoundland, Labrador, New Brunswick',\n",
       "       'Katie Pedersen Is An Investigative Journalist For Cbc Marketplace.',\n",
       "       '\"Nic Meloney Is A Wolastoqew Video Journalist Raised On Cape Breton Island In Nova Scotia MiKmaKi. Email Him At Nic.Meloney Cbc.Ca Or Follow Him On Twitter\"',\n",
       "       '\"Jessica Deer Is Kanien Kehá Ka Kahnawake. She Works In CbcS Indigenous Unit Based In Montreal. Email Her At Jessica.Deer Cbc.Ca Or Follow Her On Twitter\"',\n",
       "       'Hillary Johnstone Is A Reporter For Cbc Ottawa., You Can Reach Her Email Hillary.Johnstone Cbc.Ca.',\n",
       "       'Senior Reporter, Evan Dyer Has Been A Journalist With Cbc For Years, After An Early Career As A Freelancer In Argentina. He Works In The Parliamentary Bureau, Can Be Reached At Evan.Dyer Cbc.Ca.',\n",
       "       'Samantha Craggs Is A Cbc News Reporter Based In Hamilton, Ont. She Has A Particular Interest In Politics, Social Justice Stories, Tweets Live Hamilton City Hall. Follow Her On Twitter At, Samcraggscbc, Or Email Her At Samantha.Craggs Cbc.Ca',\n",
       "       'Co-Host, Cbc Vancouver News At, \"Anita Bathe Is Co-Host Of Cbc VancouverS Flagship Newscast.\", She Remains Committed To Working In The Field, Telling Stories That Matter, Giving Citizens A Voice. Bathe Is A Multiple Rtdna Award Winner, A Recipient Of The Jack Webster Fellowship, \"SheS Won Several Bcab Awards For Her In-Depth Reporting On Breaking News.\"',\n",
       "       'Host, London Morning, Rebecca Zandbergen Is Ottawa, Has Worked For Cbc Radio Across The Country For More Than Years, Including Stops In Iqaluit, Halifax, Windsor',\n",
       "       'Andrea Huncar Reports On Human Rights, Immigrant, Indigenous Communities, Youth At-Risk, The Justice System. Contact Her In Confidence At Andrea.Huncar Cbc.Ca, Follow Andrea Huncar On Twitter, More Andrea Huncar',\n",
       "       'Julia Page Is A Radio, Online Journalist With Cbc News, Based In Quebec City.',\n",
       "       'Correspondent, Documentary Maker, Terence Mckenna Has Reported Extensively On Domestic, International Affairs For More Than Years. His Cbc Documentaries Have Won Numerous Awards In Canada, The U.K., The U.S. Based In Toronto, \"He Now Reports For CbcS The National.\"',\n",
       "       'Cbc News, \"Brandie Weikle Is A Senior Writer For Cbc News Based In Toronto. SheS A Long-Time Magazine\", Newspaper Editor, Podcast Host With Specialities In Family Life, Health, The Workplace. You Can Reach Her At Brandie.Weikle Cbc.Ca.',\n",
       "       'Morning News Editor, Gary Ennett Is A Veteran Editor, Reporter. He S Been With Cbc Since The Opening Of The London Bureau In His Email Address Is Gary.Ennett Cbc.Ca',\n",
       "       'Joseph Arvay Qc Is A Lawyer At Arvay Finlay Llp In Vancouver, Victoria',\n",
       "       'Brian Higgins Shoots Video, Reports News On Prince Edward Island.',\n",
       "       'Bryan Eneas Is A Journalist The Penticton Indian Band Currently Based In Regina, Saskatchewan. Before Joining Cbc, He Reported In Central, Northern Saskatchewan. Send News Tips To Bryan.Eneas Cbc.Ca.',\n",
       "       'Benjamin Shingler Is A Journalist With Cbc Montreal. Follow Him On Twitter',\n",
       "       'Jordan Gill Is A Cbc Reporter Based Out Of Fredericton. He Can Be Reached At, Jordan.Gill Cbc.Ca.',\n",
       "       'Jan Lakes Is A Producer At Cbc Sudbury. You Can Reach Her At Jan.Lakes Cbc.Ca Or Find Her On Twitter',\n",
       "       'Andrew Lupton Is A B.C.-Born Journalist, Father Of Two, A North London Resident With A Passion For Politics, Photography, Follow Andrew On Twitter',\n",
       "       'Provincial Affairs Reporter, \"Jacques Poitras Has Been CbcS Provincial Affairs Reporter In New Brunswick Since Raised In Moncton\", He Also Produces The Cbc Political Podcast Spin Reduxit.',\n",
       "       'Kate Letterick Is A Reporter With Cbc New Brunswick.',\n",
       "       'Cbc News, \"Mark Quinn Is A Videojournalist With CbcS Bureau In St. JohnS.\"',\n",
       "       'Entertainment Reporter, Film Critic, Eli Glasner Is A National Entertainment Reporter, Film Critic For Cbc News. Each Friday He Reviews Films On Cbc News Network As Well As Appearing On Cbc Radio Programs Coast To Coast. Covering Culture Has Taken Him The Northern Tip Of Moosonee, Ont. To The Oscars Red Carpet., More This Author',\n",
       "       'Cbc News, \"Terry Roberts Is A Journalist With CbcS Bureau In St. JohnS.\", Follow Terry Roberts On Twitter',\n",
       "       'Janice Johnston Is An Award-Winning Journalist In Edmonton Who Has Covered The Courts, Crime For More Than Two Decades., You Can Reach Her At Janice.Johnston Cbc.Ca Or On Twitter At',\n",
       "       'Kevin Yarr Is The Early Morning Web Journalist At Cbc P.E.I. You Can Reach Him At Kevin.Yarr Cbc.Ca.',\n",
       "       'Reporter, \"Robson FletcherS Work For Cbc Calgary Focuses On Data\", Analysis, Investigative Journalism. He Joined Cbc In After Spending The Previous Decade Working As A Reporter, Editor At Newspapers In Alberta, British Columbia, Follow Robson On Twitter',\n",
       "       'Cbc Prince George, Andrew Kurjata Is An Award-Winning Journalist Covering Northern British Columbia For Cbc Radio, Cbc.Ca, \"Situated In Unceded Lheidli TEnneh Territory In Prince George.\", You Can Email Him At Andrew.Kurjata Cbc.Ca., Twitter, Facebook, More Cbc British Columbia Interior',\n",
       "       'Aarti Pole Is A Host With Cbc News Network, Reporting Breaking Stories Across The Country. She Has Also Previously Reported For The National, Cbc Toronto, Cbc Vancouver, Cbc Winnipeg. Prior To Joining The News Network Team, She Was The Washington Correspondent For Global National.',\n",
       "       'Reporter, Cbc Manitoba, Reporter Bartley Kives Joined Cbc Manitoba In Prior To That, He Spent Three Years At The Winnipeg Sun, At The Winnipeg Free Press, Writing About Politics, Music, Food, \"Outdoor Recreation. HeS The Author Of The Canadian Bestseller A DaytripperS Guide To Manitoba\", \"Exploring CanadaS Undiscovered Province\"',\n",
       "       'Tim Ford Is A Mixed-Race Freelance Writer Based In Victoria. He Has Written Articles For Avenue Magazine, Monday Magazine, Livewire Calgary, Has Authored Science Fiction, Fantasy Stories For Neo-Opsis Magazine, Crossed Genres Magazine, Several Anthology Collections.',\n",
       "       'Katie Simpson Is A Foreign Correspondent With Cbc News Based In Washington. Prior To Joining The Team In D.C. She Spent Six Years Covering Parliament Hill In Ottawa, Nearly A Decade Covering Local, Provincial Issues In Toronto., Follow, Cbckatie On Twitter, More Katie Simpson',\n",
       "       'Senior Reporter, Consumer Affairs, \"Aaron Saltzman Is CbcS Senior Business Reporter. Tips Story Ideas Always Welcome. Aaron.Saltzman Cbc.Ca Twitter.Com Cbcsaltzman\"',\n",
       "       'Bethany Lindsay Is A B.C. Journalist With A Focus On The Courts, Health, Science, Social Justice Issues. Questions Or News Tips, Get In Touch At Bethany.Lindsay Cbc.Ca Or On Twitter Through',\n",
       "       'Elias Abboud Is A Journalist At Cbc Montreal.',\n",
       "       'Editor In Chief, Brodie Fenlon Is Editor In Chief, Executive Director Of Daily News For Cbc News.',\n",
       "       '\"The CbcS Tahmina Aziz Currently Reports Out Of Windsor\", Toronto For Tv, Radio, Web. Have A Story, Email Tahmina.Aziz Cbc.Ca. Twitter',\n",
       "       'Douglas Gelevan, A National Award-Winning Sports Journalist, Has Been A Member Of The Cbc Team Since He Is Currently The Sports Journalist For Cbc News Montreal., Follow Doug On Twitter',\n",
       "       'For Cbc News',\n",
       "       'Haley Ryan Is A Reporter Based In Halifax. Got A Story Idea, Send An Email To Haley.Ryan Cbc.Ca, Or Reach Out On Twitter',\n",
       "       'Reporter, Cbc Toronto, \"Nicole Brockbank Is A Reporter For Cbc TorontoS Enterprise Unit. Fuelled Coffee\", She Digs Up, Researches, Writes Original Investigative, Feature Stories. Nicole.Brockbank Cbc.Ca',\n",
       "       'Marina Von Stackelberg Is A Cbc Journalist Based In Winnipeg. She Previously Worked For Cbc In Halifax, Sudbury. Connect With Her, Cbcmarina Or Marina.Von.Stackelberg Cbc.Ca',\n",
       "       'Jason Proctor Is A Reporter In British Columbia For Cbc News, Has Covered The B.C. Courts, Mental Health Issues In The Justice System Extensively.',\n",
       "       'Covering Everything, Anything For Cbc Saskatoon, Morgan Is A Journalist Interested In Municipal, Provincial Affairs, Canadian Crime, Canadian Politics. Familiar With A Variety Of Beats, Morgan Has Worked As A Staff Reporter For The Saskatoon Starphoenix, Metro Calgary, Metro Saskatoon, The Fort Mcmurray Today',\n",
       "       'Maryse Zeidler Is A Reporter For Cbc News In Vancouver, Covering News Across British Columbia. You Can Reach Her At Maryse.Zeidler Cbc.Ca.',\n",
       "       'Cbc News, Gary Moore Is A Video Journalist Based In Fredericton., Follow Gary Moore On Twitter',\n",
       "       'Senior Reporter, Cbc Toronto, Small Town Ontario To Washington D.C., Philip Has Covered Stories Big, Small. An Award-Winning Reporter With More Than Two Decades Of Experience In Ontario, Alberta, \"HeS Now A Senior Reporter For Cbc Toronto On Television\", Radio, Online. He Is Also A National Reporter For The World This Weekend On Radio One., Follow Him On Twitter',\n",
       "       'Senior Reporter, Cbc News, Natalie Is An Award-Wining Senior Reporter For Cbc News Network, \"Cbc The National Specializing In Breaking News. Whether ItS A Terror Attack Or A Royal Tour\", She Brings The Stories To You., Natalie Lives In Toronto With Her Husband',\n",
       "       'Dr. Taylor Lougheed Is An Ontario Physician Practicing In Family, Emergency, Sport, Cannabinoid Medicine.',\n",
       "       '\"David Thurton Is A National Reporter In CbcS Parliamentary Bureau. HeS Worked For Cbc In Fort Mcmurray\", The Maritimes, \"In CanadaS Arctic.\"',\n",
       "       'Paul Palmeter Is An Award-Winning Video Journalist Born, Raised In The Annapolis Valley. He Has Covered News, Sports Stories Across The Province For Years.',\n",
       "       'Rachel Cave Is A Cbc Reporter Based In Saint John, New Brunswick.',\n",
       "       'Carolyn Ray Is A Videojournalist Who Has Reported Out Of Three Provinces, Two Territories, Is Now Based In Halifax. You Can Reach Her At Carolyn.Ray Cbc.Ca',\n",
       "       'Isabella Zavarise Is A Video Journalist With Cbc In P.E.I. You Can Contact Her At Isabella.Zavarise Cbc.Ca',\n",
       "       'Bernice Hillier Is A Host Of Cbc Newfoundland Morning, Which Airs Weekday Mornings Across Western, Central Newfoundland, As Well As Southern Labrador., Read More Articles This Author, Follow Bernice Hillier On Twitter',\n",
       "       'Raffy Boudjikanian Is A National Reporter With Cbc In Edmonton. He Has Also Worked In Calgary, Montreal For The Public Broadcaster.',\n",
       "       '\"Dr. Tito Daodu Is A Pediatric Surgery Fellow At The Alberta Children S Hospital. She Is Currently Completing A MasterS Degree In Public Health At The Harvard T.H. Chan School Of Public Health. Dr. Daodu Is Actively Involved In Global\", Public Health Research With A Focus On Improving Surgical Outcomes, Making Surgical Care More Accessible In Canada, Around The World.',\n",
       "       'Alexander Panetta Is A Washington-Based Correspondent For Cbc News Who Has Covered American Politics, Canada-U.S. Issues Since He Previously Worked In Ottawa, Quebec City, Internationally, Reporting On Politics, Conflict, Disaster, The Montreal Expos.',\n",
       "       'Data Journalist, \"Jacques Marcoux Is A Cbc News Investigative Reporter Specializing In Data Analysis. Previously He Worked As A Multiplatform Reporter For The CbcS French Network Radio-Canada\", As A Public Relations Officer In The Agricultural Industry, Worked In Competitive Intelligence Gathering In The Financial Industry. Confidential Email, Jacques.Marcoux Cbc.Ca',\n",
       "       'Rachel Bergen Is A Journalist For Cbc Manitoba, Previously Reported For Cbc Saskatoon. Find Her On Twitter At, R_Bergen Or Email Her At, Rachel.Bergen Cbc.Ca.',\n",
       "       'Laura Clementson Is A Journalist With Cbc News. She Can Be Reached At Laura.Clementson Cbc.Ca., Follow Laura On Twitter',\n",
       "       'Cbc Reporter, \"Angela Sterritt Is A Journalist The Gitxsan Nation. SterrittS News\", Current Affairs Pieces Are Featured On National, \"Local Cbc Platforms. Her Cbc Column Reconcile This Tackles The Tensions Between Indigenous People\", Institutions In B.C.',\n",
       "       'Jennifer Sweet Is A Reporter With Cbc Based In Fredericton. She Can Be Reached At Or Jennifer.Sweet Cbc.Ca.',\n",
       "       'Aidan Geary Is A Journalist At Cbc Manitoba. Connect With Her At Aidan.Geary Cbc.Ca.',\n",
       "       'A.T. Kingsmith Is An Anxiety Researcher, Mixed Media Documentarian Who Teaches In The Department Of Politics, Public Administration At Ryerson University.',\n",
       "       'Reporter-Editor, Cbc News, Betsy Trumpener Is An Award-Winning Journalist, \"Author. SheS Been Covering The News In Central\", Northern British Columbia For More Than Years.',\n",
       "       'Joanne Seiff Is The Author Of Three Books., She Works In Winnipeg As A Freelance Writer.',\n",
       "       'Austin Grabish Landed His First Byline When He Was Just He Joined Cbc In After Freelancing For Several Outlets., In, \"He Was Part Of A Team Of Cbc Journalists Who Won The Ron Laidlaw Award For The CorporationS Extensive Digital Coverage On Asylum Seekers Crossing Into Canada. This Past Summer\", He Was On The Ground In Northern Manitoba Covering The Manhunt For B.C. Fugitives Bryer Schmegelsky, Kam Mcleod, Which Attracted International Attention. Email, Austin.Grabish Cbc.Ca, Pgp Key',\n",
       "       '\"You Can Find Columnist Graham ThomsonS Thoughts\", Analysis On Provincial Politics Every Friday At Cbc.Ca Edmonton, On Cbc Edmonton Television News, During Radio Active On Cbc Radio One, On Twitter At',\n",
       "       'Colin Harris Is A Journalist With Cbc In Montreal., Follow Colin On Twitter',\n",
       "       'Bailey Martens Is A Student At The University Of British Columbia, A Freelance Journalist.',\n",
       "       'Radio-Canada Columnist, Jeff Yates Is A Radio-Canada Columnist Who Checks Online Facts, \"Debunks Fake News. HeS Part Of Décrypteurs\", \"Radio-CanadaS Team Dedicated To Tackling Online Disinformation.\"',\n",
       "       'Senior Reporter, \"Olivia Stefanovich Is A Senior Reporter For CbcS Parliamentary Bureau Based In Ottawa. She Previously Worked In Toronto\", Saskatchewan, Northern Ontario. Connect With Her On Twitter At, Cbcolivia. Story Tips Welcome, Olivia.Stefanovich Cbc.Ca.',\n",
       "       'Senior Investigative Journalist, Geoff Leo Has Been A Reporter For Cbc News In Saskatchewan Since His Work As An Investigative Journalist, Documentary Producer Has Earned Numerous National, Regional Awards., Send Your Tips, Story Ideas To Geoff.',\n",
       "       'Andie Bulman Is A Chef, Writer, \"Comedian In St. JohnS.\"',\n",
       "       'Connell Smith Is A Reporter With Cbc In Saint John. He Can Be Reached At Connell.Smith Cbc.Ca',\n",
       "       'Claire Can Be Reached At Claire.Loewen Cbc.Ca', 'Cbc Radio',\n",
       "       '\"Ashley Burke Is A Senior Reporter With CbcS Parliamentary Bureau. Have A Story Idea\", Email Her At Ashley.Burke Cbc.Ca',\n",
       "       'Kendall Latimer Has Shared Compelling Stories, Photos, Audio, Video With Cbc Saskatchewan Since She Loves A Good Yarn, Is Always Open To Chat, Kendall.Latimer Cbc.Ca., Follow Me',\n",
       "       'Shane Ross Is A Former Newspaper, Tv Journalist In Halifax, Ottawa, \"Charlottetown. He Joined Cbc P.E.I.S Web Team In\"',\n",
       "       'Laura Glowacki Is A Reporter Based In Ottawa. Previously, She Worked As A Reporter In Winnipeg, \"As An Associate Producer For CbcS Metro Morning In Toronto. Find Her On Twitter\", Glowackicbc, Reach Her Email At Laura.Glowacki Cbc.Ca.',\n",
       "       'Nick Murray Is A Cbc Reporter, \"Based In Iqaluit Since He Got His Start With Cbc In Fredericton After Graduating St. Thomas UniversityS Journalism Program. HeS Also Worked Two Olympic Games As A Senior Writer With Cbc Sports. You Can Follow Nick On Twitter At\"',\n",
       "       'Sarah Macmillan Is A Reporter With Cbc Sudbury. She Previously Worked With Cbc P.E.I. You Can Contact Her At Sarah.Macmillan Cbc.Ca',\n",
       "       'Digital Broadcast Reporter, Zulekha Nathoo Is An Entertainment Reporter Based In Los Angeles. The Oscars To The Grammys, \"SheS Interviewed Some Of The Biggest Names In Showbiz Including Celine Dion\", Denzel Washington, Angelina Jolie. She Also Works On-Air, Having Spent More Than A Decade At Cbc News Stations Across Canada. Follow Her On Twitter Instagram',\n",
       "       'Staff Photographer, Ben Nelms Is An Award-Winning Photojournalist Based In Vancouver',\n",
       "       'Cbc News, \"John Gushue Is The Digital Senior Producer With Cbc News In St. JohnS.\", More This Author',\n",
       "       'Madeleine Cummings Is A Digital Journalist With Cbc Edmonton., Follow Madeleine On Twitter',\n",
       "       'Senior Writer, Peter Zimonjic Has Worked As A Reporter, Columnist In London, England, For The Daily Mail, Sunday Times, Daily Telegraph, In Canada For Sun Media, The Ottawa Citizen. He Is The Author Of Into The Darkness, An Account Of',\n",
       "       'Video Journalist, Jon Hernandez Is An Award-Winning Multimedia Journalist Vancouver, British Columbia. His Reporting Has Explored Mass International Migration In Chile, Controversial Logging Practices In British Columbia, The Global Hiv Aids Epidemic. Follow Jon Hernandez On Twitter',\n",
       "       '\"Kyle Bakx Is A Calgary-Based Journalist With CbcS Network Business Unit. HeS Covered Stories Across The Country\", Follow, Kylebakx On Twitter',\n",
       "       'Cbc Calgary Reporter, Meghan Grant Is The Courts, Crime Reporter For Cbc Calgary., Follow Her On Twitter',\n",
       "       'Janine Legal Is A Freelance Writer, A Grassroots Activist Who Believes Passionately In The Power Of Each One Of Us To Make The World A Better Place.',\n",
       "       'Health Policy Analyst, Steven Lewis Is A Health Policy Consultant Formerly Based In Saskatchewan. He Now Lives In Australia.',\n",
       "       'Nancy Russell Has Been A Reporter With Cbc Since, In Whitehorse, Winnipeg, Toronto, Charlottetown. When Not On The Job, She Spends Her Time On The Water Or In The Gym Rowing, Or Walking Her Dog. Nancy.Russell Cbc.Ca',\n",
       "       '\"Karissa Donkin Is A Journalist In CbcS Atlantic Investigative Unit. Do You Have A Story You Want Us To Investigate\", Send Your Tips To Nbinvestigates Cbc.Ca.',\n",
       "       'Philip Drost Is A Reporter With Cbc New Brunswick.',\n",
       "       'Emma Smith Is A Journalist B.C. Who Has Covered Rural Issues, Indigenous Communities. Before Joining Cbc Nova Scotia In, She Worked As The Editor Of A Community Newspaper. Have A Story Idea To Send Her Way, Email Emma.Smith Cbc.Ca',\n",
       "       '\"Alex Migdal Is A Journalist With Cbc News In Vancouver. HeS Previously Reported For The Globe\", Mail, Guelph Mercury, Edmonton Journal. You Can Reach Him At Alex.Migdal Cbc.Ca., Twitter, More Stories',\n",
       "       'Enterprise Reporter, Bryan Labis An Enterprise Reporter With Cbc Calgary. If You Have A Good Story Idea Or Tip, You Can Reach Him At Bryan.Labby Cbc.Ca Or On Twitter At',\n",
       "       'Eva Uguen-Csenge Is A Multimedia Reporter For Cbc News In Vancouver. Get In Touch With Her At Eva.Uguen-Csenge Cbc.Ca Or On Twitter, Evacsenge For Story Tips., Twitter',\n",
       "       'Jason Warick Is A Reporter With Cbc Saskatoon.', 'Elham Shabahat',\n",
       "       'Dr Judi L. Malone, R. Psych, Ab Aus, Is The Ceo Of The Psychologists, Association Of Alberta. Dr Malone Has A Wealth Of Scientist-Practitioner Experience Clinical Practice, Academia, Professional Association Administration, Advocacy. Her Expertise Includes Trauma, The Neurobiology Of Addictions, Small Communities Of Practice',\n",
       "       'Dan Taekema Is A Reporter Editor With Cbc Hamilton., Email, Daniel.Taekema Cbc.Ca, Follow, Dantaekema On Twitter',\n",
       "       'Wawmeesh Hamilton Is An Associate Producer With Cbc Vancouver S Urban Nations, Which Covers The News Of Urban Indigenous People In Metro Vancouver, In Towns Across B.C. His Work About Indigenous People, Reconciliation Has Also Been Published On Cbc Radio, Cbc Online, Cbc Indigenous. The Two-Time Webster Award Nominee Graduated The Ubc Graduate School Of Journalism In Wawmeesh Lives In Vancouver, Is A Member Of The Hupacasath First Nation In Port Alberni',\n",
       "       'Video Journalist, Send Tips Or Comments To Cory.Correia Cbc.Ca, Follow Along On Twitter',\n",
       "       'Karin Larsen Is A Former Olympian, Award Winning Sports Broadcaster Who Covers News, Sports For Cbc Vancouver.',\n",
       "       '\"Kristin Annable Is A Member Of CbcS Investigative Unit Based In Winnipeg. She Can Be Reached At Kristin.Annable Cbc.Ca\"',\n",
       "       'Wallis Snowdon Is A Digital Journalist With Cbc Edmonton. She Has Nearly A Decade Of Experience Reporting Behind Her. Originally New Brunswick, Her Journalism Career Has Taken Her Nova Scotia To Fort Mcmurray. Share Your Stories With Wallis At Wallis.Snowdon Cbc.Ca',\n",
       "       'Video Journalist, Dale Molnar Is An Award-Winning Video Journalist At Cbc Windsor. He Is A Graduate Of The University Of Windsor, Has Worked In Television, Radio',\n",
       "       'Investigative Reporter, Charles Rusnell Is A Reporter With Cbc Investigates, The Award-Winning Investigative Unit Of Cbc Edmonton. His Journalism In The Public Interest Is Widely Credited With Forcing Accountability, Transparency, Democratic Change In Alberta. Send Tips In Confidence To Cbcinvestigates Cbc.Ca., Follow Him On Twitter Charlesrusnell',\n",
       "       'Cbc News, \"Rob Antle Is Producer For CbcS Investigative Unit In Newfoundland\", Follow Rob Antle On Twitter',\n",
       "       'This Column Is An Opinion Dr. Kumanan Wilson, Md, Msc, Frcpc. He Is A Physician At The Ottawa Hospital, A Member Of The University Of Ottawa Centre For Health Law, Policy, Ethics, Was A Consultant To The World Health Organization On The International Health Regulations',\n",
       "       'Investigative Journalist, Eric Rankin Is An Award-Winning Cbc Reporter. His Honours Include The Canadian Screen Award For Best Local Reportage, The, Rtdna Awards For Best In-Depth Investigative Reporting, The Jack Webster Award For Best News Reporting.',\n",
       "       'Senior Reporter, Nicole Has An Avid Interest In All Things Science. As An Amateur Astronomer, Nicole Can Be Found Looking Up At The Night Sky Appreciating The Marvels Of Our Universe. She Is The Editor Of The Journal Of The Royal Astronomical Society Of Canada, The Author Of Several Books.',\n",
       "       'Muriel Draaisma Is A Cbc Toronto Web Reporter. She Writes About Crime, Social Justice, Politics, Civic Issues, The Environment. Muriel.Draaisma Cbc.Ca',\n",
       "       'Senior Writer, Benjamin Blum Is A Senior Writer With Cbc News, \"Previously Worked With Cbc Sports In The Same Capacity. He Holds A MasterS Of Journalism The University Of KingS College In Halifax.\"',\n",
       "       'Senior Writer, Lucas Powers Is A Toronto-Based Reporter, \"Writer. HeS Reported For Cbc News Across Canada. Have A Story To Tell\", Email Lucas.Powers Cbc.Ca Any Time.',\n",
       "       'Provincial Affairs Reporter, Kerry Campbell Is The Provincial Affairs Reporter For Cbc P.E.I., Covering Politics, The Provincial Legislature., Kerry.Campbell Cbc.Ca',\n",
       "       'Reporter, Cbc Toronto, Shanifa Nasser Is An Investigative Journalist Interested In National Security, Stories With A Heartbeat. Before Coming To Cbc News, \"She Was A Munk Fellow In Global Journalism At The University Of Toronto. She Also Holds A MasterS Degree In Islamic Studies. Shanifa.Nasser Cbc.Ca\", Twitter',\n",
       "       'Robert Jones Has Been A Reporter, Producer With Cbc New Brunswick Since His Investigative Reports On Petroleum Pricing In New Brunswick Won Several Regional, National Awards, Led To The Adoption Of Price Regulation In',\n",
       "       'Julia Peterson Is A Freelance Journalist Currently Based In Regina, Saskatchewan. Her Writing Can Be Found In Eagle Feather News, Plenitude Magazine, Startrek.Com, Alma, Briarpatch Magazine.',\n",
       "       'Senior Reporter, Kayla Hounsell Is A Network Reporter With Cbc News Based In Halifax. She Covers The Maritime Provinces For Cbc National News On Television, Radio, Online. She Welcomes Story Ideas At Kayla.Hounsell Cbc.Ca., Follow Kayla Hounsell On Twitter',\n",
       "       'Janet French Is A Provincial Affairs Reporter With Cbc Edmonton. She Has Also Been A Reporter At The Edmonton Journal, Saskatoon Starphoenix. You Can Reach Her At Janet.French Cbc.Ca',\n",
       "       'Web Journalist, \"Sara Is A P.E.I. Native Who Graduated The University Of KingS College In Halifax. N.S.\", With A Bachelor Of Journalism, Honours, \"Degree. SheS Worked With Cbc Radio\", Television Since, Moving To The Cbc P.E.I. Web Team In, Focusing On Weekend Features., Email Sara.Fraser Cbc.Ca',\n",
       "       'Peter Mills Is An Associate Producer At Cbc Saskatchewan, The Host Of The Meet The Riders Podcast. Follow Him On Twitter, Tweetermillscbc. Do You Have A Story Idea, Email Peter.Mills Cbc.Ca.',\n",
       "       'Nicole Williams Is A Video Journalist With Cbc P.E.I. She Previously Worked As An Associate Producer With Cbc News In Toronto.',\n",
       "       'Amitha Kalaichandran, M.H.S., M.D. Is A Physician, Writer, Asia Pacific Foundation Media Fellow Based In Toronto.',\n",
       "       'Brittany Spencer Is A Multi-Platform Journalist With Cbc P.E.I. Email, Brittany.Spencer Cbc.Ca',\n",
       "       'Senior Technology Reporter, \"While In CbcS London\", U.K. Bureau, Thomas Reported On Everything The Royal Family, European Politics To Terrorism. He Filed Stories Quebec For Several Years, Reported For Radio-Canada In His Native New Brunswick. Thomas Is Now Based In Toronto, Focuses On Technology-Related News. He Can Be Reached Email At Thomas.Daigle Cbc.Ca., Follow Thomas On Twitter',\n",
       "       'National Reporter, \"Greg Rasmussen Is A National Reporter For Cbc News Based In Vancouver. HeS Covered News Stories Across Canada\", Around The World For More Than Two Decades. Follow Him, Cbcgreg On Twitter.',\n",
       "       'Cbc Theatre Reviewer, Joff Schmidt Is A Copy Editor For Cbc Manitoba. Since, \"HeS Also Been Cbc ManitobaS Theatre Critic On Radio\", Online. He Majored In Theatre At The U Of M, Performed In Many University, Fringe Festival Productions Along The Way, Ranging Terrible To Pretty Good, According To The Reviews . Find Him On Twitter',\n",
       "       'Reporter, Cbc Toronto, Sara Jabakhanji Is A Reporter, \"News Intern For Cbc TorontoS Enterprise Unit. You Can Reach Her At Sara.Jabakhanji Cbc.Ca\"',\n",
       "       'Sarath Peiris Was Born In Colombo, Sri Lanka, In, Spent His Career At The Moose Jaw Times Herald, Saskatoon Starphoenix. He Was The Starphoenix S Opinions Editor, Editorial Writer.',\n",
       "       'Cbc Saskatchewan Meteorologist, Christy Climenhaga, \"Cbc SaskatchewanS Meteorologist\", Covers Weather For The Province. Catch Her Forecast Tonight At On Cbc Saskatchewan News.',\n",
       "       '\"Marie Isabelle Rochon Is A Videojournalist For Radio-Canada Based In St. JohnS.\"',\n",
       "       'Trevor Tombe Is An Associate Professor Of Economics At The University Of Calgary, Research Fellow At The School Of Public Policy.',\n",
       "       'Wyatt James Schierman Is A Freelance Writer Alberta, A Regular Columnist With Loonie Politics. His Writing Has Also Been Published In The Ottawa Citizen, The Toronto Star, The Calgary Herald, Huffington Post Canada, The Hill Times. When He Is Not Writing, Wyatt Is Traveling Abroad As An Election Observer.',\n",
       "       'National Affairs Editor, \"Chris Hall Is The CbcS National Affairs Editor\", Host Of The House On Cbc Radio, Based In The Parliamentary Bureau In Ottawa. He Began His Reporting Career With The Ottawa Citizen, Before Moving To Cbc Radio In, Where He Worked As A National Radio Reporter In Toronto, Halifax, \"St. JohnS. He Returned To Ottawa\", The Hill In, More This Author'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Authors Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['authors'].replace(to_replace = [r'cbcs?\\b.*',r'.*\\bcbcs?', r'.*cbcnews.*'], value='cbc', regex=True, inplace=True)\n",
    "df['authors'].replace(to_replace = ['the associated press'], value='associated press', inplace=True)\n",
    "df['authors'].replace(to_replace = [r'canadian?\\b.*',r'.*\\bcanadian?'], value='canadian', regex=True, inplace=True)\n",
    "df['authors'].replace(to_replace = [r'freelancer?\\b.*',r'.*\\bfreelancer?'], value='freelancer', regex=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     cbc\n",
       "1                                                     cbc\n",
       "2                                        associated press\n",
       "3                                                     cbc\n",
       "4                                                     cbc\n",
       "5                                                     cbc\n",
       "6                                                     cbc\n",
       "7                                        associated press\n",
       "8                                         thomson reuters\n",
       "9                                                     cbc\n",
       "10                                                    cbc\n",
       "11                                                    cbc\n",
       "12      colleen m. flood is director of the centre for...\n",
       "13                                                    cbc\n",
       "14                                                    cbc\n",
       "15                                                    cbc\n",
       "16                                                       \n",
       "17                                                       \n",
       "18                                                    cbc\n",
       "19                                                    cbc\n",
       "20                                                    cbc\n",
       "21                                       associated press\n",
       "22                                                    cbc\n",
       "23                                                    cbc\n",
       "24                                                    cbc\n",
       "25                                                    cbc\n",
       "26                                        thomson reuters\n",
       "27                                                    cbc\n",
       "28                                                       \n",
       "29                                        thomson reuters\n",
       "                              ...                        \n",
       "3536                                                  cbc\n",
       "3537    trevor tombe is an associate professor of econ...\n",
       "3538                                                  cbc\n",
       "3539                                                  cbc\n",
       "3540                                             canadian\n",
       "3541                                     associated press\n",
       "3542                                             canadian\n",
       "3543                                                  cbc\n",
       "3544                                      thomson reuters\n",
       "3545                                                     \n",
       "3546                                                  cbc\n",
       "3547                                                  cbc\n",
       "3548                                                  cbc\n",
       "3549                                                  cbc\n",
       "3550                                           freelancer\n",
       "3551                                             canadian\n",
       "3552                                     associated press\n",
       "3553                                                  cbc\n",
       "3554                                             canadian\n",
       "3555                                     associated press\n",
       "3556                                     associated press\n",
       "3557                                             canadian\n",
       "3558                                                  cbc\n",
       "3559                                                  cbc\n",
       "3560                                                  cbc\n",
       "3561                                     associated press\n",
       "3562                                             canadian\n",
       "3563                                                  cbc\n",
       "3564                                                  cbc\n",
       "3565                                             canadian\n",
       "Name: authors, Length: 3566, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data has 3566 rows and 4 columns\n"
     ]
    }
   ],
   "source": [
    "# What is the shape of the dataset?\n",
    "\n",
    "print(\"Input data has {} rows and {} columns\".format(len(df), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3566 rows, 0 are CBC News, 0 are Associated Press\n"
     ]
    }
   ],
   "source": [
    "# How many News Authors are there? Considering Authors as Label.\n",
    "\n",
    "print(\"Out of {} rows, {} are CBC News, {} are Associated Press\".format(len(df),\n",
    "                                                       len(df[df['authors']=='Cbc News']),\n",
    "                                                       len(df[df['authors']=='The Associated Press'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null in label: 0\n",
      "Number of null in text: 0\n"
     ]
    }
   ],
   "source": [
    "# How much missing data is there?\n",
    "\n",
    "print(\"Number of null in label: {}\".format(df['authors'].isnull().sum()))\n",
    "print(\"Number of null in text: {}\".format(df['text'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Basics: Implementing a pipeline to clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing text data\n",
    "\n",
    "Cleaning up the text data is necessary to highlight attributes. These would be loaded to machine learning system to pick up on. Cleaning (or pre-processing) the data typically consists of a number of steps:\n",
    "1. **Remove punctuation**\n",
    "2. **Tokenization**\n",
    "3. **Remove stopwords**\n",
    "4. **Lemmatize/Stem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3               cbc  Coronavirus: The latest in drug treatment and ...   \n",
       "4               cbc  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4      Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_clean'] = df['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3               cbc  Coronavirus: The latest in drug treatment and ...   \n",
       "4               cbc  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4      Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_tokenized'] = df['body_text_clean'].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3               cbc  Coronavirus: The latest in drug treatment and ...   \n",
       "4               cbc  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \n",
       "0  [canadian, pharmacies, are, limiting, how, muc...  \n",
       "1  [the, yukon, government, has, identified, two,...  \n",
       "2  [the, senate, late, wednesday, passed, an, unp...  \n",
       "3  [scientists, around, the, world, are, racing, ...  \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_nostop'] = df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "      <td>[scientists, around, world, racing, find, nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "      <td>[, trudeau, says, rules, quarantine, act, enfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3               cbc  Coronavirus: The latest in drug treatment and ...   \n",
       "4               cbc  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "3  [scientists, around, the, world, are, racing, ...   \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...   \n",
       "\n",
       "                                    body_text_nostop  \n",
       "0  [canadian, pharmacies, limiting, much, medicat...  \n",
       "1  [yukon, government, identified, two, places, w...  \n",
       "2  [senate, late, wednesday, passed, unparalleled...  \n",
       "3  [scientists, around, world, racing, find, nove...  \n",
       "4  [, trudeau, says, rules, quarantine, act, enfo...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental Data Cleaning: Using Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "ps = nltk.PorterStemmer()   # Test out Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ps.stem('grows'))\n",
    "#print(ps.stem('growing'))\n",
    "#print(ps.stem('grow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ps.stem('run'))\n",
    "#print(ps.stem('running'))\n",
    "#print(ps.stem('runner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_stemmed'] = df['body_text_nostop'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "      <td>[senat, late, wednesday, pass, unparallel, 22,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "      <td>[scientists, around, world, racing, find, nove...</td>\n",
       "      <td>[scientist, around, world, race, find, novel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "      <td>[, trudeau, says, rules, quarantine, act, enfo...</td>\n",
       "      <td>[, trudeau, say, rule, quarantin, act, enforc,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3               cbc  Coronavirus: The latest in drug treatment and ...   \n",
       "4               cbc  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "3  [scientists, around, the, world, are, racing, ...   \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "2  [senate, late, wednesday, passed, unparalleled...   \n",
       "3  [scientists, around, world, racing, find, nove...   \n",
       "4  [, trudeau, says, rules, quarantine, act, enfo...   \n",
       "\n",
       "                                   body_text_stemmed  \n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...  \n",
       "1  [yukon, govern, identifi, two, place, whitehor...  \n",
       "2  [senat, late, wednesday, pass, unparallel, 22,...  \n",
       "3  [scientist, around, world, race, find, novel, ...  \n",
       "4  [, trudeau, say, rule, quarantin, act, enforc,...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['authors']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplemental Data Cleaning: Using a Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "import nltk\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()   # https://wordnet.princeton.edu/\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(wn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ps.stem('meanness'))\n",
    "#print(ps.stem('meaning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(wn.lemmatize('meanness'))\n",
    "#print(wn.lemmatize('meaning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_lemmatized'] = df['body_text_nostop'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "      <td>[canadian, pharmacy, limiting, much, medicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "      <td>[yukon, government, identified, two, place, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "      <td>[senat, late, wednesday, pass, unparallel, 22,...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "      <td>[scientists, around, world, racing, find, nove...</td>\n",
       "      <td>[scientist, around, world, race, find, novel, ...</td>\n",
       "      <td>[scientist, around, world, racing, find, novel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "      <td>[, trudeau, says, rules, quarantine, act, enfo...</td>\n",
       "      <td>[, trudeau, say, rule, quarantin, act, enforc,...</td>\n",
       "      <td>[, trudeau, say, rule, quarantine, act, enforc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cbc</td>\n",
       "      <td>'Worse' pandemic on horizon unless world deals...</td>\n",
       "      <td>The continued existence of wildlife markets, w...</td>\n",
       "      <td>The continued existence of wildlife markets, w...</td>\n",
       "      <td>The continued existence of wildlife markets wh...</td>\n",
       "      <td>[the, continued, existence, of, wildlife, mark...</td>\n",
       "      <td>[continued, existence, wildlife, markets, cons...</td>\n",
       "      <td>[continu, exist, wildlif, market, consid, pote...</td>\n",
       "      <td>[continued, existence, wildlife, market, consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cbc</td>\n",
       "      <td>What you need to know about COVID-19 in Ottawa...</td>\n",
       "      <td>CBC Ottawa's latest roundup of key points duri...</td>\n",
       "      <td>Recent developments:  Two new cases in western...</td>\n",
       "      <td>Recent developments  Two new cases in western ...</td>\n",
       "      <td>[recent, developments, two, new, cases, in, we...</td>\n",
       "      <td>[recent, developments, two, new, cases, wester...</td>\n",
       "      <td>[recent, develop, two, new, case, western, que...</td>\n",
       "      <td>[recent, development, two, new, case, western,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>associated press</td>\n",
       "      <td>Michigan hospitals jammed as coronavirus cases...</td>\n",
       "      <td>Michigan hospitals are bracing for a surge of ...</td>\n",
       "      <td>Michigan hospitals are bracing for a surge of ...</td>\n",
       "      <td>Michigan hospitals are bracing for a surge of ...</td>\n",
       "      <td>[michigan, hospitals, are, bracing, for, a, su...</td>\n",
       "      <td>[michigan, hospitals, bracing, surge, coronavi...</td>\n",
       "      <td>[michigan, hospit, brace, surg, coronaviru, ca...</td>\n",
       "      <td>[michigan, hospital, bracing, surge, coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thomson reuters</td>\n",
       "      <td>U.S. coronavirus cases now highest in the world</td>\n",
       "      <td>The number of confirmed COVID-19 cases in the ...</td>\n",
       "      <td>The number of confirmed COVID-19 cases in the ...</td>\n",
       "      <td>The number of confirmed COVID19 cases in the U...</td>\n",
       "      <td>[the, number, of, confirmed, covid19, cases, i...</td>\n",
       "      <td>[number, confirmed, covid19, cases, us, rose, ...</td>\n",
       "      <td>[number, confirm, covid19, case, us, rose, 838...</td>\n",
       "      <td>[number, confirmed, covid19, case, u, rose, 83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cbc</td>\n",
       "      <td>'Avoid the emergency' pleads Jewish General, a...</td>\n",
       "      <td>Montreal's Jewish General Hospital, one of the...</td>\n",
       "      <td>The Jewish General Hospital plans to set up tr...</td>\n",
       "      <td>The Jewish General Hospital plans to set up tr...</td>\n",
       "      <td>[the, jewish, general, hospital, plans, to, se...</td>\n",
       "      <td>[jewish, general, hospital, plans, set, traile...</td>\n",
       "      <td>[jewish, gener, hospit, plan, set, trailer, ou...</td>\n",
       "      <td>[jewish, general, hospital, plan, set, trailer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3               cbc  Coronavirus: The latest in drug treatment and ...   \n",
       "4               cbc  The latest on the coronavirus outbreak for Mar...   \n",
       "5               cbc  'Worse' pandemic on horizon unless world deals...   \n",
       "6               cbc  What you need to know about COVID-19 in Ottawa...   \n",
       "7  associated press  Michigan hospitals jammed as coronavirus cases...   \n",
       "8   thomson reuters    U.S. coronavirus cases now highest in the world   \n",
       "9               cbc  'Avoid the emergency' pleads Jewish General, a...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "5  The continued existence of wildlife markets, w...   \n",
       "6  CBC Ottawa's latest roundup of key points duri...   \n",
       "7  Michigan hospitals are bracing for a surge of ...   \n",
       "8  The number of confirmed COVID-19 cases in the ...   \n",
       "9  Montreal's Jewish General Hospital, one of the...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "5  The continued existence of wildlife markets, w...   \n",
       "6  Recent developments:  Two new cases in western...   \n",
       "7  Michigan hospitals are bracing for a surge of ...   \n",
       "8  The number of confirmed COVID-19 cases in the ...   \n",
       "9  The Jewish General Hospital plans to set up tr...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "5  The continued existence of wildlife markets wh...   \n",
       "6  Recent developments  Two new cases in western ...   \n",
       "7  Michigan hospitals are bracing for a surge of ...   \n",
       "8  The number of confirmed COVID19 cases in the U...   \n",
       "9  The Jewish General Hospital plans to set up tr...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "3  [scientists, around, the, world, are, racing, ...   \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...   \n",
       "5  [the, continued, existence, of, wildlife, mark...   \n",
       "6  [recent, developments, two, new, cases, in, we...   \n",
       "7  [michigan, hospitals, are, bracing, for, a, su...   \n",
       "8  [the, number, of, confirmed, covid19, cases, i...   \n",
       "9  [the, jewish, general, hospital, plans, to, se...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "2  [senate, late, wednesday, passed, unparalleled...   \n",
       "3  [scientists, around, world, racing, find, nove...   \n",
       "4  [, trudeau, says, rules, quarantine, act, enfo...   \n",
       "5  [continued, existence, wildlife, markets, cons...   \n",
       "6  [recent, developments, two, new, cases, wester...   \n",
       "7  [michigan, hospitals, bracing, surge, coronavi...   \n",
       "8  [number, confirmed, covid19, cases, us, rose, ...   \n",
       "9  [jewish, general, hospital, plans, set, traile...   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...   \n",
       "1  [yukon, govern, identifi, two, place, whitehor...   \n",
       "2  [senat, late, wednesday, pass, unparallel, 22,...   \n",
       "3  [scientist, around, world, race, find, novel, ...   \n",
       "4  [, trudeau, say, rule, quarantin, act, enforc,...   \n",
       "5  [continu, exist, wildlif, market, consid, pote...   \n",
       "6  [recent, develop, two, new, case, western, que...   \n",
       "7  [michigan, hospit, brace, surg, coronaviru, ca...   \n",
       "8  [number, confirm, covid19, case, us, rose, 838...   \n",
       "9  [jewish, gener, hospit, plan, set, trailer, ou...   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [canadian, pharmacy, limiting, much, medicatio...  \n",
       "1  [yukon, government, identified, two, place, wh...  \n",
       "2  [senate, late, wednesday, passed, unparalleled...  \n",
       "3  [scientist, around, world, racing, find, novel...  \n",
       "4  [, trudeau, say, rule, quarantine, act, enforc...  \n",
       "5  [continued, existence, wildlife, market, consi...  \n",
       "6  [recent, development, two, new, case, western,...  \n",
       "7  [michigan, hospital, bracing, surge, coronavir...  \n",
       "8  [number, confirmed, covid19, case, u, rose, 83...  \n",
       "9  [jewish, general, hospital, plan, set, trailer...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying punctuation, Tokenization, Remove stopwords, Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "      <td>[canadian, pharmacy, limiting, much, medicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "      <td>[yukon, government, identified, two, place, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "      <td>[senat, late, wednesday, pass, unparallel, 22,...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>Coronavirus: The latest in drug treatment and ...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "      <td>[scientists, around, world, racing, find, nove...</td>\n",
       "      <td>[scientist, around, world, race, find, novel, ...</td>\n",
       "      <td>[scientist, around, world, racing, find, novel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cbc News</td>\n",
       "      <td>The latest on the coronavirus outbreak for Mar...</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "      <td>[, trudeau, says, rules, quarantine, act, enfo...</td>\n",
       "      <td>[, trudeau, say, rule, quarantin, act, enforc,...</td>\n",
       "      <td>[, trudeau, say, rule, quarantine, act, enforc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                              title  \\\n",
       "0              Cbc News  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1              Cbc News  Yukon gov't names 2 possible sources of corona...   \n",
       "2  The Associated Press  U.S. Senate passes $2T coronavirus relief package   \n",
       "3              Cbc News  Coronavirus: The latest in drug treatment and ...   \n",
       "4              Cbc News  The latest on the coronavirus outbreak for Mar...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4  The latest on the coronavirus outbreak from CB...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "3  [scientists, around, the, world, are, racing, ...   \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "2  [senate, late, wednesday, passed, unparalleled...   \n",
       "3  [scientists, around, world, racing, find, nove...   \n",
       "4  [, trudeau, says, rules, quarantine, act, enfo...   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...   \n",
       "1  [yukon, govern, identifi, two, place, whitehor...   \n",
       "2  [senat, late, wednesday, pass, unparallel, 22,...   \n",
       "3  [scientist, around, world, race, find, novel, ...   \n",
       "4  [, trudeau, say, rule, quarantin, act, enforc,...   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [canadian, pharmacy, limiting, much, medicatio...  \n",
       "1  [yukon, government, identified, two, place, wh...  \n",
       "2  [senate, late, wednesday, passed, unparalleled...  \n",
       "3  [scientist, around, world, racing, find, novel...  \n",
       "4  [, trudeau, say, rule, quarantine, act, enforc...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemented 3 types of vectorization Models. They are:\n",
    "\n",
    "1. count Vectorization\n",
    "2. Bag-Of-words Model (TF-IDF)\n",
    "3. N-gram Vectorization or Skip Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorization \n",
    "\n",
    "Creates a document-term matrix where the entry of each cell will be a count of the number of times that word occurred in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3566, 31399)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=clean_text)  # call the function clean_text. \n",
    "X_counts = count_vect.fit_transform(df['text'])\n",
    "\n",
    "# X_counts is the vectorized version of the data.\n",
    "\n",
    "print(X_counts.shape)\n",
    "#print(count_vect.get_feature_names())  # get_feature_names() prints all the unique words that are found in all of the text messages.\n",
    "\n",
    "# (3566, 31399) : 3566 text messages, across this 3566 text messages there are 31399 unique words.\n",
    "# It means the document term matrix consists of 3566 rows and 31399 columns.\n",
    "\n",
    "# Each row : Text message and the column will have unique words of this text message.\n",
    "\n",
    "# get_feature_names() : means the numbers are names of the columns. We can remove the numbers and change it to names.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2951)\n",
      "CountVectorizer(analyzer=<function clean_text at 0x1a229fe268>, binary=False,\n",
      "                decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "                encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "                max_features=None, min_df=1, ngram_range=(1, 1),\n",
      "                preprocessor=None, stop_words=None, strip_accents=None,\n",
      "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
      "                vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# Apply CountVectorizer to smaller sample\n",
    "\n",
    "data_sample = df[0:20]\n",
    "\n",
    "count_vect_sample = CountVectorizer(analyzer=clean_text)\n",
    "X_counts_sample = count_vect_sample.fit_transform(data_sample['text'])\n",
    "print(X_counts_sample.shape)\n",
    "#print(count_vect_sample.get_feature_names())\n",
    "\n",
    "# (20, 2951) : 20 rows and 2951 columns.\n",
    "# There are new feature names. \n",
    "# \n",
    "# \n",
    "print(count_vect_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The raw data output of the count vector is called as the Sparse Vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x2951 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7096 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizers output sparse matrices\n",
    "#Sparse Matrix: A matrix in which most entries are 0. In the interest of efficient storage, \n",
    "#    a sparse matrix will be stored by only storing the locations of the non-zero elements.\n",
    "\n",
    "X_counts_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2941</th>\n",
       "      <th>2942</th>\n",
       "      <th>2943</th>\n",
       "      <th>2944</th>\n",
       "      <th>2945</th>\n",
       "      <th>2946</th>\n",
       "      <th>2947</th>\n",
       "      <th>2948</th>\n",
       "      <th>2949</th>\n",
       "      <th>2950</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 2951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6     7     8     9     ...  2941  \\\n",
       "0      1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4      1     1     0     0     0     0     0     0     0     0  ...     1   \n",
       "5      0     0     1     0     0     0     0     0     0     0  ...     0   \n",
       "6      1     0     0     0     1     1     1     0     1     1  ...     1   \n",
       "7      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "8      0     0     0     0     0     0     0     0     0     2  ...     0   \n",
       "9      0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "10     1     0     0     0     0     0     0     0     3     0  ...     0   \n",
       "11     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "12     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "13     0     0     0     1     0     0     0     0     0     0  ...     1   \n",
       "14     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "15     0     0     0     0     0     0     0     0     0     0  ...     1   \n",
       "16     0     0     0     0     0     0     0     0     1     0  ...     0   \n",
       "17     0     0     0     0     0     0     0     0     8     0  ...    12   \n",
       "18     0     0     0     0     1     0     0     1     0     1  ...     0   \n",
       "19     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "    2942  2943  2944  2945  2946  2947  2948  2949  2950  \n",
       "0      0     0     0     0     0     0     0     0     0  \n",
       "1      0     0     4     0     0     0     0     0     1  \n",
       "2      0     0     0     0     0     0     0     0     0  \n",
       "3      0     0     0     0     2     0     0     0     0  \n",
       "4      2     0     0     0     0     0     0     0     0  \n",
       "5      0     0     0     0     0     0     0     0     0  \n",
       "6      0     0     0     0     0     1     0     1     0  \n",
       "7      0     0     0     0     0     0     0     0     0  \n",
       "8      0     0     0     0     0     0     0     0     0  \n",
       "9      0     0     0     0     0     0     0     0     0  \n",
       "10     0     0     0     0     0     0     0     0     0  \n",
       "11     0     0     0     0     0     0     0     0     0  \n",
       "12     0     0     0     0     0     0     0     0     0  \n",
       "13     0     0     0     1     0     0     0     0     0  \n",
       "14     0     0     0     0     0     0     0     0     0  \n",
       "15     0     0     0     0     0     0     0     0     1  \n",
       "16     0     0     0     0     0     0     0     0     0  \n",
       "17     1     0     0     0     0     0     0     0     0  \n",
       "18     0     1     0     0     0     0     2     0     0  \n",
       "19     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[20 rows x 2951 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts_df = pd.DataFrame(X_counts_sample.toarray())\n",
    "X_counts_df\n",
    "\n",
    "# This is the document term Matrix. It has 2951 columns and 20 rows. \n",
    "# Values are numbered from 0 to 191 in the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>025</th>\n",
       "      <th>026</th>\n",
       "      <th>042</th>\n",
       "      <th>049</th>\n",
       "      <th>057</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>youv</th>\n",
       "      <th>yuje</th>\n",
       "      <th>yukon</th>\n",
       "      <th>z</th>\n",
       "      <th>zarychanski</th>\n",
       "      <th>zibi</th>\n",
       "      <th>ziomek</th>\n",
       "      <th>zmiyiwski</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 2951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       000  025  026  042  049  057  1  10  100  ...  your  youv  yuje  yukon  \\\n",
       "0   1    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "1   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      4   \n",
       "2   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "3   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "4   1    1    0    0    0    0    0  0   0    0  ...     1     2     0      0   \n",
       "5   0    0    1    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "6   1    0    0    0    1    1    1  0   1    1  ...     1     0     0      0   \n",
       "7   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "8   0    0    0    0    0    0    0  0   0    2  ...     0     0     0      0   \n",
       "9   0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "10  1    0    0    0    0    0    0  0   3    0  ...     0     0     0      0   \n",
       "11  0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "12  1    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "13  0    0    0    1    0    0    0  0   0    0  ...     1     0     0      0   \n",
       "14  1    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "15  0    0    0    0    0    0    0  0   0    0  ...     1     0     0      0   \n",
       "16  0    0    0    0    0    0    0  0   1    0  ...     0     0     0      0   \n",
       "17  0    0    0    0    0    0    0  0   8    0  ...    12     1     0      0   \n",
       "18  0    0    0    0    1    0    0  1   0    1  ...     0     0     1      0   \n",
       "19  0    0    0    0    0    0    0  0   0    0  ...     0     0     0      0   \n",
       "\n",
       "    z  zarychanski  zibi  ziomek  zmiyiwski  zone  \n",
       "0   0            0     0       0          0     0  \n",
       "1   0            0     0       0          0     1  \n",
       "2   0            0     0       0          0     0  \n",
       "3   0            2     0       0          0     0  \n",
       "4   0            0     0       0          0     0  \n",
       "5   0            0     0       0          0     0  \n",
       "6   0            0     1       0          1     0  \n",
       "7   0            0     0       0          0     0  \n",
       "8   0            0     0       0          0     0  \n",
       "9   0            0     0       0          0     0  \n",
       "10  0            0     0       0          0     0  \n",
       "11  0            0     0       0          0     0  \n",
       "12  0            0     0       0          0     0  \n",
       "13  1            0     0       0          0     0  \n",
       "14  0            0     0       0          0     0  \n",
       "15  0            0     0       0          0     1  \n",
       "16  0            0     0       0          0     0  \n",
       "17  0            0     0       0          0     0  \n",
       "18  0            0     0       2          0     0  \n",
       "19  0            0     0       0          0     0  \n",
       "\n",
       "[20 rows x 2951 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts_df.columns = count_vect_sample.get_feature_names()  # Assigning the feature names to the columns\n",
    "X_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words model:\n",
    "1.\tCount how many times does a word occur in each message (Known as term frequency) (TF)\n",
    "2.\tWeigh the counts, so that frequent tokens get lower weight (inverse document frequency)- (IDF)\n",
    "3.\tNormalize the vectors to unit length, to abstract from the original text length (L2 norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17331\n"
     ]
    }
   ],
   "source": [
    "# Might take awhile...\n",
    "train_data = df[0:1000]\n",
    "bow_transformer = CountVectorizer(analyzer=clean_text).fit(train_data['text'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "newstest1 = train_data['text'][3]\n",
    "#print(newstest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 172)\t1\n",
      "  (0, 223)\t1\n",
      "  (0, 332)\t1\n",
      "  (0, 368)\t1\n",
      "  (0, 434)\t1\n",
      "  (0, 645)\t2\n",
      "  (0, 706)\t1\n",
      "  (0, 739)\t1\n",
      "  (0, 777)\t1\n",
      "  (0, 1015)\t1\n",
      "  (0, 1263)\t1\n",
      "  (0, 1710)\t1\n",
      "  (0, 1713)\t1\n",
      "  (0, 1722)\t1\n",
      "  (0, 1751)\t2\n",
      "  (0, 1781)\t1\n",
      "  (0, 1793)\t1\n",
      "  (0, 1857)\t1\n",
      "  (0, 1864)\t1\n",
      "  (0, 1939)\t1\n",
      "  (0, 2026)\t2\n",
      "  (0, 2170)\t1\n",
      "  (0, 2190)\t1\n",
      "  (0, 2193)\t1\n",
      "  (0, 2213)\t3\n",
      "  :\t:\n",
      "  (0, 15848)\t4\n",
      "  (0, 15855)\t1\n",
      "  (0, 16075)\t1\n",
      "  (0, 16176)\t4\n",
      "  (0, 16300)\t1\n",
      "  (0, 16303)\t1\n",
      "  (0, 16319)\t2\n",
      "  (0, 16352)\t10\n",
      "  (0, 16433)\t1\n",
      "  (0, 16460)\t1\n",
      "  (0, 16558)\t2\n",
      "  (0, 16609)\t1\n",
      "  (0, 16700)\t1\n",
      "  (0, 16721)\t1\n",
      "  (0, 16743)\t2\n",
      "  (0, 16778)\t1\n",
      "  (0, 16804)\t1\n",
      "  (0, 16870)\t2\n",
      "  (0, 16910)\t1\n",
      "  (0, 16980)\t1\n",
      "  (0, 17011)\t1\n",
      "  (0, 17021)\t2\n",
      "  (0, 17036)\t4\n",
      "  (0, 17203)\t1\n",
      "  (0, 17269)\t2\n",
      "(1, 17331)\n"
     ]
    }
   ],
   "source": [
    "bowtest1 = bow_transformer.transform([newstest1])\n",
    "print(bowtest1)\n",
    "print(bowtest1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(bow_transformer.get_feature_names())\n",
    "#print(bow_transformer.get_feature_names()[9570])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_bows = bow_transformer.transform(train_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (1000, 17331)\n",
      "Amount of Non-Zero occurences:  260806\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', news_bows.shape)\n",
    "print('Amount of Non-Zero occurences: ', news_bows.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * news_bows.nnz / (news_bows.shape[0] * news_bows.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17269)\t0.13058072787464675\n",
      "  (0, 17203)\t0.0296249945017847\n",
      "  (0, 17036)\t0.0608861449974719\n",
      "  (0, 17021)\t0.0276023897036252\n",
      "  (0, 17011)\t0.026468178204935924\n",
      "  (0, 16980)\t0.041739948472949276\n",
      "  (0, 16910)\t0.03634719746060934\n",
      "  (0, 16870)\t0.044399747248866445\n",
      "  (0, 16804)\t0.017694428664810868\n",
      "  (0, 16778)\t0.013397644457302273\n",
      "  (0, 16743)\t0.03890585323985886\n",
      "  (0, 16721)\t0.03249554585605943\n",
      "  (0, 16700)\t0.02251463549972901\n",
      "  (0, 16609)\t0.0349787853183564\n",
      "  (0, 16558)\t0.025227955942080483\n",
      "  (0, 16460)\t0.029983397450680554\n",
      "  (0, 16433)\t0.03530198008474523\n",
      "  (0, 16352)\t0.31799164530439683\n",
      "  (0, 16319)\t0.03615701436040493\n",
      "  (0, 16303)\t0.03451465838070459\n",
      "  (0, 16300)\t0.024674975953548815\n",
      "  (0, 16176)\t0.08833841863248833\n",
      "  (0, 16075)\t0.06162151635796847\n",
      "  (0, 15855)\t0.049864965335699736\n",
      "  (0, 15848)\t0.15756705451835676\n",
      "  :\t:\n",
      "  (0, 2213)\t0.16604873998444136\n",
      "  (0, 2193)\t0.020511552193603216\n",
      "  (0, 2190)\t0.017303454619042147\n",
      "  (0, 2170)\t0.033250023634791376\n",
      "  (0, 2026)\t0.024135565049104336\n",
      "  (0, 1939)\t0.028948156361921724\n",
      "  (0, 1864)\t0.04078659474385927\n",
      "  (0, 1857)\t0.03261700394127664\n",
      "  (0, 1793)\t0.048353377872607094\n",
      "  (0, 1781)\t0.02945097968707959\n",
      "  (0, 1751)\t0.040895209982283076\n",
      "  (0, 1722)\t0.018687038383836858\n",
      "  (0, 1713)\t0.044919569260865995\n",
      "  (0, 1710)\t0.0539547488805437\n",
      "  (0, 1263)\t0.039654057110241836\n",
      "  (0, 1015)\t0.031152568703113486\n",
      "  (0, 777)\t0.06529036393732338\n",
      "  (0, 739)\t0.03379039262165257\n",
      "  (0, 706)\t0.02738030866688079\n",
      "  (0, 645)\t0.061491652905345466\n",
      "  (0, 434)\t0.06529036393732338\n",
      "  (0, 368)\t0.030261834542195068\n",
      "  (0, 332)\t0.03407318099552451\n",
      "  (0, 223)\t0.0590184275741687\n",
      "  (0, 172)\t0.06162151635796847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(news_bows)\n",
    "tfidf4 = tfidf_transformer.transform(bowtest1)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17331)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(news_bows)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(messages_tfidf, train_data['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: Cbc News\n",
      "expected: Cbc News\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', spam_detect_model.predict(tfidf4)[0])\n",
    "print('expected:', train_data.authors[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a classification to predict CBC News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' '' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' '' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' '' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' ''\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News' 'Cbc News' '' ''\n",
      " 'Cbc News' '' 'Cbc News' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' '' '' '' '' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " '' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' '' 'Cbc News' '' '' 'Cbc News' 'Cbc News' '' '' '' 'Cbc News'\n",
      " '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' '' 'Cbc News'\n",
      " '' 'Cbc News' '' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News' 'Cbc News'\n",
      " '' 'Cbc News' 'Cbc News' '' 'Cbc News' '' 'Cbc News' 'Cbc News'\n",
      " 'Cbc News' 'Cbc News' '' '' 'Cbc News' 'Cbc News']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detect_model.predict(messages_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                            precision    recall  f1-score   support\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.80      0.51      0.62       270\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                 \"Rosemary Barton Is CbcS Chief Political Correspondent\", Based In Ottawa.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                \"Ryan Cooke Works For Cbc Out Of Its Bureau In St. JohnS.\", Read More Articles This Author       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                         \"Tori Weldon Is A Reporter Based In Moncton. SheS Been Working For The Cbc Since\"       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                          Adam Carter Is A Newfoundlander Who Now Calls Toronto Home. He Enjoys A Good Story, Playing Loud Music. You Can Follow Him On Twitter, Adamcartercbc Or Drop Him An Email At Adam.Carter Cbc.Ca.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                             Adam Hunter Is The Provincial Affairs Reporter At Cbc Saskatchewan, Based In Regina. He Has Been With Cbc For Years. He Hosts The Cbc Podcast On The Ledge. Follow Him On Twitter, Ahiddycbc. Contact Him, Adam.Hunter Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                              Alanna Petroff Is A Freelance Reporter Based In London. She Has Covered Business, Economic, International News For The Past Decade At Outlets Such As Reuters, Cnn, The Bbc.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                        Alex Soloducha Is A Reporter For Cbc Saskatchewan.       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                                                                   Alicia Bridges Is A Digital, Broadcast Journalist At Cbc Saskatoon. Email Her At Alicia.Bridges Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                         American Politics Contributor, Keith Boag Writes About American Politics, Issues That Shape The American Experience. Keith Was Based For Several Years In Los Angeles, Now, In Retirement After A Long Career With Cbc News, Continues To Live In Washington, D.C. Earlier, Keith Reported Ottawa, Where He Served As Chief Political Correspondent For Cbc News.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                         Andrea Bellemare Is A Reporter, Producer With Cbc News Who Currently Focuses On Disinformation, Tech, Privacy., She Helped Launch The New Cbc Kitchener-Waterloo Radio Station In, Reported For Cbc Montreal, Produced Radio Docs For Cbc Radio. She Has Also Reported For The Wire Service Agence France-Presse.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                Angela Gemmill Is A Cbc Journalist Who Has Covered News In Sudbury, Ont., For Years. Connect With Her On Twitter, Angelagemmill. Send Story Ideas To Angela.Gemmill Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                             Anjuli Patil Is A Reporter, \"Occasional Video Journalist With Cbc Nova ScotiaS Digital Team.\"       0.00      0.00      0.00         2\n",
      "                                                                                                                   Ap Journalist, Heidi Atter Is A Journalist Working In Regina. She Started With Cbc Saskatchewan After A Successful Internship, Has A Passion For Character-Driven Stories. Heidi Has Worked As A Reporter, Web Writer, Associate Producer, Show Director So Far, Has Worked In Edmonton, At The Wainwright Military Base, In Adazi, Latvia. Story Ideas       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                               Ariana Kelland Is A Reporter With The Cbc Newfoundland, \"Labrador Bureau In St. JohnS.\", More This Author, Follow Ariana Kelland On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                  Asia Correspondent, \"Saša Petricic Is The CbcS Asia Correspondent\", Based In Beijing. He Has Covered China As Well As Reported North, South Korea. He Previously Reported On The Middle East, Jerusalem, Through The Arab Spring, The Syrian Civil War. He Has Filed Stories Every Continent For Cbc News. Instagram, More Saša Petricic       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                  Associate Producer Technician, Danelle Cloutier Is An Associate Producer, Audio Technician In Current Affairs At Cbc Manitoba. She Has A Background In Audio Engineering       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                        Bill Graveland Is A Calgary-Based Reporter For The Canadian Press.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                       Brian Rodgers Is A Videojournalist, Producer With Cbc Saskatchewan.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                 Briar Stewart Is A Senior Reporter With Cbc News., For More Than A Decade, She Has Been Covering Stories For Television, Radio, Online., She Is Based In Vancouver, Can Be Reached At Briar.Stewart Cbc.Ca, Or On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                    Bridget Yard Is A Video Journalist Based In Saskatoon. She Has Also Worked For Cbc In Fredericton, Bathurst, Follow Bridget On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                     Bryce Hoye Is An Award-Winning Journalist, Science Writer With A Background In Wildlife Biology, Interests In Courts, Social Justice, Health, More. He Is The Prairie Rep For Outcbc. Story Idea, Email Bryce.Hoye Cbc.Ca., Email, Bryce.Hoye Cbc.Ca, More Bryce Hoye       0.00      0.00      0.00         1\n",
      "                                                                            Business Columnist, Don Pittis Was A Forest Firefighter, \"A Ranger In CanadaS High Arctic Islands. After Moving Into Journalism\", He Was Principal Business Reporter For Radio Television Hong Kong Before The Handover To China. He Has Produced, Reported For The Cbc In Saskatchewan, Toronto, \"The Bbc In London. He Is Currently Senior Producer At CbcS Business Unit.\", More Don Pittis       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                         Business Reporter, Sophia Harris Covers Business, Consumer News., Contact, Sophia.Harris Cbc.Ca, More This Author       0.00      0.00      0.00         7\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                        Cbc Communications       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                            Cbc Investigates, Katie Nicholson Is A Senior Reporter With Cbc Investigates Based In Toronto.       0.00      0.00      0.00         1\n",
      "                                                                                                                                             Cbc Investigative Journalist, Jonathon Gatehouse Has Covered News, Politics At Home, Abroad, Reporting Dozens Of Countries. He Has Also Written Extensively About Sports, Covering Seven Olympic Games, Authoring A Best-Selling Book On The Business Of Pro-Hockey. He Works For The National Investigative Unit In Toronto.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Cbc News       0.38      1.00      0.55       318\n",
      "                                                                                                                                                                                    Cbc News New York, \"Steven DSouza Is A Gemini-Nominated Journalist Based In New York City. He Has Reported Internationally The Papal Conclave In Rome\", The World Cup In Brazil, He Spent Eight Years In Toronto Covering Stories Like The Protests, The Rob Ford Crack Video Scandal.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                               Cbc News, \"David Cochrane Is A Senior Reporter In CbcS Parliamentary Bureau. He Previously Wrote For Cbc Newfoundland\", Follow David Cochrane On Twitter, Read More Articles David Cochrane       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                      Cbc Reporter, Brady Strachan Is A Cbc Reporter Based In Kelowna, B.C. Besides Kelowna, Strachan Has Covered Stories For Cbc News In Winnipeg, Brandon, Vancouver, Internationally. Follow His Tweets       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                              Cbc Staff, Alvin Yu Splits His Time Along The Corridor As A Reporter For Cbc London, Associate Producer For Cbc Toronto, The National. Yu Set His Sights On Journalism Early - As A Kid He Would Anchor The News In The Shower, Hoping One Day To Make It To The Big Screen.       0.00      0.00      0.00         5\n",
      "                                                                                                                                                                                                                                                                                                                                City Hall Reporter, Lauren Pelley Is A Cbc Reporter In Toronto Covering City Hall, Municipal Affairs. Contact Her At, Lauren.Pelley Cbc.Ca       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                         Colleen M. Flood Is Director Of The Centre For Health Law, Policy, Ethics, University Research Chair At The University Of Ottawa.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                           Dan Mcgarvey Is A Mobile Journalist Focused On Filing Stories Remotely For Cbc Calgary S Web, Radio, Tv, Social Media Platforms, Only Using An Iphone, Mobile Tech. You Can Email Story Ideas, Tips To Dan At, Dan.Mcgarvey Cbc.Ca Or Tweet Him       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                             Dan Zakreski Is A Reporter For Cbc Saskatoon.       0.00      0.00      0.00         3\n",
      "Defence, Murray Brewster Is Senior Defence Writer For Cbc News, Based In Ottawa. He Has Covered The Canadian Military, Foreign Policy Parliament Hill For Over A Decade. Among Other Assignments, He Spent A Total Of Months On The Ground Covering The Afghan War For The Canadian Press. Prior To That, He Covered Defence Issues, Politics For Cp In Nova Scotia For Years, Was Bureau Chief For Standard Broadcast News In Ottawa., Follow, Murray_Brewster On Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                             Dr. Vivek Goel Was The Founding Head Of Public Health Ontario, Set Up In Response To The Sars Crisis. He Is Currently A Professor At The University Of Toronto S Dalla Lana School Of Public Health, Vice-President Of Research, Innovation, Strategic Initiatives At U Of T.       0.00      0.00      0.00         1\n",
      "                                                                                                                                        Drew Anderson Is A Web Journalist At Cbc Calgary. Like Almost Every Journalist Working Today, \"HeS Won A Few Awards. HeS Also A Third-Generation Calgarian.\", You Can Follow Him On Twitter, Drewpanderson. Contact Him In Confidence At Drew.Anderson Cbc.Ca. Signal Contact Upon Request. Cbc Secure Drop, Www.Cbc.Ca Securedrop       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                   Elizabeth Chiu Is A Reporter In Nova Scotia, Hosts Atlantic Tonight On Saturdays At P.M., P.M. In Newfoundland. If You Have A Story Idea For Her, Contact Her At Elizabeth.Chiu Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                 Erik White Is A Cbc Journalist Based In Sudbury. He Covers A Wide Range Of Stories About Northern Ontario. Connect With Him On Twitter, Erikjwhite. Send Story Ideas To Erik.White Cbc.Ca       0.00      0.00      0.00         5\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                       Franca G. Mignacca Is A Journalist At Cbc Montreal.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                     Hadeel Ibrahim Is A Cbc Reporter Based Out Of Saint John. She Can Be Reached At Hadeel.Ibrahim Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                   Health Writer, Amina Zafar Has Covered Health, Medical, Science News At Cbc Since She Has A Degree In Environmental Science, \"A MasterS In Journalism.\"       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                       Holly Conners Is A Reporter, Current Affairs Producer Who Has Been With Cbc Cape Breton Since, Contact Her At Holly.Conners Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                  Host Of Afternoon Drive, \"Chris Dela Torre Is The Host Of Afternoon Drive On Cbc Radio One In Southwestern Ontario. HeS Worked As A Host\", Reporter, Producer In Several Cities Across Canada, Has Hosted Several Cbc Network Programs, Such As Q, Dnto, The Story Here.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                 Ian Froese Is A Reporter With Cbc Manitoba. He Has Previously Worked For Newspapers In Brandon, Steinbach. Story Idea, Email, Ian.Froese Cbc.Ca., Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                     Investigative Journalist, \"Timothy Sawa Works For CbcS Investigative Unit\", The Fifth Estate, Has Been An Investigative Journalist At Cbc News For More Than A Decade. He Has Produced Investigations Looking At Police Corruption, Sexual Abuse In Public Institutions, Offshore Tax Evasion., Cbc News Investigates       0.00      0.00      0.00         1\n",
      "                   Investigative Reporter, Cbc Manitoba I-Team, Caroline Began Her Career Co-Hosting An Internet Radio Talk Show In Toronto, Then Worked At Various Stations In Oshawa, Sudbury, Toronto Before Landing In Winnipeg In Since Joining Cbc Manitoba As A Reporter In, She Has Won An Award For Her Work On Crowded Jails, \"Her Investigation Into Tina FontaineS Death Led To Changes In The Child Welfare System. Email\", Caroline.Barghout Cbc.Ca, Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                              Investigative Reporter, Jennie Russell Is A Reporter With Cbc Investigates, The Award-Winning Investigative Unit Of Cbc Edmonton. Jennie Specializes In Accountability Journalism, Her Work Has Been Widely Credited With Forcing Transparency, Democratic Change In Alberta. Contact Jennie At Jennie.Russell Cbc.Ca, Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                               Jack Julian Joined Cbc Nova Scotia As An Arts Reporter In His News Career Began On The Morning Of Sept., Following The Crash Of Swissair He Is Now A Data Journalist In Halifax, You Can Reach Him At, Email At Jack.Julian Cbc.Ca Or Follow Him On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                 Jackie Mckay Is A Métis Journalist Working For Cbc In Nunavut. She Has Worked As A Reporter In Thunder Bay, Yellowknife, Whitehorse, Iqaluit. Jackie Also Worked On Cbc Radio One Shows Including The Current, Metro Morning After Graduating Ryerson University In Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                        Jason Viau Is A Video Journalist, Tv Host, Radio Newsreader At Cbc Windsor. He Was Born In North Bay, But Has Lived In Windsor For Most Of His Life. Since Graduating St. Clair College, \"HeS Worked In Print\", Tv, Radio. Email Him At Jason.Viau Cbc.Ca, Follow Jason On Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                      Jim Agapito Is A Filipino Filmmaker Winnipeg. Jim Writes, Boxes, Takes Photos, Sings In A Punk Band.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                         Joe Tunney Reports For Cbc News In Ottawa. He Can Be Reached At Joe.Tunney Cbc.Ca       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                                                                            Joel Ballard Is A Reporter With The Cbc In Vancouver. You Can Reach Him At Joel.Ballard Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                  Joel Joined Cbc Calgary In Reach Him Email At Joel.Dryden Cbc.Ca, Follow Joel On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                              Jonathan Montpetit Is A Journalist With Cbc Montreal., Follow Him On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                            Jorge Barrera Is A Caracas-Born, Award-Winning Journalist Who Has Worked Across The Country, \"Internationally. He Works For CbcS Indigenous Unit Based Out Of Ottawa. Follow Him On Twitter\", Jorgebarrera Or Email Him Jorge.Barrera Cbc.Ca., Follow, Jorgebarrera On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                               Leah Hendry Is A Tv, Radio, Online Journalist With Cbc Montreal Investigates. Contact Her Via Our Confidential Tipline, Or On Email At Montrealinvestigates Cbc.Ca., Follow Leah On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                            Lenard Monkman Is Anishinaabe Lake Manitoba First Nation, Treaty Territory. He Is The Co-Founder Of Red Rising Magazine, \"Has Been An Associate Producer With The CbcS Indigenous Unit For Three Years. Follow Him On Twitter\"       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                            Lien Yeung Hosts Cbc Vancouver News Weekends. As A Multimedia Reporter, She Has Covered Stories Locally, Nationally Coast To Coast On Television, Radio, Social Media. You Can Reach Her On Instagram Or Twitter, Lienyeung Or Via Email At Lien.Yeung Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                Lucie Edwardson Is A Reporter With Cbc Calgary, Currently Focused On Bringing You Stories Related To Education In Alberta. In She Headed A Pop-Up Bureau In Lethbridge, Alta . Her Experience Includes Newspaper, Online, Tv, Radio. Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                    Mandy Luk Is A Senior Producer With Cbc News. She Holds A Journalism Degree The Chinese University Of Hong Kong, \"A MasterS Degree In Economics The University Of Toronto. Programs She Has Worked For Include Cbc News Network\", The National, Cross Country Checkup.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                Mark Gollom Is A Toronto-Based Reporter With Cbc News. He Covers Canadian, U.S. Politics, Current Affairs.       0.00      0.00      0.00         5\n",
      "                                                                                                                                                                                                                                                               Medical Science, Kelly Crowe Is A Science Correspondent For Cbc News. She Joined Cbc In, Has Spent Years Reporting On A Wide Range Of National News, Current Affairs, With A Particular Interest In Science       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                            Moscow Correspondent, Chris Brown Is A Foreign Correspondent Based In The Cbc S Moscow Bureau. Previously A National Reporter For Cbc News On Radio, Tv, Online, Chris Has A Passion For Great Stories, Has Travelled All Over Canada, The World To Find Them.       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                     Natalia Is A Multi-Platform Journalist In Ottawa. She Has Also Worked For Cbc In P.E.I., Newfoundland       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                Nicholas Frew Is An Online Reporter Based In Winnipeg. Hailing Newfoundland, Frew Moved To Halifax To Attend Journalism School Before Moving To Winnipeg. Prior To Joining Cbc Manitoba, Frew Interned At The Winnipeg Free Press. Story Idea, Email At Nick.Frew Cbc.Ca, Email, Nick.Frew Cbc.Ca, Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                           Nicola Macleod Is A Reporter With Cbc In P.E.I.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                       Parliament Hill Bureau, Aaron Wherry Has Covered Parliament Hill Since, \"Has Written For MacleanS\", The National Post, The Globe, Mail. He Is The Author Of Promise, Peril, \"A Book About Justin TrudeauS Years In Power.\", Follow Aaron On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                Parliamentary Bureau, John Paul, J.P., \"Tasker Is A Reporter In The CbcS Parliamentary Bureau In Ottawa. He Can Be Reached At John.Tasker Cbc.Ca.\", Follow J.P. On Twitter       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                   Paul Withers Is An Award-Winning Journalist Whose Career Started In The As A Cartoonist. He Has Been Covering Nova Scotia Politics For More Than Years.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                             Politics, Éric Grenier Is A Senior Writer, \"The CbcS Polls Analyst. He Was The Founder Of Threehundredeight.Com\", Has Written For The Globe, Mail, Huffington Post Canada, The Hill Times, Le Devoir, L Actualité., Read More Cbcnews.Ca Columns Éric Grenier       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                            Preston Mulligan Has Been A Reporter In The Maritimes For More Than Years. Along With His Reporting Gig, \"He Also Hosts Cbc RadioS Sunday Phone-In Show\", Maritime Connection.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                        Prince Edward Island, Wayne Thibodeau Is A Reporter Editor With Cbc Prince Edward Island. He Has Worked As A Reporter, Editor, Photographer, Video Journalist In Print, Digital, Tv For More Than Years. He Can Be Reached At Wayne.Thibodeau Cbc.Ca, Follow, Jwaynecbc On Twitter       0.00      0.00      0.00         2\n",
      "                                                                               Producer, Cbc News Business, James Dunne Researches, Produces, Writes Stories For The Business Unit At Cbc News. He Has A Decade Of Experience In Business Programming, Including On The Shows Venture, Fortune Hunters. An Award-Winning Videojournalist, \"HeS Also Worked On Special Projects\", As The Late Lineup Editor For The World At Six On Cbc Radio One., James Dunne On Linkedin       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                Producer, The Fifth Estate, Scott Anderson Is A Producer At The Fifth Estate. He Has Been An Investigative Journalist In Both Print, Broadcast. He Has Covered Stories At City Hall, Across The Country, Around The World.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                      Provincial Affairs Reporter Covering The B.C. Legislature. Anything Political, Tanya.Fletcher Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                  Provincial Affairs Reporter, Mike Crawley Is Provincial Affairs Reporter In Ontario For Cbc News. He Has Won Awards For His Reporting On The Ehealth Spending Scandal, \"Flaws In OntarioS Welfare-Payment Computer System. Before Joining The Cbc In\", Mike Filed Stories Countries In Africa As A Freelance Journalist, Worked As A Newspaper Reporter In B.C., Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                            Rachel Ward Is A Journalist With Cbc Calgary. You Can Reach Her With Questions Or Story Ideas At Rachel.Ward Cbc.Ca., Follow Rachel On Twitter       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                           Rafferty Baker Is A Video Journalist With Cbc News, Based In Vancouver. You Can Find His Stories On Cbc Radio, Television, Online At Cbc.Ca Bc.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                          Renée Is A Cbc Correspondent Based In London, U.K., She Has Spent A Decade With The Organization In A Number Of Roles, Including Senior Business Reporter, Weekend News Anchor, Television, Radio Reporter, Associate Producer, Program Director       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                            Reporter Associate Producer, Emily Pasiuk Is A Reporter For Cbc Saskatchewan, \"An Associate Producer For The Morning Edition. SheS Based In Regina. She Has Also Reported At Ctv Saskatoon\", Written For Global Regina. Reach Her At Emily.Pasiuk Cbc.Ca., Find Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                        Reporter Editor, \"Elizabeth Fraser Is A Reporter Editor With Cbc New Brunswick Based In Fredericton. SheS Originally Manitoba. Story Tip\", Elizabeth.Fraser Cbc.Ca       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                         Reporter Editor, Alex Is A Reporter Living In Halifax. Send Her Story Ideas At Alex.Cooke Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                       Reporter Editor, Bobhristova Is A Reporter Editor With Cbc Hamilton. Email, Bobby.Hristova Cbc.Ca, Follow, Bobbyhristova On Twitter       0.00      0.00      0.00         5\n",
      "                                                                                                                                                            Reporter Editor, Darren Bernhardt Spent The First Dozen Years Of His Journalism Career In Newspapers, First At The Regina Leader-Post Then The Saskatoon Starphoenix. He Has Been With Cbc Manitoba Since, Specializes In Offbeat, Local History Stories, Features. Story Idea, Email, Darren.Bernhardt Cbc.Ca       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                                                                                                                                                               Reporter Editor, Jennifer La Grassa Is A Reporter Editor For Cbc Hamilton. Email, Jennifer.Lagrassa Cbc.Ca, Follow, Jennlagrassa On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                 Reporter Editor, Tom Ayers Has Been A Reporter, Editor For More Than Years. He Has Spent The Last Years Covering Cape Breton, Nova Scotia Stories. You Can Reach Him At Tom.Ayers Cbc.Ca.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                         Reporter The Canadian Press, Stephanie Taylor Is A Canadian Press Reporter Based In Saskatchewan.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                       Reporter, Web Writer For Cbc Saskatoon, Story Tips, Ideas Welcomed At Guy.Quenneville Cbc.Ca, Follow Guy On Twitter       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                           Sam Samson Is A Multimedia Journalist Who Has Worked For Cbc In Manitoba, Ontario As A Reporter, Associate Producer. Before Working For Cbc, She Studied Journalism, Communications In Winnipeg. You Can Get In Touch On Twitter, Cbcsamsamson Or Email Samantha.Samson Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                Sanjay Maru Is A Reporter At Cbc Windsor. Email Him At Sanjay.Maru Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                 Sarah Leavitt Is A Journalist With Cbc Montreal., Follow Sarah On Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                             Sarah Rieger Joined Cbc Calgary As An Online Journalist In You Can Reach Her Email At Sarah.Rieger Cbc.Ca., Follow Sarah On Twitter, Read More Articles Sarah       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                        Science, Technology Writer, Emily Chung Covers Science, Technology For Cbc News. She Has Previously Worked As A Digital Journalist For Cbc Ottawa, \"As An Occasional Producer At CbcS Quirks\", Quarks. She Has A Phd In Chemistry.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                      Senior Producer Western Digital Business Unit, \"Tony Seskus Is Senior Producer With CbcS Western Business Unit In Calgary. HeS Written For Newspapers\", Wire Services For More Than Years On Three Continents. In Calgary, Tony Has Reported On The Energy Sector, Federal Politics.       0.00      0.00      0.00         2\n",
      "                                                                                                 Senior Reporter, Award-Winning Reporter Elizabeth Thompson Covers Parliament Hill. A Veteran Of The Montreal Gazette, Sun Media, Ipolitics, \"She Currently Works With The CbcS Ottawa Bureau\", Specializing In Investigative Reporting, Data Journalism. She Can Be Reached At, Elizabeth.Thompson Cbc.Ca., More Elizabeth Thompson, Follow Elizabeth Thompson On Twitter       0.00      0.00      0.00         3\n",
      "                                                                                                                                                              Senior Reporter, Bonnie Allen Is A Senior Reporter For Cbc News Based In Saskatchewan. Before Returning To Canada In, Allen Spent Four Years Reporting Across Africa, Including Libya, South Sudan, Liberia, \"Sierra Leone. She Holds A MasterS In International Human Rights Law The University Of Oxford.\"       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                           Senior Reporter, Julie Ireton Is A Senior Reporter Who Works On Investigations, \"Enterprise News Features At Cbc Ottawa. SheS Also The Host Of The New Cbc Investigative Podcast\", The Band Played On. You Can Reach Her At Julie.Ireton Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                  Senior Writer, \"Adam Miller Is Senior Digital Writer With Cbc News. HeS Covered Health\", Politics, Breaking News Extensively In Canada, In Addition To Several Years Reporting On News, Current Affairs Throughout Asia.       0.00      0.00      0.00         8\n",
      "                                                                                                                                                                                                                                                                                                                  Senior Writer, \"Kathleen Harris Is A Senior Writer In The CbcS Parliament Hill Bureau. She Covers Politics\", Immigration, Justice, Follow Her On Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                   Senior Writer, Pete Evans Is The Senior Business Writer For Cbcnews.Ca. Prior To Coming To The Cbc, His Work Has Appeared In The Globe, Mail, The Financial Post, The Toronto Star, Canadian Business Magazine, Believe It Or Not, Circuits Assembly Magazine., Twitter       0.00      0.00      0.00         8\n",
      "                                                                                                                                                                                                                                                                                                            Shaina Luck Covers Everything Court To City Council. Her Favourite Stories Are About Ordinary People In Extraordinary Circumstances. Email, Shaina.Luck Cbc.Ca       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                          Shane Magee Is A Moncton-Based Reporter For Cbc.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                            Taryn Grant Is A Halifax-Based Reporter For Cbc Nova Scotia. Get In Touch With Her Email At Taryn.Grant Cbc.Ca       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                      The Associated Press       0.00      0.00      0.00       100\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                        The Canadian Press       0.00      0.00      0.00        28\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                           Thomson Reuters       0.00      0.00      0.00        61\n",
      "                                                                                                                                                                                                                                                                                                                                                          Tony Davis Grew Up On P.E.I., Studied Journalism At Holland College. He Can Be Contacted At Anthony.Davis Cbc.Ca       0.00      0.00      0.00         1\n",
      "                                                                                                                                                            Tory Gillis Began Work As A Journalist With Cbc Saskatchewan In You Can Hear Her Deliver The Afternoon News On Weekdays On Cbc Radio One In Saskatchewan. She Has Also Worked As A Reporter, \"As An Associate Producer On Cbc SaskatchewanS Radio Shows\", The Morning Edition, Bluesky, The Afternoon Edition.       0.00      0.00      0.00         2\n",
      "                                                                                                                                                                                                                                                                                Video Journalist, \"Colin Butler Is A Veteran Cbc Reporter WhoS Worked In Moncton\", Saint John, Fredericton, Toronto, Kitchener-Waterloo, Hamilton, London, Ont. Email, Colin.Butler Cbc.Ca       0.00      0.00      0.00         6\n",
      "                                                                                                                                                                                                                                     Web Writer, \"Creeden Martell Is A Cree Journalist The Waterhen Lake First Nation. He Works For Cbc Saskatchewan In Regina. He Has Also Written For The University Of ReginaS Jschool\", The Saskatoon Starphoenix, Vice News., Twitter       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                           Web Writer, Sam Juric Is A Journalist With Cbc P.E.I., Can Be Reached At Samantha.Juric Cbc.Ca.       0.00      0.00      0.00         1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                       Winnipeg Free Press       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                           Yvette Brend Is A Cbc Vancouver Journalist. Yvette.Brend Cbc.Ca       0.00      0.00      0.00         3\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  accuracy                           0.46      1000\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                 macro avg       0.01      0.01      0.01      1000\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                              weighted avg       0.34      0.46      0.34      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(train_data['authors'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data  = df[1001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.punkt import PunktLanguageVars\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "      <td>[canadian, pharmacy, limiting, much, medicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "      <td>[yukon, government, identified, two, place, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "      <td>[senat, late, wednesday, pass, unparallel, 22,...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                              title  \\\n",
       "0               cbc  Coronavirus a 'wake-up call' for Canada's pres...   \n",
       "1               cbc  Yukon gov't names 2 possible sources of corona...   \n",
       "2  associated press  U.S. Senate passes $2T coronavirus relief package   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "2  [senate, late, wednesday, passed, unparalleled...   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...   \n",
       "1  [yukon, govern, identifi, two, place, whitehor...   \n",
       "2  [senat, late, wednesday, pass, unparallel, 22,...   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [canadian, pharmacy, limiting, much, medicatio...  \n",
       "1  [yukon, government, identified, two, place, wh...  \n",
       "2  [senate, late, wednesday, passed, unparalleled...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['body_text_clean'].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_specials_string = re.sub('[!#?,.:\";]', '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_specials_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=PunktLanguageVars()\n",
    "tokens=p.word_tokenize(no_specials_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in h\n",
      "h 3563\n",
      "3563 Its\n",
      "Its a\n",
      "a relic\n",
      "relic of\n",
      "of a\n",
      "a bygone\n",
      "bygone era\n",
      "era when\n",
      "when wealthy\n",
      "wealthy Nova\n",
      "Nova 3564\n",
      "3564 Camels\n",
      "Camels have\n",
      "have been\n",
      "been implicated\n",
      "implicated in\n",
      "in a\n",
      "a Middle\n",
      "Middle Easter\n",
      "Easter 3565\n",
      "3565 A\n",
      "A World\n",
      "World Health\n",
      "Health Organizationled\n",
      "Organizationled group\n",
      "group of\n",
      "of expert\n"
     ]
    }
   ],
   "source": [
    "# See the last 10 pairs\n",
    "for i in range(len(tokens)-30, len(tokens)-1):\n",
    "    print(tokens[i], tokens[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31854\n",
      "19823\n",
      "[('Isobel', 'Mackenzie'), ('and', 'first'), ('d', '206'), ('more', 'p'), ('1472', 'It'), ('Friday', 'Kraft'), ('Windsor', 'announced'), ('diamond', 'mine'), ('toward', 'the'), ('a', 'hug'), ('3361', 'Canadians'), ('Algonquin', 'First'), ('of', 'phishing'), ('Rosa', 'desperately'), ('The', 'Brewer'), ('anchored', 'just'), ('on', '1588'), ('2333', 'Manitobans'), ('fourthquarter', '2764'), ('ongo', '495'), ('Follow', 'the'), ('manslaughter', 'and'), ('ma', '1970'), ('April', 'is'), ('has', 'added'), ('and', 'vaccines'), ('1882', 'Its'), ('pos', '182'), ('stood', 'shoulder'), ('As', 'country'), ('82', 'A'), ('coronavirus', 'pandemic'), ('call', 'centre'), ('declared', 'a'), ('are', 'working'), ('i', '2799'), ('su', '2128'), ('in', 'Greater'), ('provincial', 'telephone'), ('2894', 'Last'), ('its', 'final'), ('COVID', '3210'), ('The', 'death'), ('since', 'an'), ('Halton', 'Region'), ('1651', 'An'), ('Hes', 'a'), ('to', '1420'), ('Some', 'who'), ('PE', '337')]\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [(tokens[i], tokens[i+1]) for i in range(len(tokens)-1)]\n",
    "print(len(word_pairs))\n",
    "\n",
    "gram2 = set(word_pairs)\n",
    "print(len(gram2))\n",
    "\n",
    "# Print 20 elements from gram2\n",
    "gram2_iter = iter(gram2)\n",
    "print([next(gram2_iter) for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 'Canadian'), ('1', '983'), ('1', 'The'), ('1', 'a'), ('1', 'milli'), ('10', '870'), ('10', '874'), ('10', 'Read'), ('10', 'Three'), ('10', 'billion'), ('10', 'cities'), ('10', 'days'), ('10', 'metal'), ('10', 'people'), ('100', 'Calgarians'), ('100', 'Ford'), ('100', 'm'), ('100', 'people'), ('1000', 'In'), ('1000', 'a'), ('1000', '—'), ('100000', 'globa'), ('1001', 'Beverly'), ('1002', 'When'), ('1003', 'The'), ('1004', 'Getting'), ('1005', 'Murray'), ('1006', 'For'), ('1007', 'Prime'), ('1008', 'Youve'), ('1009', 'On'), ('101', 'The'), ('1010', 'Music'), ('1011', 'Youve'), ('1012', 'The'), ('1013', 'Ottawa'), ('1014', 'Alberta'), ('1015', 'The'), ('1016', 'The'), ('1017', 'As'), ('1018', 'Gunmen'), ('1019', 'Provincial'), ('102', 'Starbucks'), ('1020', 'BC'), ('1021', 'CALGARY'), ('1022', 'As'), ('1023', 'Premier'), ('1024', 'Starting'), ('1025', 'After'), ('1026', 'Some')]\n"
     ]
    }
   ],
   "source": [
    "gram2 = dict()\n",
    "\n",
    "# Populate 2-gram dictionary\n",
    "for i in range(len(tokens)-1):\n",
    "    key = (tokens[i], tokens[i+1])\n",
    "    if key in gram2:\n",
    "        gram2[key] += 1\n",
    "    else:\n",
    "        gram2[key] = 1\n",
    "\n",
    "# Turn into a list of (word, count) sorted by count from most to least\n",
    "\n",
    "gram2 = sorted(gram2, key=lambda count: count)\n",
    "\n",
    "# Print top 20 most frequent words\n",
    "print(gram2[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Canadian'),\n",
       " ('Canadian', 'pharmacies'),\n",
       " ('pharmacies', 'are'),\n",
       " ('are', 'limiting'),\n",
       " ('limiting', 'how'),\n",
       " ('how', 'much'),\n",
       " ('much', 'medi'),\n",
       " ('medi', '1'),\n",
       " ('1', 'The'),\n",
       " ('The', 'Yukon'),\n",
       " ('Yukon', 'government'),\n",
       " ('government', 'has'),\n",
       " ('has', 'identified'),\n",
       " ('identified', 'two'),\n",
       " ('two', 'places'),\n",
       " ('places', '2'),\n",
       " ('2', 'The'),\n",
       " ('The', 'Senate'),\n",
       " ('Senate', 'late'),\n",
       " ('late', 'Wednesday'),\n",
       " ('Wednesday', 'passed'),\n",
       " ('passed', 'an'),\n",
       " ('an', 'unparallel'),\n",
       " ('unparallel', '3'),\n",
       " ('3', 'Scientists'),\n",
       " ('Scientists', 'around'),\n",
       " ('around', 'the'),\n",
       " ('the', 'world'),\n",
       " ('world', 'are'),\n",
       " ('are', 'racing'),\n",
       " ('racing', 'to'),\n",
       " ('to', 'find'),\n",
       " ('find', '4'),\n",
       " ('4', 'Trudeau'),\n",
       " ('Trudeau', 'says'),\n",
       " ('says', 'rules'),\n",
       " ('rules', 'of'),\n",
       " ('of', 'Quarantine'),\n",
       " ('Quarantine', 'Act'),\n",
       " ('Act', 'will'),\n",
       " ('will', '5'),\n",
       " ('5', 'The'),\n",
       " ('The', 'continued'),\n",
       " ('continued', 'existence'),\n",
       " ('existence', 'of'),\n",
       " ('of', 'wildlife'),\n",
       " ('wildlife', 'markets'),\n",
       " ('markets', 'wh'),\n",
       " ('wh', '6'),\n",
       " ('6', 'Recent'),\n",
       " ('Recent', 'developments'),\n",
       " ('developments', 'Two'),\n",
       " ('Two', 'new'),\n",
       " ('new', 'cases'),\n",
       " ('cases', 'in'),\n",
       " ('in', 'western'),\n",
       " ('western', '7'),\n",
       " ('7', 'Michigan'),\n",
       " ('Michigan', 'hospitals'),\n",
       " ('hospitals', 'are'),\n",
       " ('are', 'bracing'),\n",
       " ('bracing', 'for'),\n",
       " ('for', 'a'),\n",
       " ('a', 'surge'),\n",
       " ('surge', 'of'),\n",
       " ('of', '8'),\n",
       " ('8', 'The'),\n",
       " ('The', 'number'),\n",
       " ('number', 'of'),\n",
       " ('of', 'confirmed'),\n",
       " ('confirmed', 'COVID19'),\n",
       " ('COVID19', 'cases'),\n",
       " ('cases', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'U'),\n",
       " ('U', '9'),\n",
       " ('9', 'The'),\n",
       " ('The', 'Jewish'),\n",
       " ('Jewish', 'General'),\n",
       " ('General', 'Hospital'),\n",
       " ('Hospital', 'plans'),\n",
       " ('plans', 'to'),\n",
       " ('to', 'set'),\n",
       " ('set', 'up'),\n",
       " ('up', 'tr'),\n",
       " ('tr', '10'),\n",
       " ('10', 'Three'),\n",
       " ('Three', 'Saskatchewan'),\n",
       " ('Saskatchewan', 'residents'),\n",
       " ('residents', 'have'),\n",
       " ('have', 'recovered'),\n",
       " ('recovered', 'f'),\n",
       " ('f', '11'),\n",
       " ('11', 'A'),\n",
       " ('A', 'Manitoba'),\n",
       " ('Manitoba', 'chiefs'),\n",
       " ('chiefs', 'organization'),\n",
       " ('organization', 'wants'),\n",
       " ('wants', 'the'),\n",
       " ('the', 'feder'),\n",
       " ('feder', '12'),\n",
       " ('12', 'This'),\n",
       " ('This', 'column'),\n",
       " ('column', 'is'),\n",
       " ('is', 'an'),\n",
       " ('an', 'opinion'),\n",
       " ('opinion', 'by'),\n",
       " ('by', 'Colleen'),\n",
       " ('Colleen', 'M'),\n",
       " ('M', 'Flood'),\n",
       " ('Flood', 'T'),\n",
       " ('T', '13'),\n",
       " ('13', 'Construction'),\n",
       " ('Construction', 'is'),\n",
       " ('is', 'on'),\n",
       " ('on', 'Ontarios'),\n",
       " ('Ontarios', 'list'),\n",
       " ('list', 'of'),\n",
       " ('of', 'essential'),\n",
       " ('essential', '14'),\n",
       " ('14', 'Albertas'),\n",
       " ('Albertas', 'TV'),\n",
       " ('TV', 'and'),\n",
       " ('and', 'movie'),\n",
       " ('movie', 'industry'),\n",
       " ('industry', 'is'),\n",
       " ('is', 'completely'),\n",
       " ('completely', 's'),\n",
       " ('s', '15'),\n",
       " ('15', 'The'),\n",
       " ('The', 'first'),\n",
       " ('first', 'wave'),\n",
       " ('wave', 'hit'),\n",
       " ('hit', 'last'),\n",
       " ('last', 'week'),\n",
       " ('week', 'The'),\n",
       " ('The', 'ER'),\n",
       " ('ER', 'at'),\n",
       " ('at', 'NYU'),\n",
       " ('NYU', 'Lan'),\n",
       " ('Lan', '16'),\n",
       " ('16', 'A'),\n",
       " ('A', 'Memorial'),\n",
       " ('Memorial', 'University'),\n",
       " ('University', 'professor'),\n",
       " ('professor', 'is'),\n",
       " ('is', 'hiring'),\n",
       " ('hiring', 'cash'),\n",
       " ('cash', '17'),\n",
       " ('17', 'Manitoba'),\n",
       " ('Manitoba', 'is'),\n",
       " ('is', 'under'),\n",
       " ('under', 'a'),\n",
       " ('a', 'state'),\n",
       " ('state', 'of'),\n",
       " ('of', 'emergency'),\n",
       " ('emergency', 'as'),\n",
       " ('as', 'the'),\n",
       " ('the', '18'),\n",
       " ('18', 'Medical'),\n",
       " ('Medical', 'experts'),\n",
       " ('experts', 'are'),\n",
       " ('are', 'warning'),\n",
       " ('warning', 'Canadians'),\n",
       " ('Canadians', 'not'),\n",
       " ('not', 'to'),\n",
       " ('to', 'b'),\n",
       " ('b', '19'),\n",
       " ('19', 'New'),\n",
       " ('New', 'Brunswick'),\n",
       " ('Brunswick', 'has'),\n",
       " ('has', 'lost'),\n",
       " ('lost', 'its'),\n",
       " ('its', 'chance'),\n",
       " ('chance', 'to'),\n",
       " ('to', 'use'),\n",
       " ('use', 'testi'),\n",
       " ('testi', '20'),\n",
       " ('20', 'Parliament'),\n",
       " ('Parliament', 'passes'),\n",
       " ('passes', '107'),\n",
       " ('107', 'billion'),\n",
       " ('billion', 'COVID19'),\n",
       " ('COVID19', 'aid'),\n",
       " ('aid', '21'),\n",
       " ('21', 'Prince'),\n",
       " ('Prince', 'Charles'),\n",
       " ('Charles', 'the'),\n",
       " ('the', 'heir'),\n",
       " ('heir', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'British'),\n",
       " ('British', 'throne'),\n",
       " ('throne', '22'),\n",
       " ('22', 'The'),\n",
       " ('The', 'recent'),\n",
       " ('recent', 'news'),\n",
       " ('news', 'may'),\n",
       " ('may', 'have'),\n",
       " ('have', 'you'),\n",
       " ('you', 'worried'),\n",
       " ('worried', 'about'),\n",
       " ('about', 'cat'),\n",
       " ('cat', '23'),\n",
       " ('23', 'Medical'),\n",
       " ('Medical', 'regulators'),\n",
       " ('regulators', 'in'),\n",
       " ('in', 'Canada'),\n",
       " ('Canada', 'suspect'),\n",
       " ('suspect', 'some'),\n",
       " ('some', 'doct'),\n",
       " ('doct', '24'),\n",
       " ('24', 'Life'),\n",
       " ('Life', 'has'),\n",
       " ('has', 'changed'),\n",
       " ('changed', 'on'),\n",
       " ('on', 'Selkirk'),\n",
       " ('Selkirk', 'Avenue'),\n",
       " ('Avenue', 'Social'),\n",
       " ('Social', 'assi'),\n",
       " ('assi', '25'),\n",
       " ('25', 'The'),\n",
       " ('The', 'black'),\n",
       " ('black', 'swan'),\n",
       " ('swan', 'has'),\n",
       " ('has', 'landed'),\n",
       " ('landed', 'The'),\n",
       " ('The', 'novel'),\n",
       " ('novel', 'coronavir'),\n",
       " ('coronavir', '26'),\n",
       " ('26', 'Jackson'),\n",
       " ('Jackson', 'Browne'),\n",
       " ('Browne', 'has'),\n",
       " ('has', 'tested'),\n",
       " ('tested', 'positive'),\n",
       " ('positive', 'for'),\n",
       " ('for', 'coronav'),\n",
       " ('coronav', '27'),\n",
       " ('27', 'From'),\n",
       " ('From', 'shuttered'),\n",
       " ('shuttered', 'businesses'),\n",
       " ('businesses', 'and'),\n",
       " ('and', 'empty'),\n",
       " ('empty', 'offices'),\n",
       " ('offices', 'to'),\n",
       " ('to', '28'),\n",
       " ('28', 'For'),\n",
       " ('For', 'the'),\n",
       " ('the', 'numerous'),\n",
       " ('numerous', 'expats'),\n",
       " ('expats', 'and'),\n",
       " ('and', 'foreign'),\n",
       " ('foreign', 'workers'),\n",
       " ('workers', 'th'),\n",
       " ('th', '29'),\n",
       " ('29', 'New'),\n",
       " ('New', 'York'),\n",
       " ('York', 'which'),\n",
       " ('which', 'is'),\n",
       " ('is', 'experiencing'),\n",
       " ('experiencing', 'more'),\n",
       " ('more', 'coronaviru'),\n",
       " ('coronaviru', '30'),\n",
       " ('30', 'When'),\n",
       " ('When', 'Sunwing'),\n",
       " ('Sunwing', 'pilot'),\n",
       " ('pilot', 'Derek'),\n",
       " ('Derek', 'Butcher'),\n",
       " ('Butcher', 'recovers'),\n",
       " ('recovers', 'from'),\n",
       " ('from', '31'),\n",
       " ('31', 'The'),\n",
       " ('The', 'federal'),\n",
       " ('federal', 'government'),\n",
       " ('government', 'is'),\n",
       " ('is', 'shutting'),\n",
       " ('shutting', 'down'),\n",
       " ('down', 'the'),\n",
       " ('the', 'ne'),\n",
       " ('ne', '32'),\n",
       " ('32', 'The'),\n",
       " ('The', 'plan'),\n",
       " ('plan', 'for'),\n",
       " ('for', 'an'),\n",
       " ('an', 'ambitious'),\n",
       " ('ambitious', 'reforestation'),\n",
       " ('reforestation', 'season'),\n",
       " ('season', '33'),\n",
       " ('33', 'Chinese'),\n",
       " ('Chinese', 'authorities'),\n",
       " ('authorities', 'said'),\n",
       " ('said', 'Tuesday'),\n",
       " ('Tuesday', 'they'),\n",
       " ('they', 'will'),\n",
       " ('will', 'end'),\n",
       " ('end', '34'),\n",
       " ('34', 'The'),\n",
       " ('The', 'latest'),\n",
       " ('latest', 'House'),\n",
       " ('House', 'of'),\n",
       " ('of', 'Commons'),\n",
       " ('Commons', 'suspends'),\n",
       " ('suspends', 'proceedi'),\n",
       " ('proceedi', '35'),\n",
       " ('35', 'One'),\n",
       " ('One', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'most'),\n",
       " ('most', 'persistent'),\n",
       " ('persistent', 'and'),\n",
       " ('and', 'widespread'),\n",
       " ('widespread', 'piec'),\n",
       " ('piec', '36'),\n",
       " ('36', 'Kirstin'),\n",
       " ('Kirstin', 'Knight'),\n",
       " ('Knight', 'is'),\n",
       " ('is', 'still'),\n",
       " ('still', 'apprehensive'),\n",
       " ('apprehensive', 'at'),\n",
       " ('at', 'the'),\n",
       " ('the', 'th'),\n",
       " ('th', '37'),\n",
       " ('37', 'The'),\n",
       " ('The', 'White'),\n",
       " ('White', 'House'),\n",
       " ('House', 'and'),\n",
       " ('and', 'Senate'),\n",
       " ('Senate', 'leaders'),\n",
       " ('leaders', 'of'),\n",
       " ('of', 'both'),\n",
       " ('both', 'par'),\n",
       " ('par', '38'),\n",
       " ('38', 'House'),\n",
       " ('House', 'of'),\n",
       " ('of', 'Commons'),\n",
       " ('Commons', 'suspended'),\n",
       " ('suspended', 'amid'),\n",
       " ('amid', 'COVID19'),\n",
       " ('COVID19', 'ai'),\n",
       " ('ai', '39'),\n",
       " ('39', 'Chef'),\n",
       " ('Chef', 'Floyd'),\n",
       " ('Floyd', 'Cardoz'),\n",
       " ('Cardoz', 'who'),\n",
       " ('who', 'competed'),\n",
       " ('competed', 'on'),\n",
       " ('on', 'Top'),\n",
       " ('Top', 'Chef'),\n",
       " ('Chef', 'won'),\n",
       " ('won', '40'),\n",
       " ('40', 'BCs'),\n",
       " ('BCs', 'Ministry'),\n",
       " ('Ministry', 'of'),\n",
       " ('of', 'Health'),\n",
       " ('Health', 'has'),\n",
       " ('has', 'released'),\n",
       " ('released', 'a'),\n",
       " ('a', 'new'),\n",
       " ('new', 'app'),\n",
       " ('app', '41'),\n",
       " ('41', 'A'),\n",
       " ('A', 'smallbatch'),\n",
       " ('smallbatch', 'distillery'),\n",
       " ('distillery', 'in'),\n",
       " ('in', 'Prince'),\n",
       " ('Prince', 'Edward'),\n",
       " ('Edward', 'Count'),\n",
       " ('Count', '42'),\n",
       " ('42', 'A'),\n",
       " ('A', 'statement'),\n",
       " ('statement', 'from'),\n",
       " ('from', 'G7'),\n",
       " ('G7', 'finance'),\n",
       " ('finance', 'ministers'),\n",
       " ('ministers', 'and'),\n",
       " ('and', 'cent'),\n",
       " ('cent', '43'),\n",
       " ('43', 'Harvey'),\n",
       " ('Harvey', 'Weinstein'),\n",
       " ('Weinstein', 'tested'),\n",
       " ('tested', 'positive'),\n",
       " ('positive', 'for'),\n",
       " ('for', 'the'),\n",
       " ('the', 'coron'),\n",
       " ('coron', '44'),\n",
       " ('44', 'Democrats'),\n",
       " ('Democrats', 'and'),\n",
       " ('and', 'Republicans'),\n",
       " ('Republicans', 'said'),\n",
       " ('said', 'Tuesday'),\n",
       " ('Tuesday', 'they'),\n",
       " ('they', 'we'),\n",
       " ('we', '45'),\n",
       " ('45', 'India'),\n",
       " ('India', 'will'),\n",
       " ('will', 'begin'),\n",
       " ('begin', 'the'),\n",
       " ('the', 'worlds'),\n",
       " ('worlds', 'largest'),\n",
       " ('largest', 'lockdown'),\n",
       " ('lockdown', 'o'),\n",
       " ('o', '46'),\n",
       " ('46', 'A'),\n",
       " ('A', 'Phoenixarea'),\n",
       " ('Phoenixarea', 'man'),\n",
       " ('man', 'has'),\n",
       " ('has', 'died'),\n",
       " ('died', 'and'),\n",
       " ('and', 'his'),\n",
       " ('his', 'wife'),\n",
       " ('wife', 'was'),\n",
       " ('was', 'in'),\n",
       " ('in', '47'),\n",
       " ('47', 'Main'),\n",
       " ('Main', 'Street'),\n",
       " ('Street', 'Project'),\n",
       " ('Project', 'is'),\n",
       " ('is', 'moving'),\n",
       " ('moving', 'fast'),\n",
       " ('fast', 'to'),\n",
       " ('to', 'create'),\n",
       " ('create', 's'),\n",
       " ('s', '48'),\n",
       " ('48', 'THE'),\n",
       " ('THE', 'LATEST'),\n",
       " ('LATEST', 'Go'),\n",
       " ('Go', 'home'),\n",
       " ('home', 'and'),\n",
       " ('and', 'stay'),\n",
       " ('stay', 'home'),\n",
       " ('home', 'Trudeau'),\n",
       " ('Trudeau', 'tell'),\n",
       " ('tell', '49'),\n",
       " ('49', 'From'),\n",
       " ('From', 'trumpetplaying'),\n",
       " ('trumpetplaying', 'for'),\n",
       " ('for', 'dad'),\n",
       " ('dad', 'to'),\n",
       " ('to', 'a'),\n",
       " ('a', 'community'),\n",
       " ('community', 'dan'),\n",
       " ('dan', '50'),\n",
       " ('50', 'Travellers'),\n",
       " ('Travellers', 'coming'),\n",
       " ('coming', 'through'),\n",
       " ('through', 'the'),\n",
       " ('the', 'Calgary'),\n",
       " ('Calgary', 'Internat'),\n",
       " ('Internat', '51'),\n",
       " ('51', 'Two'),\n",
       " ('Two', 'researchers'),\n",
       " ('researchers', 'from'),\n",
       " ('from', 'the'),\n",
       " ('the', 'University'),\n",
       " ('University', 'of'),\n",
       " ('of', 'British'),\n",
       " ('British', '52'),\n",
       " ('52', 'Spanish'),\n",
       " ('Spanish', 'army'),\n",
       " ('army', 'troops'),\n",
       " ('troops', 'disinfecting'),\n",
       " ('disinfecting', 'nursing'),\n",
       " ('nursing', 'homes'),\n",
       " ('homes', '53'),\n",
       " ('53', 'Top'),\n",
       " ('Top', 'congressional'),\n",
       " ('congressional', 'and'),\n",
       " ('and', 'White'),\n",
       " ('White', 'House'),\n",
       " ('House', 'officials'),\n",
       " ('officials', 'em'),\n",
       " ('em', '54'),\n",
       " ('54', 'Interior'),\n",
       " ('Interior', 'Health'),\n",
       " ('Health', 'officials'),\n",
       " ('officials', 'are'),\n",
       " ('are', 'asking'),\n",
       " ('asking', 'people'),\n",
       " ('people', 'wh'),\n",
       " ('wh', '55'),\n",
       " ('55', 'The'),\n",
       " ('The', 'latest'),\n",
       " ('latest', 'Yukon'),\n",
       " ('Yukon', 'reports'),\n",
       " ('reports', 'first'),\n",
       " ('first', '2'),\n",
       " ('2', 'confirmed'),\n",
       " ('confirmed', 'ca'),\n",
       " ('ca', '56'),\n",
       " ('56', 'Stock'),\n",
       " ('Stock', 'markets'),\n",
       " ('markets', 'in'),\n",
       " ('in', 'New'),\n",
       " ('New', 'York'),\n",
       " ('York', 'and'),\n",
       " ('and', 'Toronto'),\n",
       " ('Toronto', 'jumped'),\n",
       " ('jumped', 's'),\n",
       " ('s', '57'),\n",
       " ('57', 'Fiat'),\n",
       " ('Fiat', 'Chrysler'),\n",
       " ('Chrysler', 'Automobiles'),\n",
       " ('Automobiles', 'FCA'),\n",
       " ('FCA', 'announced'),\n",
       " ('announced', 'on'),\n",
       " ('on', 'Mon'),\n",
       " ('Mon', '58'),\n",
       " ('58', 'A'),\n",
       " ('A', 'strong'),\n",
       " ('strong', 'earthquake'),\n",
       " ('earthquake', 'in'),\n",
       " ('in', 'Croatia'),\n",
       " ('Croatia', 'on'),\n",
       " ('on', 'Sunday'),\n",
       " ('Sunday', 'cause'),\n",
       " ('cause', '59'),\n",
       " ('59', 'The'),\n",
       " ('The', 'City'),\n",
       " ('City', 'of'),\n",
       " ('of', 'Edmonton'),\n",
       " ('Edmonton', 'announced'),\n",
       " ('announced', 'it'),\n",
       " ('it', 'will'),\n",
       " ('will', 'close'),\n",
       " ('close', 'o'),\n",
       " ('o', '60'),\n",
       " ('60', 'Michigan'),\n",
       " ('Michigan', 'Gov'),\n",
       " ('Gov', 'Gretchen'),\n",
       " ('Gretchen', 'Whitmer'),\n",
       " ('Whitmer', 'has'),\n",
       " ('has', 'issued'),\n",
       " ('issued', 'a'),\n",
       " ('a', 'sta'),\n",
       " ('sta', '61'),\n",
       " ('61', 'Edoardo'),\n",
       " ('Edoardo', 'Spinosa'),\n",
       " ('Spinosa', 'has'),\n",
       " ('has', 'been'),\n",
       " ('been', 'sent'),\n",
       " ('sent', 'home'),\n",
       " ('home', 'to'),\n",
       " ('to', 'Milan'),\n",
       " ('Milan', 'It'),\n",
       " ('It', '62'),\n",
       " ('62', 'The'),\n",
       " ('The', 'provincial'),\n",
       " ('provincial', 'government'),\n",
       " ('government', 'announced'),\n",
       " ('announced', '15'),\n",
       " ('15', 'new'),\n",
       " ('new', 'pre'),\n",
       " ('pre', '63'),\n",
       " ('63', 'Ask'),\n",
       " ('Ask', 'Syrian'),\n",
       " ('Syrian', 'aid'),\n",
       " ('aid', 'worker'),\n",
       " ('worker', 'Osama'),\n",
       " ('Osama', 'alHussein'),\n",
       " ('alHussein', 'how'),\n",
       " ('how', 'hes'),\n",
       " ('hes', '64'),\n",
       " ('64', 'The'),\n",
       " ('The', 'possibility'),\n",
       " ('possibility', 'of'),\n",
       " ('of', 'having'),\n",
       " ('having', 'COVID19'),\n",
       " ('COVID19', 'started'),\n",
       " ('started', 'to'),\n",
       " ('to', 'b'),\n",
       " ('b', '65'),\n",
       " ('65', 'The'),\n",
       " ('The', 'coronavirus'),\n",
       " ('coronavirus', 'pandemic'),\n",
       " ('pandemic', 'will'),\n",
       " ('will', 'cause'),\n",
       " ('cause', 'a'),\n",
       " ('a', 'global'),\n",
       " ('global', 'r'),\n",
       " ('r', '66'),\n",
       " ('66', 'British'),\n",
       " ('British', 'Prime'),\n",
       " ('Prime', 'Minister'),\n",
       " ('Minister', 'Boris'),\n",
       " ('Boris', 'Johnson'),\n",
       " ('Johnson', 'on'),\n",
       " ('on', 'Monday'),\n",
       " ('Monday', '67'),\n",
       " ('67', 'As'),\n",
       " ('As', 'the'),\n",
       " ('the', 'doors'),\n",
       " ('doors', 'of'),\n",
       " ('of', 'planes'),\n",
       " ('planes', 'landing'),\n",
       " ('landing', 'at'),\n",
       " ('at', 'Beijings'),\n",
       " ('Beijings', 'Cap'),\n",
       " ('Cap', '68'),\n",
       " ('68', 'The'),\n",
       " ('The', 'greatness'),\n",
       " ('greatness', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'American'),\n",
       " ('American', 'character'),\n",
       " ('character', 'is'),\n",
       " ('is', 'shi'),\n",
       " ('shi', '69'),\n",
       " ('69', 'With'),\n",
       " ('With', 'live'),\n",
       " ('live', 'events'),\n",
       " ('events', 'being'),\n",
       " ('being', 'cancelled'),\n",
       " ('cancelled', 'due'),\n",
       " ('due', 'to'),\n",
       " ('to', 'concer'),\n",
       " ('concer', '70'),\n",
       " ('70', 'The'),\n",
       " ('The', 'WindsorEssex'),\n",
       " ('WindsorEssex', 'County'),\n",
       " ('County', 'Health'),\n",
       " ('Health', 'Unit'),\n",
       " ('Unit', 'confirmed'),\n",
       " ('confirmed', '71'),\n",
       " ('71', 'London'),\n",
       " ('London', 'area'),\n",
       " ('area', 'health'),\n",
       " ('health', 'professionals'),\n",
       " ('professionals', 'are'),\n",
       " ('are', 'the'),\n",
       " ('the', 'first'),\n",
       " ('first', '72'),\n",
       " ('72', 'In'),\n",
       " ('In', 'these'),\n",
       " ('these', 'days'),\n",
       " ('days', 'of'),\n",
       " ('of', 'physical'),\n",
       " ('physical', 'distancing'),\n",
       " ('distancing', 'grocery'),\n",
       " ('grocery', 's'),\n",
       " ('s', '73'),\n",
       " ('73', 'As'),\n",
       " ('As', 'the'),\n",
       " ('the', 'coronavirus'),\n",
       " ('coronavirus', 'infects'),\n",
       " ('infects', 'more'),\n",
       " ('more', 'people'),\n",
       " ('people', 'around'),\n",
       " ('around', '74'),\n",
       " ('74', 'Nine'),\n",
       " ('Nine', 'workers'),\n",
       " ('workers', 'will'),\n",
       " ('will', 'stay'),\n",
       " ('stay', 'indefinitely'),\n",
       " ('indefinitely', 'at'),\n",
       " ('at', 'the'),\n",
       " ('the', 'Cit'),\n",
       " ('Cit', '75'),\n",
       " ('75', 'A'),\n",
       " ('A', 'group'),\n",
       " ('group', 'of'),\n",
       " ('of', 'eastern'),\n",
       " ('eastern', 'Ontario'),\n",
       " ('Ontario', 'municipal'),\n",
       " ('municipal', 'leaders'),\n",
       " ('leaders', 'i'),\n",
       " ('i', '76'),\n",
       " ('76', 'An'),\n",
       " ('An', 'expanded'),\n",
       " ('expanded', 'call'),\n",
       " ('call', 'centre'),\n",
       " ('centre', 'at'),\n",
       " ('at', 'Global'),\n",
       " ('Global', 'Affairs'),\n",
       " ('Affairs', 'Cana'),\n",
       " ('Cana', '77'),\n",
       " ('77', 'Slaight'),\n",
       " ('Slaight', 'Music'),\n",
       " ('Music', 'is'),\n",
       " ('is', 'doubling'),\n",
       " ('doubling', 'a'),\n",
       " ('a', 'performing'),\n",
       " ('performing', 'arts'),\n",
       " ('arts', 'fu'),\n",
       " ('fu', '78'),\n",
       " ('78', 'Laurie'),\n",
       " ('Laurie', 'Pushor'),\n",
       " ('Pushor', 'Saskatchewans'),\n",
       " ('Saskatchewans', 'deputy'),\n",
       " ('deputy', 'minister'),\n",
       " ('minister', 'of'),\n",
       " ('of', '79'),\n",
       " ('79', 'BC'),\n",
       " ('BC', 'is'),\n",
       " ('is', 'ordering'),\n",
       " ('ordering', 'all'),\n",
       " ('all', 'restaurants'),\n",
       " ('restaurants', 'to'),\n",
       " ('to', 'stop'),\n",
       " ('stop', 'providi'),\n",
       " ('providi', '80'),\n",
       " ('80', 'Whats'),\n",
       " ('Whats', 'COVID19'),\n",
       " ('COVID19', 'Whats'),\n",
       " ('Whats', 'isolation'),\n",
       " ('isolation', 'Is'),\n",
       " ('Is', 'there'),\n",
       " ('there', 'a'),\n",
       " ('a', 'cure'),\n",
       " ('cure', '81'),\n",
       " ('81', 'A'),\n",
       " ('A', 'tentative'),\n",
       " ('tentative', 'agreement'),\n",
       " ('agreement', 'has'),\n",
       " ('has', 'been'),\n",
       " ('been', 'reached'),\n",
       " ('reached', 'with'),\n",
       " ('with', 'Br'),\n",
       " ('Br', '82'),\n",
       " ('82', 'A'),\n",
       " ('A', 'survey'),\n",
       " ('survey', 'conducted'),\n",
       " ('conducted', 'by'),\n",
       " ('by', 'Dene'),\n",
       " ('Dene', 'Nation'),\n",
       " ('Nation', 'suggests'),\n",
       " ('suggests', 'tha'),\n",
       " ('tha', '83'),\n",
       " ('83', 'Alberta'),\n",
       " ('Alberta', 'talk'),\n",
       " ('talk', 'radio'),\n",
       " ('radio', 'host'),\n",
       " ('host', 'and'),\n",
       " ('and', 'former'),\n",
       " ('former', 'Wildrose'),\n",
       " ('Wildrose', 'Pa'),\n",
       " ('Pa', '84'),\n",
       " ('84', 'The'),\n",
       " ('The', 'Cannes'),\n",
       " ('Cannes', 'Film'),\n",
       " ('Film', 'Festival'),\n",
       " ('Festival', 'has'),\n",
       " ('has', 'been'),\n",
       " ('been', 'postponed'),\n",
       " ('postponed', 'du'),\n",
       " ('du', '85'),\n",
       " ('85', 'Like'),\n",
       " ('Like', 'airports'),\n",
       " ('airports', 'around'),\n",
       " ('around', 'the'),\n",
       " ('the', 'world'),\n",
       " ('world', 'the'),\n",
       " ('the', 'global'),\n",
       " ('global', 'pand'),\n",
       " ('pand', '86'),\n",
       " ('86', 'The'),\n",
       " ('The', 'latest'),\n",
       " ('latest', 'NWT'),\n",
       " ('NWT', 'confirms'),\n",
       " ('confirms', '1st'),\n",
       " ('1st', 'case'),\n",
       " ('case', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'terri'),\n",
       " ('terri', '87'),\n",
       " ('87', 'Leaders'),\n",
       " ('Leaders', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'worlds'),\n",
       " ('worlds', '20'),\n",
       " ('20', 'biggest'),\n",
       " ('biggest', 'economies'),\n",
       " ('economies', 'met'),\n",
       " ('met', '88'),\n",
       " ('88', 'A'),\n",
       " ('A', 'man'),\n",
       " ('man', 'in'),\n",
       " ('in', 'his'),\n",
       " ('his', '50s'),\n",
       " ('50s', 'who'),\n",
       " ('who', 'tested'),\n",
       " ('tested', 'positive'),\n",
       " ('positive', 'for'),\n",
       " ('for', 'COVID'),\n",
       " ('COVID', '89'),\n",
       " ('89', 'Confused'),\n",
       " ('Confused', 'about'),\n",
       " ('about', 'the'),\n",
       " ('the', 'language'),\n",
       " ('language', 'that'),\n",
       " ('that', 'health'),\n",
       " ('health', 'and'),\n",
       " ('and', 'go'),\n",
       " ('go', '90'),\n",
       " ('90', 'Italys'),\n",
       " ('Italys', 'death'),\n",
       " ('death', 'toll'),\n",
       " ('toll', 'from'),\n",
       " ('from', 'coronavirus'),\n",
       " ('coronavirus', 'on'),\n",
       " ('on', 'Thursday'),\n",
       " ('Thursday', '91'),\n",
       " ('91', 'The'),\n",
       " ('The', 'coronavirus'),\n",
       " ('coronavirus', 'outbreak'),\n",
       " ('outbreak', 'has'),\n",
       " ('has', 'resulted'),\n",
       " ('resulted', 'in'),\n",
       " ('in', 'a'),\n",
       " ('a', 'del'),\n",
       " ('del', '92'),\n",
       " ('92', 'BC'),\n",
       " ('BC', 'is'),\n",
       " ('is', 'ordering'),\n",
       " ('ordering', 'all'),\n",
       " ('all', 'restaurants'),\n",
       " ('restaurants', 'to'),\n",
       " ('to', 'stop'),\n",
       " ('stop', 'providi'),\n",
       " ('providi', '93'),\n",
       " ('93', 'Southwest'),\n",
       " ('Southwest', 'Sounds'),\n",
       " ('Sounds', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'weekly'),\n",
       " ('weekly', 'feature'),\n",
       " ('feature', 'that'),\n",
       " ('that', 'prof'),\n",
       " ('prof', '94'),\n",
       " ('94', 'Twothirds'),\n",
       " ('Twothirds', 'of'),\n",
       " ('of', 'Canadians'),\n",
       " ('Canadians', 'think'),\n",
       " ('think', 'Prime'),\n",
       " ('Prime', 'Minister'),\n",
       " ('Minister', 'Ju'),\n",
       " ('Ju', '95'),\n",
       " ('95', 'The'),\n",
       " ('The', 'Alberta'),\n",
       " ('Alberta', 'government'),\n",
       " ('government', 'has'),\n",
       " ('has', 'fished'),\n",
       " ('fished', '153'),\n",
       " ('153', 'million'),\n",
       " ('million', '96'),\n",
       " ('96', 'BC'),\n",
       " ('BC', 'is'),\n",
       " ('is', 'ordering'),\n",
       " ('ordering', 'all'),\n",
       " ('all', 'restaurants'),\n",
       " ('restaurants', 'to'),\n",
       " ('to', 'stop'),\n",
       " ('stop', 'providi'),\n",
       " ('providi', '97'),\n",
       " ('97', 'As'),\n",
       " ('As', 'if'),\n",
       " ('if', 'there'),\n",
       " ('there', 'wasnt'),\n",
       " ('wasnt', 'enough'),\n",
       " ('enough', 'COVID19'),\n",
       " ('COVID19', 'chaos'),\n",
       " ('chaos', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', '98'),\n",
       " ('98', 'While'),\n",
       " ('While', 'many'),\n",
       " ('many', 'people'),\n",
       " ('people', 'are'),\n",
       " ('are', 'staying'),\n",
       " ('staying', 'home'),\n",
       " ('home', 'amid'),\n",
       " ('amid', 'COVID1'),\n",
       " ('COVID1', '99'),\n",
       " ('99', 'The'),\n",
       " ('The', 'latest'),\n",
       " ('latest', 'Ottawa'),\n",
       " ('Ottawa', 'finalizing'),\n",
       " ('finalizing', 'plan'),\n",
       " ('plan', 'to'),\n",
       " ('to', 'boost'),\n",
       " ('boost', 'pr'),\n",
       " ('pr', '100'),\n",
       " ('100', 'Ford'),\n",
       " ('Ford', 'General'),\n",
       " ('General', 'Motors'),\n",
       " ('Motors', 'Fiat'),\n",
       " ('Fiat', 'Chrysler'),\n",
       " ('Chrysler', 'Honda'),\n",
       " ('Honda', 'and'),\n",
       " ('and', 'To'),\n",
       " ('To', '101'),\n",
       " ('101', 'The'),\n",
       " ('The', 'provincial'),\n",
       " ('provincial', 'government'),\n",
       " ('government', 'says'),\n",
       " ('says', 'safe'),\n",
       " ('safe', 'prescripti'),\n",
       " ('prescripti', '102'),\n",
       " ('102', 'Starbucks'),\n",
       " ('Starbucks', 'is'),\n",
       " ('is', 'joining'),\n",
       " ('joining', 'the'),\n",
       " ('the', 'growing'),\n",
       " ('growing', 'list'),\n",
       " ('list', 'of'),\n",
       " ('of', 'compa'),\n",
       " ('compa', '103'),\n",
       " ('103', 'COVID19'),\n",
       " ('COVID19', 'anxiety'),\n",
       " ('anxiety', 'is'),\n",
       " ('is', 'real'),\n",
       " ('real', 'for'),\n",
       " ('for', 'many'),\n",
       " ('many', 'people'),\n",
       " ('people', 'but'),\n",
       " ('but', 'it'),\n",
       " ('it', '104'),\n",
       " ('104', 'Netflix'),\n",
       " ('Netflix', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'it'),\n",
       " ('it', 'is'),\n",
       " ('is', 'establishing'),\n",
       " ('establishing', 'a'),\n",
       " ('a', '100'),\n",
       " ('100', 'm'),\n",
       " ('m', '105'),\n",
       " ('105', 'The'),\n",
       " ('The', 'Ministry'),\n",
       " ('Ministry', 'of'),\n",
       " ('of', 'Health'),\n",
       " ('Health', 'has'),\n",
       " ('has', 'quietly'),\n",
       " ('quietly', 'launched'),\n",
       " ('launched', 'a'),\n",
       " ('a', '106'),\n",
       " ('106', 'UPDATE'),\n",
       " ('UPDATE', 'On'),\n",
       " ('On', 'March'),\n",
       " ('March', '12'),\n",
       " ('12', 'Hong'),\n",
       " ('Hong', 'Kongs'),\n",
       " ('Kongs', 'Agriculture'),\n",
       " ('Agriculture', 'Fish'),\n",
       " ('Fish', '107'),\n",
       " ('107', 'In'),\n",
       " ('In', 'the'),\n",
       " ('the', '25'),\n",
       " ('25', 'years'),\n",
       " ('years', 'hes'),\n",
       " ('hes', 'owned'),\n",
       " ('owned', 'his'),\n",
       " ('his', 'Ontario'),\n",
       " ('Ontario', 'gun'),\n",
       " ('gun', 'shop'),\n",
       " ('shop', '108'),\n",
       " ('108', 'Employees'),\n",
       " ('Employees', 'at'),\n",
       " ('at', 'TD'),\n",
       " ('TD', 'Bank'),\n",
       " ('Bank', 'say'),\n",
       " ('say', 'hundreds'),\n",
       " ('hundreds', 'of'),\n",
       " ('of', 'people'),\n",
       " ('people', 'ar'),\n",
       " ('ar', '109'),\n",
       " ('109', 'Sarah'),\n",
       " ('Sarah', 'Swarks'),\n",
       " ('Swarks', 'wedding'),\n",
       " ('wedding', 'is'),\n",
       " ('is', 'not'),\n",
       " ('not', 'going'),\n",
       " ('going', 'ahead'),\n",
       " ('ahead', 'as'),\n",
       " ('as', 'pla'),\n",
       " ('pla', '110'),\n",
       " ('110', 'Canadas'),\n",
       " ('Canadas', 'hospitals'),\n",
       " ('hospitals', 'and'),\n",
       " ('and', 'health'),\n",
       " ('health', 'officials'),\n",
       " ('officials', 'are'),\n",
       " ('are', 'loo'),\n",
       " ('loo', '111'),\n",
       " ('111', 'Extra'),\n",
       " ('Extra', 'resources'),\n",
       " ('resources', 'are'),\n",
       " ('are', 'being'),\n",
       " ('being', 'added'),\n",
       " ('added', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'Tele–Ca'),\n",
       " ('Tele–Ca', '112'),\n",
       " ('112', 'The'),\n",
       " ('The', 'Eurovision'),\n",
       " ('Eurovision', 'song'),\n",
       " ('song', 'contest'),\n",
       " ('contest', 'one'),\n",
       " ('one', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'worlds'),\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=bigrams(tokens)\n",
    "[x for x in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Canadian', 'pharmacies'),\n",
       " ('Canadian', 'pharmacies', 'are'),\n",
       " ('pharmacies', 'are', 'limiting'),\n",
       " ('are', 'limiting', 'how'),\n",
       " ('limiting', 'how', 'much'),\n",
       " ('how', 'much', 'medi'),\n",
       " ('much', 'medi', '1'),\n",
       " ('medi', '1', 'The'),\n",
       " ('1', 'The', 'Yukon'),\n",
       " ('The', 'Yukon', 'government'),\n",
       " ('Yukon', 'government', 'has'),\n",
       " ('government', 'has', 'identified'),\n",
       " ('has', 'identified', 'two'),\n",
       " ('identified', 'two', 'places'),\n",
       " ('two', 'places', '2'),\n",
       " ('places', '2', 'The'),\n",
       " ('2', 'The', 'Senate'),\n",
       " ('The', 'Senate', 'late'),\n",
       " ('Senate', 'late', 'Wednesday'),\n",
       " ('late', 'Wednesday', 'passed'),\n",
       " ('Wednesday', 'passed', 'an'),\n",
       " ('passed', 'an', 'unparallel'),\n",
       " ('an', 'unparallel', '3'),\n",
       " ('unparallel', '3', 'Scientists'),\n",
       " ('3', 'Scientists', 'around'),\n",
       " ('Scientists', 'around', 'the'),\n",
       " ('around', 'the', 'world'),\n",
       " ('the', 'world', 'are'),\n",
       " ('world', 'are', 'racing'),\n",
       " ('are', 'racing', 'to'),\n",
       " ('racing', 'to', 'find'),\n",
       " ('to', 'find', '4'),\n",
       " ('find', '4', 'Trudeau'),\n",
       " ('4', 'Trudeau', 'says'),\n",
       " ('Trudeau', 'says', 'rules'),\n",
       " ('says', 'rules', 'of'),\n",
       " ('rules', 'of', 'Quarantine'),\n",
       " ('of', 'Quarantine', 'Act'),\n",
       " ('Quarantine', 'Act', 'will'),\n",
       " ('Act', 'will', '5'),\n",
       " ('will', '5', 'The'),\n",
       " ('5', 'The', 'continued'),\n",
       " ('The', 'continued', 'existence'),\n",
       " ('continued', 'existence', 'of'),\n",
       " ('existence', 'of', 'wildlife'),\n",
       " ('of', 'wildlife', 'markets'),\n",
       " ('wildlife', 'markets', 'wh'),\n",
       " ('markets', 'wh', '6'),\n",
       " ('wh', '6', 'Recent'),\n",
       " ('6', 'Recent', 'developments'),\n",
       " ('Recent', 'developments', 'Two'),\n",
       " ('developments', 'Two', 'new'),\n",
       " ('Two', 'new', 'cases'),\n",
       " ('new', 'cases', 'in'),\n",
       " ('cases', 'in', 'western'),\n",
       " ('in', 'western', '7'),\n",
       " ('western', '7', 'Michigan'),\n",
       " ('7', 'Michigan', 'hospitals'),\n",
       " ('Michigan', 'hospitals', 'are'),\n",
       " ('hospitals', 'are', 'bracing'),\n",
       " ('are', 'bracing', 'for'),\n",
       " ('bracing', 'for', 'a'),\n",
       " ('for', 'a', 'surge'),\n",
       " ('a', 'surge', 'of'),\n",
       " ('surge', 'of', '8'),\n",
       " ('of', '8', 'The'),\n",
       " ('8', 'The', 'number'),\n",
       " ('The', 'number', 'of'),\n",
       " ('number', 'of', 'confirmed'),\n",
       " ('of', 'confirmed', 'COVID19'),\n",
       " ('confirmed', 'COVID19', 'cases'),\n",
       " ('COVID19', 'cases', 'in'),\n",
       " ('cases', 'in', 'the'),\n",
       " ('in', 'the', 'U'),\n",
       " ('the', 'U', '9'),\n",
       " ('U', '9', 'The'),\n",
       " ('9', 'The', 'Jewish'),\n",
       " ('The', 'Jewish', 'General'),\n",
       " ('Jewish', 'General', 'Hospital'),\n",
       " ('General', 'Hospital', 'plans'),\n",
       " ('Hospital', 'plans', 'to'),\n",
       " ('plans', 'to', 'set'),\n",
       " ('to', 'set', 'up'),\n",
       " ('set', 'up', 'tr'),\n",
       " ('up', 'tr', '10'),\n",
       " ('tr', '10', 'Three'),\n",
       " ('10', 'Three', 'Saskatchewan'),\n",
       " ('Three', 'Saskatchewan', 'residents'),\n",
       " ('Saskatchewan', 'residents', 'have'),\n",
       " ('residents', 'have', 'recovered'),\n",
       " ('have', 'recovered', 'f'),\n",
       " ('recovered', 'f', '11'),\n",
       " ('f', '11', 'A'),\n",
       " ('11', 'A', 'Manitoba'),\n",
       " ('A', 'Manitoba', 'chiefs'),\n",
       " ('Manitoba', 'chiefs', 'organization'),\n",
       " ('chiefs', 'organization', 'wants'),\n",
       " ('organization', 'wants', 'the'),\n",
       " ('wants', 'the', 'feder'),\n",
       " ('the', 'feder', '12'),\n",
       " ('feder', '12', 'This'),\n",
       " ('12', 'This', 'column'),\n",
       " ('This', 'column', 'is'),\n",
       " ('column', 'is', 'an'),\n",
       " ('is', 'an', 'opinion'),\n",
       " ('an', 'opinion', 'by'),\n",
       " ('opinion', 'by', 'Colleen'),\n",
       " ('by', 'Colleen', 'M'),\n",
       " ('Colleen', 'M', 'Flood'),\n",
       " ('M', 'Flood', 'T'),\n",
       " ('Flood', 'T', '13'),\n",
       " ('T', '13', 'Construction'),\n",
       " ('13', 'Construction', 'is'),\n",
       " ('Construction', 'is', 'on'),\n",
       " ('is', 'on', 'Ontarios'),\n",
       " ('on', 'Ontarios', 'list'),\n",
       " ('Ontarios', 'list', 'of'),\n",
       " ('list', 'of', 'essential'),\n",
       " ('of', 'essential', '14'),\n",
       " ('essential', '14', 'Albertas'),\n",
       " ('14', 'Albertas', 'TV'),\n",
       " ('Albertas', 'TV', 'and'),\n",
       " ('TV', 'and', 'movie'),\n",
       " ('and', 'movie', 'industry'),\n",
       " ('movie', 'industry', 'is'),\n",
       " ('industry', 'is', 'completely'),\n",
       " ('is', 'completely', 's'),\n",
       " ('completely', 's', '15'),\n",
       " ('s', '15', 'The'),\n",
       " ('15', 'The', 'first'),\n",
       " ('The', 'first', 'wave'),\n",
       " ('first', 'wave', 'hit'),\n",
       " ('wave', 'hit', 'last'),\n",
       " ('hit', 'last', 'week'),\n",
       " ('last', 'week', 'The'),\n",
       " ('week', 'The', 'ER'),\n",
       " ('The', 'ER', 'at'),\n",
       " ('ER', 'at', 'NYU'),\n",
       " ('at', 'NYU', 'Lan'),\n",
       " ('NYU', 'Lan', '16'),\n",
       " ('Lan', '16', 'A'),\n",
       " ('16', 'A', 'Memorial'),\n",
       " ('A', 'Memorial', 'University'),\n",
       " ('Memorial', 'University', 'professor'),\n",
       " ('University', 'professor', 'is'),\n",
       " ('professor', 'is', 'hiring'),\n",
       " ('is', 'hiring', 'cash'),\n",
       " ('hiring', 'cash', '17'),\n",
       " ('cash', '17', 'Manitoba'),\n",
       " ('17', 'Manitoba', 'is'),\n",
       " ('Manitoba', 'is', 'under'),\n",
       " ('is', 'under', 'a'),\n",
       " ('under', 'a', 'state'),\n",
       " ('a', 'state', 'of'),\n",
       " ('state', 'of', 'emergency'),\n",
       " ('of', 'emergency', 'as'),\n",
       " ('emergency', 'as', 'the'),\n",
       " ('as', 'the', '18'),\n",
       " ('the', '18', 'Medical'),\n",
       " ('18', 'Medical', 'experts'),\n",
       " ('Medical', 'experts', 'are'),\n",
       " ('experts', 'are', 'warning'),\n",
       " ('are', 'warning', 'Canadians'),\n",
       " ('warning', 'Canadians', 'not'),\n",
       " ('Canadians', 'not', 'to'),\n",
       " ('not', 'to', 'b'),\n",
       " ('to', 'b', '19'),\n",
       " ('b', '19', 'New'),\n",
       " ('19', 'New', 'Brunswick'),\n",
       " ('New', 'Brunswick', 'has'),\n",
       " ('Brunswick', 'has', 'lost'),\n",
       " ('has', 'lost', 'its'),\n",
       " ('lost', 'its', 'chance'),\n",
       " ('its', 'chance', 'to'),\n",
       " ('chance', 'to', 'use'),\n",
       " ('to', 'use', 'testi'),\n",
       " ('use', 'testi', '20'),\n",
       " ('testi', '20', 'Parliament'),\n",
       " ('20', 'Parliament', 'passes'),\n",
       " ('Parliament', 'passes', '107'),\n",
       " ('passes', '107', 'billion'),\n",
       " ('107', 'billion', 'COVID19'),\n",
       " ('billion', 'COVID19', 'aid'),\n",
       " ('COVID19', 'aid', '21'),\n",
       " ('aid', '21', 'Prince'),\n",
       " ('21', 'Prince', 'Charles'),\n",
       " ('Prince', 'Charles', 'the'),\n",
       " ('Charles', 'the', 'heir'),\n",
       " ('the', 'heir', 'to'),\n",
       " ('heir', 'to', 'the'),\n",
       " ('to', 'the', 'British'),\n",
       " ('the', 'British', 'throne'),\n",
       " ('British', 'throne', '22'),\n",
       " ('throne', '22', 'The'),\n",
       " ('22', 'The', 'recent'),\n",
       " ('The', 'recent', 'news'),\n",
       " ('recent', 'news', 'may'),\n",
       " ('news', 'may', 'have'),\n",
       " ('may', 'have', 'you'),\n",
       " ('have', 'you', 'worried'),\n",
       " ('you', 'worried', 'about'),\n",
       " ('worried', 'about', 'cat'),\n",
       " ('about', 'cat', '23'),\n",
       " ('cat', '23', 'Medical'),\n",
       " ('23', 'Medical', 'regulators'),\n",
       " ('Medical', 'regulators', 'in'),\n",
       " ('regulators', 'in', 'Canada'),\n",
       " ('in', 'Canada', 'suspect'),\n",
       " ('Canada', 'suspect', 'some'),\n",
       " ('suspect', 'some', 'doct'),\n",
       " ('some', 'doct', '24'),\n",
       " ('doct', '24', 'Life'),\n",
       " ('24', 'Life', 'has'),\n",
       " ('Life', 'has', 'changed'),\n",
       " ('has', 'changed', 'on'),\n",
       " ('changed', 'on', 'Selkirk'),\n",
       " ('on', 'Selkirk', 'Avenue'),\n",
       " ('Selkirk', 'Avenue', 'Social'),\n",
       " ('Avenue', 'Social', 'assi'),\n",
       " ('Social', 'assi', '25'),\n",
       " ('assi', '25', 'The'),\n",
       " ('25', 'The', 'black'),\n",
       " ('The', 'black', 'swan'),\n",
       " ('black', 'swan', 'has'),\n",
       " ('swan', 'has', 'landed'),\n",
       " ('has', 'landed', 'The'),\n",
       " ('landed', 'The', 'novel'),\n",
       " ('The', 'novel', 'coronavir'),\n",
       " ('novel', 'coronavir', '26'),\n",
       " ('coronavir', '26', 'Jackson'),\n",
       " ('26', 'Jackson', 'Browne'),\n",
       " ('Jackson', 'Browne', 'has'),\n",
       " ('Browne', 'has', 'tested'),\n",
       " ('has', 'tested', 'positive'),\n",
       " ('tested', 'positive', 'for'),\n",
       " ('positive', 'for', 'coronav'),\n",
       " ('for', 'coronav', '27'),\n",
       " ('coronav', '27', 'From'),\n",
       " ('27', 'From', 'shuttered'),\n",
       " ('From', 'shuttered', 'businesses'),\n",
       " ('shuttered', 'businesses', 'and'),\n",
       " ('businesses', 'and', 'empty'),\n",
       " ('and', 'empty', 'offices'),\n",
       " ('empty', 'offices', 'to'),\n",
       " ('offices', 'to', '28'),\n",
       " ('to', '28', 'For'),\n",
       " ('28', 'For', 'the'),\n",
       " ('For', 'the', 'numerous'),\n",
       " ('the', 'numerous', 'expats'),\n",
       " ('numerous', 'expats', 'and'),\n",
       " ('expats', 'and', 'foreign'),\n",
       " ('and', 'foreign', 'workers'),\n",
       " ('foreign', 'workers', 'th'),\n",
       " ('workers', 'th', '29'),\n",
       " ('th', '29', 'New'),\n",
       " ('29', 'New', 'York'),\n",
       " ('New', 'York', 'which'),\n",
       " ('York', 'which', 'is'),\n",
       " ('which', 'is', 'experiencing'),\n",
       " ('is', 'experiencing', 'more'),\n",
       " ('experiencing', 'more', 'coronaviru'),\n",
       " ('more', 'coronaviru', '30'),\n",
       " ('coronaviru', '30', 'When'),\n",
       " ('30', 'When', 'Sunwing'),\n",
       " ('When', 'Sunwing', 'pilot'),\n",
       " ('Sunwing', 'pilot', 'Derek'),\n",
       " ('pilot', 'Derek', 'Butcher'),\n",
       " ('Derek', 'Butcher', 'recovers'),\n",
       " ('Butcher', 'recovers', 'from'),\n",
       " ('recovers', 'from', '31'),\n",
       " ('from', '31', 'The'),\n",
       " ('31', 'The', 'federal'),\n",
       " ('The', 'federal', 'government'),\n",
       " ('federal', 'government', 'is'),\n",
       " ('government', 'is', 'shutting'),\n",
       " ('is', 'shutting', 'down'),\n",
       " ('shutting', 'down', 'the'),\n",
       " ('down', 'the', 'ne'),\n",
       " ('the', 'ne', '32'),\n",
       " ('ne', '32', 'The'),\n",
       " ('32', 'The', 'plan'),\n",
       " ('The', 'plan', 'for'),\n",
       " ('plan', 'for', 'an'),\n",
       " ('for', 'an', 'ambitious'),\n",
       " ('an', 'ambitious', 'reforestation'),\n",
       " ('ambitious', 'reforestation', 'season'),\n",
       " ('reforestation', 'season', '33'),\n",
       " ('season', '33', 'Chinese'),\n",
       " ('33', 'Chinese', 'authorities'),\n",
       " ('Chinese', 'authorities', 'said'),\n",
       " ('authorities', 'said', 'Tuesday'),\n",
       " ('said', 'Tuesday', 'they'),\n",
       " ('Tuesday', 'they', 'will'),\n",
       " ('they', 'will', 'end'),\n",
       " ('will', 'end', '34'),\n",
       " ('end', '34', 'The'),\n",
       " ('34', 'The', 'latest'),\n",
       " ('The', 'latest', 'House'),\n",
       " ('latest', 'House', 'of'),\n",
       " ('House', 'of', 'Commons'),\n",
       " ('of', 'Commons', 'suspends'),\n",
       " ('Commons', 'suspends', 'proceedi'),\n",
       " ('suspends', 'proceedi', '35'),\n",
       " ('proceedi', '35', 'One'),\n",
       " ('35', 'One', 'of'),\n",
       " ('One', 'of', 'the'),\n",
       " ('of', 'the', 'most'),\n",
       " ('the', 'most', 'persistent'),\n",
       " ('most', 'persistent', 'and'),\n",
       " ('persistent', 'and', 'widespread'),\n",
       " ('and', 'widespread', 'piec'),\n",
       " ('widespread', 'piec', '36'),\n",
       " ('piec', '36', 'Kirstin'),\n",
       " ('36', 'Kirstin', 'Knight'),\n",
       " ('Kirstin', 'Knight', 'is'),\n",
       " ('Knight', 'is', 'still'),\n",
       " ('is', 'still', 'apprehensive'),\n",
       " ('still', 'apprehensive', 'at'),\n",
       " ('apprehensive', 'at', 'the'),\n",
       " ('at', 'the', 'th'),\n",
       " ('the', 'th', '37'),\n",
       " ('th', '37', 'The'),\n",
       " ('37', 'The', 'White'),\n",
       " ('The', 'White', 'House'),\n",
       " ('White', 'House', 'and'),\n",
       " ('House', 'and', 'Senate'),\n",
       " ('and', 'Senate', 'leaders'),\n",
       " ('Senate', 'leaders', 'of'),\n",
       " ('leaders', 'of', 'both'),\n",
       " ('of', 'both', 'par'),\n",
       " ('both', 'par', '38'),\n",
       " ('par', '38', 'House'),\n",
       " ('38', 'House', 'of'),\n",
       " ('House', 'of', 'Commons'),\n",
       " ('of', 'Commons', 'suspended'),\n",
       " ('Commons', 'suspended', 'amid'),\n",
       " ('suspended', 'amid', 'COVID19'),\n",
       " ('amid', 'COVID19', 'ai'),\n",
       " ('COVID19', 'ai', '39'),\n",
       " ('ai', '39', 'Chef'),\n",
       " ('39', 'Chef', 'Floyd'),\n",
       " ('Chef', 'Floyd', 'Cardoz'),\n",
       " ('Floyd', 'Cardoz', 'who'),\n",
       " ('Cardoz', 'who', 'competed'),\n",
       " ('who', 'competed', 'on'),\n",
       " ('competed', 'on', 'Top'),\n",
       " ('on', 'Top', 'Chef'),\n",
       " ('Top', 'Chef', 'won'),\n",
       " ('Chef', 'won', '40'),\n",
       " ('won', '40', 'BCs'),\n",
       " ('40', 'BCs', 'Ministry'),\n",
       " ('BCs', 'Ministry', 'of'),\n",
       " ('Ministry', 'of', 'Health'),\n",
       " ('of', 'Health', 'has'),\n",
       " ('Health', 'has', 'released'),\n",
       " ('has', 'released', 'a'),\n",
       " ('released', 'a', 'new'),\n",
       " ('a', 'new', 'app'),\n",
       " ('new', 'app', '41'),\n",
       " ('app', '41', 'A'),\n",
       " ('41', 'A', 'smallbatch'),\n",
       " ('A', 'smallbatch', 'distillery'),\n",
       " ('smallbatch', 'distillery', 'in'),\n",
       " ('distillery', 'in', 'Prince'),\n",
       " ('in', 'Prince', 'Edward'),\n",
       " ('Prince', 'Edward', 'Count'),\n",
       " ('Edward', 'Count', '42'),\n",
       " ('Count', '42', 'A'),\n",
       " ('42', 'A', 'statement'),\n",
       " ('A', 'statement', 'from'),\n",
       " ('statement', 'from', 'G7'),\n",
       " ('from', 'G7', 'finance'),\n",
       " ('G7', 'finance', 'ministers'),\n",
       " ('finance', 'ministers', 'and'),\n",
       " ('ministers', 'and', 'cent'),\n",
       " ('and', 'cent', '43'),\n",
       " ('cent', '43', 'Harvey'),\n",
       " ('43', 'Harvey', 'Weinstein'),\n",
       " ('Harvey', 'Weinstein', 'tested'),\n",
       " ('Weinstein', 'tested', 'positive'),\n",
       " ('tested', 'positive', 'for'),\n",
       " ('positive', 'for', 'the'),\n",
       " ('for', 'the', 'coron'),\n",
       " ('the', 'coron', '44'),\n",
       " ('coron', '44', 'Democrats'),\n",
       " ('44', 'Democrats', 'and'),\n",
       " ('Democrats', 'and', 'Republicans'),\n",
       " ('and', 'Republicans', 'said'),\n",
       " ('Republicans', 'said', 'Tuesday'),\n",
       " ('said', 'Tuesday', 'they'),\n",
       " ('Tuesday', 'they', 'we'),\n",
       " ('they', 'we', '45'),\n",
       " ('we', '45', 'India'),\n",
       " ('45', 'India', 'will'),\n",
       " ('India', 'will', 'begin'),\n",
       " ('will', 'begin', 'the'),\n",
       " ('begin', 'the', 'worlds'),\n",
       " ('the', 'worlds', 'largest'),\n",
       " ('worlds', 'largest', 'lockdown'),\n",
       " ('largest', 'lockdown', 'o'),\n",
       " ('lockdown', 'o', '46'),\n",
       " ('o', '46', 'A'),\n",
       " ('46', 'A', 'Phoenixarea'),\n",
       " ('A', 'Phoenixarea', 'man'),\n",
       " ('Phoenixarea', 'man', 'has'),\n",
       " ('man', 'has', 'died'),\n",
       " ('has', 'died', 'and'),\n",
       " ('died', 'and', 'his'),\n",
       " ('and', 'his', 'wife'),\n",
       " ('his', 'wife', 'was'),\n",
       " ('wife', 'was', 'in'),\n",
       " ('was', 'in', '47'),\n",
       " ('in', '47', 'Main'),\n",
       " ('47', 'Main', 'Street'),\n",
       " ('Main', 'Street', 'Project'),\n",
       " ('Street', 'Project', 'is'),\n",
       " ('Project', 'is', 'moving'),\n",
       " ('is', 'moving', 'fast'),\n",
       " ('moving', 'fast', 'to'),\n",
       " ('fast', 'to', 'create'),\n",
       " ('to', 'create', 's'),\n",
       " ('create', 's', '48'),\n",
       " ('s', '48', 'THE'),\n",
       " ('48', 'THE', 'LATEST'),\n",
       " ('THE', 'LATEST', 'Go'),\n",
       " ('LATEST', 'Go', 'home'),\n",
       " ('Go', 'home', 'and'),\n",
       " ('home', 'and', 'stay'),\n",
       " ('and', 'stay', 'home'),\n",
       " ('stay', 'home', 'Trudeau'),\n",
       " ('home', 'Trudeau', 'tell'),\n",
       " ('Trudeau', 'tell', '49'),\n",
       " ('tell', '49', 'From'),\n",
       " ('49', 'From', 'trumpetplaying'),\n",
       " ('From', 'trumpetplaying', 'for'),\n",
       " ('trumpetplaying', 'for', 'dad'),\n",
       " ('for', 'dad', 'to'),\n",
       " ('dad', 'to', 'a'),\n",
       " ('to', 'a', 'community'),\n",
       " ('a', 'community', 'dan'),\n",
       " ('community', 'dan', '50'),\n",
       " ('dan', '50', 'Travellers'),\n",
       " ('50', 'Travellers', 'coming'),\n",
       " ('Travellers', 'coming', 'through'),\n",
       " ('coming', 'through', 'the'),\n",
       " ('through', 'the', 'Calgary'),\n",
       " ('the', 'Calgary', 'Internat'),\n",
       " ('Calgary', 'Internat', '51'),\n",
       " ('Internat', '51', 'Two'),\n",
       " ('51', 'Two', 'researchers'),\n",
       " ('Two', 'researchers', 'from'),\n",
       " ('researchers', 'from', 'the'),\n",
       " ('from', 'the', 'University'),\n",
       " ('the', 'University', 'of'),\n",
       " ('University', 'of', 'British'),\n",
       " ('of', 'British', '52'),\n",
       " ('British', '52', 'Spanish'),\n",
       " ('52', 'Spanish', 'army'),\n",
       " ('Spanish', 'army', 'troops'),\n",
       " ('army', 'troops', 'disinfecting'),\n",
       " ('troops', 'disinfecting', 'nursing'),\n",
       " ('disinfecting', 'nursing', 'homes'),\n",
       " ('nursing', 'homes', '53'),\n",
       " ('homes', '53', 'Top'),\n",
       " ('53', 'Top', 'congressional'),\n",
       " ('Top', 'congressional', 'and'),\n",
       " ('congressional', 'and', 'White'),\n",
       " ('and', 'White', 'House'),\n",
       " ('White', 'House', 'officials'),\n",
       " ('House', 'officials', 'em'),\n",
       " ('officials', 'em', '54'),\n",
       " ('em', '54', 'Interior'),\n",
       " ('54', 'Interior', 'Health'),\n",
       " ('Interior', 'Health', 'officials'),\n",
       " ('Health', 'officials', 'are'),\n",
       " ('officials', 'are', 'asking'),\n",
       " ('are', 'asking', 'people'),\n",
       " ('asking', 'people', 'wh'),\n",
       " ('people', 'wh', '55'),\n",
       " ('wh', '55', 'The'),\n",
       " ('55', 'The', 'latest'),\n",
       " ('The', 'latest', 'Yukon'),\n",
       " ('latest', 'Yukon', 'reports'),\n",
       " ('Yukon', 'reports', 'first'),\n",
       " ('reports', 'first', '2'),\n",
       " ('first', '2', 'confirmed'),\n",
       " ('2', 'confirmed', 'ca'),\n",
       " ('confirmed', 'ca', '56'),\n",
       " ('ca', '56', 'Stock'),\n",
       " ('56', 'Stock', 'markets'),\n",
       " ('Stock', 'markets', 'in'),\n",
       " ('markets', 'in', 'New'),\n",
       " ('in', 'New', 'York'),\n",
       " ('New', 'York', 'and'),\n",
       " ('York', 'and', 'Toronto'),\n",
       " ('and', 'Toronto', 'jumped'),\n",
       " ('Toronto', 'jumped', 's'),\n",
       " ('jumped', 's', '57'),\n",
       " ('s', '57', 'Fiat'),\n",
       " ('57', 'Fiat', 'Chrysler'),\n",
       " ('Fiat', 'Chrysler', 'Automobiles'),\n",
       " ('Chrysler', 'Automobiles', 'FCA'),\n",
       " ('Automobiles', 'FCA', 'announced'),\n",
       " ('FCA', 'announced', 'on'),\n",
       " ('announced', 'on', 'Mon'),\n",
       " ('on', 'Mon', '58'),\n",
       " ('Mon', '58', 'A'),\n",
       " ('58', 'A', 'strong'),\n",
       " ('A', 'strong', 'earthquake'),\n",
       " ('strong', 'earthquake', 'in'),\n",
       " ('earthquake', 'in', 'Croatia'),\n",
       " ('in', 'Croatia', 'on'),\n",
       " ('Croatia', 'on', 'Sunday'),\n",
       " ('on', 'Sunday', 'cause'),\n",
       " ('Sunday', 'cause', '59'),\n",
       " ('cause', '59', 'The'),\n",
       " ('59', 'The', 'City'),\n",
       " ('The', 'City', 'of'),\n",
       " ('City', 'of', 'Edmonton'),\n",
       " ('of', 'Edmonton', 'announced'),\n",
       " ('Edmonton', 'announced', 'it'),\n",
       " ('announced', 'it', 'will'),\n",
       " ('it', 'will', 'close'),\n",
       " ('will', 'close', 'o'),\n",
       " ('close', 'o', '60'),\n",
       " ('o', '60', 'Michigan'),\n",
       " ('60', 'Michigan', 'Gov'),\n",
       " ('Michigan', 'Gov', 'Gretchen'),\n",
       " ('Gov', 'Gretchen', 'Whitmer'),\n",
       " ('Gretchen', 'Whitmer', 'has'),\n",
       " ('Whitmer', 'has', 'issued'),\n",
       " ('has', 'issued', 'a'),\n",
       " ('issued', 'a', 'sta'),\n",
       " ('a', 'sta', '61'),\n",
       " ('sta', '61', 'Edoardo'),\n",
       " ('61', 'Edoardo', 'Spinosa'),\n",
       " ('Edoardo', 'Spinosa', 'has'),\n",
       " ('Spinosa', 'has', 'been'),\n",
       " ('has', 'been', 'sent'),\n",
       " ('been', 'sent', 'home'),\n",
       " ('sent', 'home', 'to'),\n",
       " ('home', 'to', 'Milan'),\n",
       " ('to', 'Milan', 'It'),\n",
       " ('Milan', 'It', '62'),\n",
       " ('It', '62', 'The'),\n",
       " ('62', 'The', 'provincial'),\n",
       " ('The', 'provincial', 'government'),\n",
       " ('provincial', 'government', 'announced'),\n",
       " ('government', 'announced', '15'),\n",
       " ('announced', '15', 'new'),\n",
       " ('15', 'new', 'pre'),\n",
       " ('new', 'pre', '63'),\n",
       " ('pre', '63', 'Ask'),\n",
       " ('63', 'Ask', 'Syrian'),\n",
       " ('Ask', 'Syrian', 'aid'),\n",
       " ('Syrian', 'aid', 'worker'),\n",
       " ('aid', 'worker', 'Osama'),\n",
       " ('worker', 'Osama', 'alHussein'),\n",
       " ('Osama', 'alHussein', 'how'),\n",
       " ('alHussein', 'how', 'hes'),\n",
       " ('how', 'hes', '64'),\n",
       " ('hes', '64', 'The'),\n",
       " ('64', 'The', 'possibility'),\n",
       " ('The', 'possibility', 'of'),\n",
       " ('possibility', 'of', 'having'),\n",
       " ('of', 'having', 'COVID19'),\n",
       " ('having', 'COVID19', 'started'),\n",
       " ('COVID19', 'started', 'to'),\n",
       " ('started', 'to', 'b'),\n",
       " ('to', 'b', '65'),\n",
       " ('b', '65', 'The'),\n",
       " ('65', 'The', 'coronavirus'),\n",
       " ('The', 'coronavirus', 'pandemic'),\n",
       " ('coronavirus', 'pandemic', 'will'),\n",
       " ('pandemic', 'will', 'cause'),\n",
       " ('will', 'cause', 'a'),\n",
       " ('cause', 'a', 'global'),\n",
       " ('a', 'global', 'r'),\n",
       " ('global', 'r', '66'),\n",
       " ('r', '66', 'British'),\n",
       " ('66', 'British', 'Prime'),\n",
       " ('British', 'Prime', 'Minister'),\n",
       " ('Prime', 'Minister', 'Boris'),\n",
       " ('Minister', 'Boris', 'Johnson'),\n",
       " ('Boris', 'Johnson', 'on'),\n",
       " ('Johnson', 'on', 'Monday'),\n",
       " ('on', 'Monday', '67'),\n",
       " ('Monday', '67', 'As'),\n",
       " ('67', 'As', 'the'),\n",
       " ('As', 'the', 'doors'),\n",
       " ('the', 'doors', 'of'),\n",
       " ('doors', 'of', 'planes'),\n",
       " ('of', 'planes', 'landing'),\n",
       " ('planes', 'landing', 'at'),\n",
       " ('landing', 'at', 'Beijings'),\n",
       " ('at', 'Beijings', 'Cap'),\n",
       " ('Beijings', 'Cap', '68'),\n",
       " ('Cap', '68', 'The'),\n",
       " ('68', 'The', 'greatness'),\n",
       " ('The', 'greatness', 'of'),\n",
       " ('greatness', 'of', 'the'),\n",
       " ('of', 'the', 'American'),\n",
       " ('the', 'American', 'character'),\n",
       " ('American', 'character', 'is'),\n",
       " ('character', 'is', 'shi'),\n",
       " ('is', 'shi', '69'),\n",
       " ('shi', '69', 'With'),\n",
       " ('69', 'With', 'live'),\n",
       " ('With', 'live', 'events'),\n",
       " ('live', 'events', 'being'),\n",
       " ('events', 'being', 'cancelled'),\n",
       " ('being', 'cancelled', 'due'),\n",
       " ('cancelled', 'due', 'to'),\n",
       " ('due', 'to', 'concer'),\n",
       " ('to', 'concer', '70'),\n",
       " ('concer', '70', 'The'),\n",
       " ('70', 'The', 'WindsorEssex'),\n",
       " ('The', 'WindsorEssex', 'County'),\n",
       " ('WindsorEssex', 'County', 'Health'),\n",
       " ('County', 'Health', 'Unit'),\n",
       " ('Health', 'Unit', 'confirmed'),\n",
       " ('Unit', 'confirmed', '71'),\n",
       " ('confirmed', '71', 'London'),\n",
       " ('71', 'London', 'area'),\n",
       " ('London', 'area', 'health'),\n",
       " ('area', 'health', 'professionals'),\n",
       " ('health', 'professionals', 'are'),\n",
       " ('professionals', 'are', 'the'),\n",
       " ('are', 'the', 'first'),\n",
       " ('the', 'first', '72'),\n",
       " ('first', '72', 'In'),\n",
       " ('72', 'In', 'these'),\n",
       " ('In', 'these', 'days'),\n",
       " ('these', 'days', 'of'),\n",
       " ('days', 'of', 'physical'),\n",
       " ('of', 'physical', 'distancing'),\n",
       " ('physical', 'distancing', 'grocery'),\n",
       " ('distancing', 'grocery', 's'),\n",
       " ('grocery', 's', '73'),\n",
       " ('s', '73', 'As'),\n",
       " ('73', 'As', 'the'),\n",
       " ('As', 'the', 'coronavirus'),\n",
       " ('the', 'coronavirus', 'infects'),\n",
       " ('coronavirus', 'infects', 'more'),\n",
       " ('infects', 'more', 'people'),\n",
       " ('more', 'people', 'around'),\n",
       " ('people', 'around', '74'),\n",
       " ('around', '74', 'Nine'),\n",
       " ('74', 'Nine', 'workers'),\n",
       " ('Nine', 'workers', 'will'),\n",
       " ('workers', 'will', 'stay'),\n",
       " ('will', 'stay', 'indefinitely'),\n",
       " ('stay', 'indefinitely', 'at'),\n",
       " ('indefinitely', 'at', 'the'),\n",
       " ('at', 'the', 'Cit'),\n",
       " ('the', 'Cit', '75'),\n",
       " ('Cit', '75', 'A'),\n",
       " ('75', 'A', 'group'),\n",
       " ('A', 'group', 'of'),\n",
       " ('group', 'of', 'eastern'),\n",
       " ('of', 'eastern', 'Ontario'),\n",
       " ('eastern', 'Ontario', 'municipal'),\n",
       " ('Ontario', 'municipal', 'leaders'),\n",
       " ('municipal', 'leaders', 'i'),\n",
       " ('leaders', 'i', '76'),\n",
       " ('i', '76', 'An'),\n",
       " ('76', 'An', 'expanded'),\n",
       " ('An', 'expanded', 'call'),\n",
       " ('expanded', 'call', 'centre'),\n",
       " ('call', 'centre', 'at'),\n",
       " ('centre', 'at', 'Global'),\n",
       " ('at', 'Global', 'Affairs'),\n",
       " ('Global', 'Affairs', 'Cana'),\n",
       " ('Affairs', 'Cana', '77'),\n",
       " ('Cana', '77', 'Slaight'),\n",
       " ('77', 'Slaight', 'Music'),\n",
       " ('Slaight', 'Music', 'is'),\n",
       " ('Music', 'is', 'doubling'),\n",
       " ('is', 'doubling', 'a'),\n",
       " ('doubling', 'a', 'performing'),\n",
       " ('a', 'performing', 'arts'),\n",
       " ('performing', 'arts', 'fu'),\n",
       " ('arts', 'fu', '78'),\n",
       " ('fu', '78', 'Laurie'),\n",
       " ('78', 'Laurie', 'Pushor'),\n",
       " ('Laurie', 'Pushor', 'Saskatchewans'),\n",
       " ('Pushor', 'Saskatchewans', 'deputy'),\n",
       " ('Saskatchewans', 'deputy', 'minister'),\n",
       " ('deputy', 'minister', 'of'),\n",
       " ('minister', 'of', '79'),\n",
       " ('of', '79', 'BC'),\n",
       " ('79', 'BC', 'is'),\n",
       " ('BC', 'is', 'ordering'),\n",
       " ('is', 'ordering', 'all'),\n",
       " ('ordering', 'all', 'restaurants'),\n",
       " ('all', 'restaurants', 'to'),\n",
       " ('restaurants', 'to', 'stop'),\n",
       " ('to', 'stop', 'providi'),\n",
       " ('stop', 'providi', '80'),\n",
       " ('providi', '80', 'Whats'),\n",
       " ('80', 'Whats', 'COVID19'),\n",
       " ('Whats', 'COVID19', 'Whats'),\n",
       " ('COVID19', 'Whats', 'isolation'),\n",
       " ('Whats', 'isolation', 'Is'),\n",
       " ('isolation', 'Is', 'there'),\n",
       " ('Is', 'there', 'a'),\n",
       " ('there', 'a', 'cure'),\n",
       " ('a', 'cure', '81'),\n",
       " ('cure', '81', 'A'),\n",
       " ('81', 'A', 'tentative'),\n",
       " ('A', 'tentative', 'agreement'),\n",
       " ('tentative', 'agreement', 'has'),\n",
       " ('agreement', 'has', 'been'),\n",
       " ('has', 'been', 'reached'),\n",
       " ('been', 'reached', 'with'),\n",
       " ('reached', 'with', 'Br'),\n",
       " ('with', 'Br', '82'),\n",
       " ('Br', '82', 'A'),\n",
       " ('82', 'A', 'survey'),\n",
       " ('A', 'survey', 'conducted'),\n",
       " ('survey', 'conducted', 'by'),\n",
       " ('conducted', 'by', 'Dene'),\n",
       " ('by', 'Dene', 'Nation'),\n",
       " ('Dene', 'Nation', 'suggests'),\n",
       " ('Nation', 'suggests', 'tha'),\n",
       " ('suggests', 'tha', '83'),\n",
       " ('tha', '83', 'Alberta'),\n",
       " ('83', 'Alberta', 'talk'),\n",
       " ('Alberta', 'talk', 'radio'),\n",
       " ('talk', 'radio', 'host'),\n",
       " ('radio', 'host', 'and'),\n",
       " ('host', 'and', 'former'),\n",
       " ('and', 'former', 'Wildrose'),\n",
       " ('former', 'Wildrose', 'Pa'),\n",
       " ('Wildrose', 'Pa', '84'),\n",
       " ('Pa', '84', 'The'),\n",
       " ('84', 'The', 'Cannes'),\n",
       " ('The', 'Cannes', 'Film'),\n",
       " ('Cannes', 'Film', 'Festival'),\n",
       " ('Film', 'Festival', 'has'),\n",
       " ('Festival', 'has', 'been'),\n",
       " ('has', 'been', 'postponed'),\n",
       " ('been', 'postponed', 'du'),\n",
       " ('postponed', 'du', '85'),\n",
       " ('du', '85', 'Like'),\n",
       " ('85', 'Like', 'airports'),\n",
       " ('Like', 'airports', 'around'),\n",
       " ('airports', 'around', 'the'),\n",
       " ('around', 'the', 'world'),\n",
       " ('the', 'world', 'the'),\n",
       " ('world', 'the', 'global'),\n",
       " ('the', 'global', 'pand'),\n",
       " ('global', 'pand', '86'),\n",
       " ('pand', '86', 'The'),\n",
       " ('86', 'The', 'latest'),\n",
       " ('The', 'latest', 'NWT'),\n",
       " ('latest', 'NWT', 'confirms'),\n",
       " ('NWT', 'confirms', '1st'),\n",
       " ('confirms', '1st', 'case'),\n",
       " ('1st', 'case', 'in'),\n",
       " ('case', 'in', 'the'),\n",
       " ('in', 'the', 'terri'),\n",
       " ('the', 'terri', '87'),\n",
       " ('terri', '87', 'Leaders'),\n",
       " ('87', 'Leaders', 'of'),\n",
       " ('Leaders', 'of', 'the'),\n",
       " ('of', 'the', 'worlds'),\n",
       " ('the', 'worlds', '20'),\n",
       " ('worlds', '20', 'biggest'),\n",
       " ('20', 'biggest', 'economies'),\n",
       " ('biggest', 'economies', 'met'),\n",
       " ('economies', 'met', '88'),\n",
       " ('met', '88', 'A'),\n",
       " ('88', 'A', 'man'),\n",
       " ('A', 'man', 'in'),\n",
       " ('man', 'in', 'his'),\n",
       " ('in', 'his', '50s'),\n",
       " ('his', '50s', 'who'),\n",
       " ('50s', 'who', 'tested'),\n",
       " ('who', 'tested', 'positive'),\n",
       " ('tested', 'positive', 'for'),\n",
       " ('positive', 'for', 'COVID'),\n",
       " ('for', 'COVID', '89'),\n",
       " ('COVID', '89', 'Confused'),\n",
       " ('89', 'Confused', 'about'),\n",
       " ('Confused', 'about', 'the'),\n",
       " ('about', 'the', 'language'),\n",
       " ('the', 'language', 'that'),\n",
       " ('language', 'that', 'health'),\n",
       " ('that', 'health', 'and'),\n",
       " ('health', 'and', 'go'),\n",
       " ('and', 'go', '90'),\n",
       " ('go', '90', 'Italys'),\n",
       " ('90', 'Italys', 'death'),\n",
       " ('Italys', 'death', 'toll'),\n",
       " ('death', 'toll', 'from'),\n",
       " ('toll', 'from', 'coronavirus'),\n",
       " ('from', 'coronavirus', 'on'),\n",
       " ('coronavirus', 'on', 'Thursday'),\n",
       " ('on', 'Thursday', '91'),\n",
       " ('Thursday', '91', 'The'),\n",
       " ('91', 'The', 'coronavirus'),\n",
       " ('The', 'coronavirus', 'outbreak'),\n",
       " ('coronavirus', 'outbreak', 'has'),\n",
       " ('outbreak', 'has', 'resulted'),\n",
       " ('has', 'resulted', 'in'),\n",
       " ('resulted', 'in', 'a'),\n",
       " ('in', 'a', 'del'),\n",
       " ('a', 'del', '92'),\n",
       " ('del', '92', 'BC'),\n",
       " ('92', 'BC', 'is'),\n",
       " ('BC', 'is', 'ordering'),\n",
       " ('is', 'ordering', 'all'),\n",
       " ('ordering', 'all', 'restaurants'),\n",
       " ('all', 'restaurants', 'to'),\n",
       " ('restaurants', 'to', 'stop'),\n",
       " ('to', 'stop', 'providi'),\n",
       " ('stop', 'providi', '93'),\n",
       " ('providi', '93', 'Southwest'),\n",
       " ('93', 'Southwest', 'Sounds'),\n",
       " ('Southwest', 'Sounds', 'is'),\n",
       " ('Sounds', 'is', 'a'),\n",
       " ('is', 'a', 'weekly'),\n",
       " ('a', 'weekly', 'feature'),\n",
       " ('weekly', 'feature', 'that'),\n",
       " ('feature', 'that', 'prof'),\n",
       " ('that', 'prof', '94'),\n",
       " ('prof', '94', 'Twothirds'),\n",
       " ('94', 'Twothirds', 'of'),\n",
       " ('Twothirds', 'of', 'Canadians'),\n",
       " ('of', 'Canadians', 'think'),\n",
       " ('Canadians', 'think', 'Prime'),\n",
       " ('think', 'Prime', 'Minister'),\n",
       " ('Prime', 'Minister', 'Ju'),\n",
       " ('Minister', 'Ju', '95'),\n",
       " ('Ju', '95', 'The'),\n",
       " ('95', 'The', 'Alberta'),\n",
       " ('The', 'Alberta', 'government'),\n",
       " ('Alberta', 'government', 'has'),\n",
       " ('government', 'has', 'fished'),\n",
       " ('has', 'fished', '153'),\n",
       " ('fished', '153', 'million'),\n",
       " ('153', 'million', '96'),\n",
       " ('million', '96', 'BC'),\n",
       " ('96', 'BC', 'is'),\n",
       " ('BC', 'is', 'ordering'),\n",
       " ('is', 'ordering', 'all'),\n",
       " ('ordering', 'all', 'restaurants'),\n",
       " ('all', 'restaurants', 'to'),\n",
       " ('restaurants', 'to', 'stop'),\n",
       " ('to', 'stop', 'providi'),\n",
       " ('stop', 'providi', '97'),\n",
       " ('providi', '97', 'As'),\n",
       " ('97', 'As', 'if'),\n",
       " ('As', 'if', 'there'),\n",
       " ('if', 'there', 'wasnt'),\n",
       " ('there', 'wasnt', 'enough'),\n",
       " ('wasnt', 'enough', 'COVID19'),\n",
       " ('enough', 'COVID19', 'chaos'),\n",
       " ('COVID19', 'chaos', 'in'),\n",
       " ('chaos', 'in', 'the'),\n",
       " ('in', 'the', '98'),\n",
       " ('the', '98', 'While'),\n",
       " ('98', 'While', 'many'),\n",
       " ('While', 'many', 'people'),\n",
       " ('many', 'people', 'are'),\n",
       " ('people', 'are', 'staying'),\n",
       " ('are', 'staying', 'home'),\n",
       " ('staying', 'home', 'amid'),\n",
       " ('home', 'amid', 'COVID1'),\n",
       " ('amid', 'COVID1', '99'),\n",
       " ('COVID1', '99', 'The'),\n",
       " ('99', 'The', 'latest'),\n",
       " ('The', 'latest', 'Ottawa'),\n",
       " ('latest', 'Ottawa', 'finalizing'),\n",
       " ('Ottawa', 'finalizing', 'plan'),\n",
       " ('finalizing', 'plan', 'to'),\n",
       " ('plan', 'to', 'boost'),\n",
       " ('to', 'boost', 'pr'),\n",
       " ('boost', 'pr', '100'),\n",
       " ('pr', '100', 'Ford'),\n",
       " ('100', 'Ford', 'General'),\n",
       " ('Ford', 'General', 'Motors'),\n",
       " ('General', 'Motors', 'Fiat'),\n",
       " ('Motors', 'Fiat', 'Chrysler'),\n",
       " ('Fiat', 'Chrysler', 'Honda'),\n",
       " ('Chrysler', 'Honda', 'and'),\n",
       " ('Honda', 'and', 'To'),\n",
       " ('and', 'To', '101'),\n",
       " ('To', '101', 'The'),\n",
       " ('101', 'The', 'provincial'),\n",
       " ('The', 'provincial', 'government'),\n",
       " ('provincial', 'government', 'says'),\n",
       " ('government', 'says', 'safe'),\n",
       " ('says', 'safe', 'prescripti'),\n",
       " ('safe', 'prescripti', '102'),\n",
       " ('prescripti', '102', 'Starbucks'),\n",
       " ('102', 'Starbucks', 'is'),\n",
       " ('Starbucks', 'is', 'joining'),\n",
       " ('is', 'joining', 'the'),\n",
       " ('joining', 'the', 'growing'),\n",
       " ('the', 'growing', 'list'),\n",
       " ('growing', 'list', 'of'),\n",
       " ('list', 'of', 'compa'),\n",
       " ('of', 'compa', '103'),\n",
       " ('compa', '103', 'COVID19'),\n",
       " ('103', 'COVID19', 'anxiety'),\n",
       " ('COVID19', 'anxiety', 'is'),\n",
       " ('anxiety', 'is', 'real'),\n",
       " ('is', 'real', 'for'),\n",
       " ('real', 'for', 'many'),\n",
       " ('for', 'many', 'people'),\n",
       " ('many', 'people', 'but'),\n",
       " ('people', 'but', 'it'),\n",
       " ('but', 'it', '104'),\n",
       " ('it', '104', 'Netflix'),\n",
       " ('104', 'Netflix', 'said'),\n",
       " ('Netflix', 'said', 'Friday'),\n",
       " ('said', 'Friday', 'it'),\n",
       " ('Friday', 'it', 'is'),\n",
       " ('it', 'is', 'establishing'),\n",
       " ('is', 'establishing', 'a'),\n",
       " ('establishing', 'a', '100'),\n",
       " ('a', '100', 'm'),\n",
       " ('100', 'm', '105'),\n",
       " ('m', '105', 'The'),\n",
       " ('105', 'The', 'Ministry'),\n",
       " ('The', 'Ministry', 'of'),\n",
       " ('Ministry', 'of', 'Health'),\n",
       " ('of', 'Health', 'has'),\n",
       " ('Health', 'has', 'quietly'),\n",
       " ('has', 'quietly', 'launched'),\n",
       " ('quietly', 'launched', 'a'),\n",
       " ('launched', 'a', '106'),\n",
       " ('a', '106', 'UPDATE'),\n",
       " ('106', 'UPDATE', 'On'),\n",
       " ('UPDATE', 'On', 'March'),\n",
       " ('On', 'March', '12'),\n",
       " ('March', '12', 'Hong'),\n",
       " ('12', 'Hong', 'Kongs'),\n",
       " ('Hong', 'Kongs', 'Agriculture'),\n",
       " ('Kongs', 'Agriculture', 'Fish'),\n",
       " ('Agriculture', 'Fish', '107'),\n",
       " ('Fish', '107', 'In'),\n",
       " ('107', 'In', 'the'),\n",
       " ('In', 'the', '25'),\n",
       " ('the', '25', 'years'),\n",
       " ('25', 'years', 'hes'),\n",
       " ('years', 'hes', 'owned'),\n",
       " ('hes', 'owned', 'his'),\n",
       " ('owned', 'his', 'Ontario'),\n",
       " ('his', 'Ontario', 'gun'),\n",
       " ('Ontario', 'gun', 'shop'),\n",
       " ('gun', 'shop', '108'),\n",
       " ('shop', '108', 'Employees'),\n",
       " ('108', 'Employees', 'at'),\n",
       " ('Employees', 'at', 'TD'),\n",
       " ('at', 'TD', 'Bank'),\n",
       " ('TD', 'Bank', 'say'),\n",
       " ('Bank', 'say', 'hundreds'),\n",
       " ('say', 'hundreds', 'of'),\n",
       " ('hundreds', 'of', 'people'),\n",
       " ('of', 'people', 'ar'),\n",
       " ('people', 'ar', '109'),\n",
       " ('ar', '109', 'Sarah'),\n",
       " ('109', 'Sarah', 'Swarks'),\n",
       " ('Sarah', 'Swarks', 'wedding'),\n",
       " ('Swarks', 'wedding', 'is'),\n",
       " ('wedding', 'is', 'not'),\n",
       " ('is', 'not', 'going'),\n",
       " ('not', 'going', 'ahead'),\n",
       " ('going', 'ahead', 'as'),\n",
       " ('ahead', 'as', 'pla'),\n",
       " ('as', 'pla', '110'),\n",
       " ('pla', '110', 'Canadas'),\n",
       " ('110', 'Canadas', 'hospitals'),\n",
       " ('Canadas', 'hospitals', 'and'),\n",
       " ('hospitals', 'and', 'health'),\n",
       " ('and', 'health', 'officials'),\n",
       " ('health', 'officials', 'are'),\n",
       " ('officials', 'are', 'loo'),\n",
       " ('are', 'loo', '111'),\n",
       " ('loo', '111', 'Extra'),\n",
       " ('111', 'Extra', 'resources'),\n",
       " ('Extra', 'resources', 'are'),\n",
       " ('resources', 'are', 'being'),\n",
       " ('are', 'being', 'added'),\n",
       " ('being', 'added', 'to'),\n",
       " ('added', 'to', 'the'),\n",
       " ('to', 'the', 'Tele–Ca'),\n",
       " ('the', 'Tele–Ca', '112'),\n",
       " ('Tele–Ca', '112', 'The'),\n",
       " ('112', 'The', 'Eurovision'),\n",
       " ('The', 'Eurovision', 'song'),\n",
       " ('Eurovision', 'song', 'contest'),\n",
       " ('song', 'contest', 'one'),\n",
       " ('contest', 'one', 'of'),\n",
       " ('one', 'of', 'the'),\n",
       " ('of', 'the', 'worlds'),\n",
       " ('the', 'worlds', '113'),\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=trigrams(tokens)\n",
    "[x for x in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Canadian', 'pharmacies', 'are', 'limiting'),\n",
       " ('Canadian', 'pharmacies', 'are', 'limiting', 'how'),\n",
       " ('pharmacies', 'are', 'limiting', 'how', 'much'),\n",
       " ('are', 'limiting', 'how', 'much', 'medi'),\n",
       " ('limiting', 'how', 'much', 'medi', '1'),\n",
       " ('how', 'much', 'medi', '1', 'The'),\n",
       " ('much', 'medi', '1', 'The', 'Yukon'),\n",
       " ('medi', '1', 'The', 'Yukon', 'government'),\n",
       " ('1', 'The', 'Yukon', 'government', 'has'),\n",
       " ('The', 'Yukon', 'government', 'has', 'identified'),\n",
       " ('Yukon', 'government', 'has', 'identified', 'two'),\n",
       " ('government', 'has', 'identified', 'two', 'places'),\n",
       " ('has', 'identified', 'two', 'places', '2'),\n",
       " ('identified', 'two', 'places', '2', 'The'),\n",
       " ('two', 'places', '2', 'The', 'Senate'),\n",
       " ('places', '2', 'The', 'Senate', 'late'),\n",
       " ('2', 'The', 'Senate', 'late', 'Wednesday'),\n",
       " ('The', 'Senate', 'late', 'Wednesday', 'passed'),\n",
       " ('Senate', 'late', 'Wednesday', 'passed', 'an'),\n",
       " ('late', 'Wednesday', 'passed', 'an', 'unparallel'),\n",
       " ('Wednesday', 'passed', 'an', 'unparallel', '3'),\n",
       " ('passed', 'an', 'unparallel', '3', 'Scientists'),\n",
       " ('an', 'unparallel', '3', 'Scientists', 'around'),\n",
       " ('unparallel', '3', 'Scientists', 'around', 'the'),\n",
       " ('3', 'Scientists', 'around', 'the', 'world'),\n",
       " ('Scientists', 'around', 'the', 'world', 'are'),\n",
       " ('around', 'the', 'world', 'are', 'racing'),\n",
       " ('the', 'world', 'are', 'racing', 'to'),\n",
       " ('world', 'are', 'racing', 'to', 'find'),\n",
       " ('are', 'racing', 'to', 'find', '4'),\n",
       " ('racing', 'to', 'find', '4', 'Trudeau'),\n",
       " ('to', 'find', '4', 'Trudeau', 'says'),\n",
       " ('find', '4', 'Trudeau', 'says', 'rules'),\n",
       " ('4', 'Trudeau', 'says', 'rules', 'of'),\n",
       " ('Trudeau', 'says', 'rules', 'of', 'Quarantine'),\n",
       " ('says', 'rules', 'of', 'Quarantine', 'Act'),\n",
       " ('rules', 'of', 'Quarantine', 'Act', 'will'),\n",
       " ('of', 'Quarantine', 'Act', 'will', '5'),\n",
       " ('Quarantine', 'Act', 'will', '5', 'The'),\n",
       " ('Act', 'will', '5', 'The', 'continued'),\n",
       " ('will', '5', 'The', 'continued', 'existence'),\n",
       " ('5', 'The', 'continued', 'existence', 'of'),\n",
       " ('The', 'continued', 'existence', 'of', 'wildlife'),\n",
       " ('continued', 'existence', 'of', 'wildlife', 'markets'),\n",
       " ('existence', 'of', 'wildlife', 'markets', 'wh'),\n",
       " ('of', 'wildlife', 'markets', 'wh', '6'),\n",
       " ('wildlife', 'markets', 'wh', '6', 'Recent'),\n",
       " ('markets', 'wh', '6', 'Recent', 'developments'),\n",
       " ('wh', '6', 'Recent', 'developments', 'Two'),\n",
       " ('6', 'Recent', 'developments', 'Two', 'new'),\n",
       " ('Recent', 'developments', 'Two', 'new', 'cases'),\n",
       " ('developments', 'Two', 'new', 'cases', 'in'),\n",
       " ('Two', 'new', 'cases', 'in', 'western'),\n",
       " ('new', 'cases', 'in', 'western', '7'),\n",
       " ('cases', 'in', 'western', '7', 'Michigan'),\n",
       " ('in', 'western', '7', 'Michigan', 'hospitals'),\n",
       " ('western', '7', 'Michigan', 'hospitals', 'are'),\n",
       " ('7', 'Michigan', 'hospitals', 'are', 'bracing'),\n",
       " ('Michigan', 'hospitals', 'are', 'bracing', 'for'),\n",
       " ('hospitals', 'are', 'bracing', 'for', 'a'),\n",
       " ('are', 'bracing', 'for', 'a', 'surge'),\n",
       " ('bracing', 'for', 'a', 'surge', 'of'),\n",
       " ('for', 'a', 'surge', 'of', '8'),\n",
       " ('a', 'surge', 'of', '8', 'The'),\n",
       " ('surge', 'of', '8', 'The', 'number'),\n",
       " ('of', '8', 'The', 'number', 'of'),\n",
       " ('8', 'The', 'number', 'of', 'confirmed'),\n",
       " ('The', 'number', 'of', 'confirmed', 'COVID19'),\n",
       " ('number', 'of', 'confirmed', 'COVID19', 'cases'),\n",
       " ('of', 'confirmed', 'COVID19', 'cases', 'in'),\n",
       " ('confirmed', 'COVID19', 'cases', 'in', 'the'),\n",
       " ('COVID19', 'cases', 'in', 'the', 'U'),\n",
       " ('cases', 'in', 'the', 'U', '9'),\n",
       " ('in', 'the', 'U', '9', 'The'),\n",
       " ('the', 'U', '9', 'The', 'Jewish'),\n",
       " ('U', '9', 'The', 'Jewish', 'General'),\n",
       " ('9', 'The', 'Jewish', 'General', 'Hospital'),\n",
       " ('The', 'Jewish', 'General', 'Hospital', 'plans'),\n",
       " ('Jewish', 'General', 'Hospital', 'plans', 'to'),\n",
       " ('General', 'Hospital', 'plans', 'to', 'set'),\n",
       " ('Hospital', 'plans', 'to', 'set', 'up'),\n",
       " ('plans', 'to', 'set', 'up', 'tr'),\n",
       " ('to', 'set', 'up', 'tr', '10'),\n",
       " ('set', 'up', 'tr', '10', 'Three'),\n",
       " ('up', 'tr', '10', 'Three', 'Saskatchewan'),\n",
       " ('tr', '10', 'Three', 'Saskatchewan', 'residents'),\n",
       " ('10', 'Three', 'Saskatchewan', 'residents', 'have'),\n",
       " ('Three', 'Saskatchewan', 'residents', 'have', 'recovered'),\n",
       " ('Saskatchewan', 'residents', 'have', 'recovered', 'f'),\n",
       " ('residents', 'have', 'recovered', 'f', '11'),\n",
       " ('have', 'recovered', 'f', '11', 'A'),\n",
       " ('recovered', 'f', '11', 'A', 'Manitoba'),\n",
       " ('f', '11', 'A', 'Manitoba', 'chiefs'),\n",
       " ('11', 'A', 'Manitoba', 'chiefs', 'organization'),\n",
       " ('A', 'Manitoba', 'chiefs', 'organization', 'wants'),\n",
       " ('Manitoba', 'chiefs', 'organization', 'wants', 'the'),\n",
       " ('chiefs', 'organization', 'wants', 'the', 'feder'),\n",
       " ('organization', 'wants', 'the', 'feder', '12'),\n",
       " ('wants', 'the', 'feder', '12', 'This'),\n",
       " ('the', 'feder', '12', 'This', 'column'),\n",
       " ('feder', '12', 'This', 'column', 'is'),\n",
       " ('12', 'This', 'column', 'is', 'an'),\n",
       " ('This', 'column', 'is', 'an', 'opinion'),\n",
       " ('column', 'is', 'an', 'opinion', 'by'),\n",
       " ('is', 'an', 'opinion', 'by', 'Colleen'),\n",
       " ('an', 'opinion', 'by', 'Colleen', 'M'),\n",
       " ('opinion', 'by', 'Colleen', 'M', 'Flood'),\n",
       " ('by', 'Colleen', 'M', 'Flood', 'T'),\n",
       " ('Colleen', 'M', 'Flood', 'T', '13'),\n",
       " ('M', 'Flood', 'T', '13', 'Construction'),\n",
       " ('Flood', 'T', '13', 'Construction', 'is'),\n",
       " ('T', '13', 'Construction', 'is', 'on'),\n",
       " ('13', 'Construction', 'is', 'on', 'Ontarios'),\n",
       " ('Construction', 'is', 'on', 'Ontarios', 'list'),\n",
       " ('is', 'on', 'Ontarios', 'list', 'of'),\n",
       " ('on', 'Ontarios', 'list', 'of', 'essential'),\n",
       " ('Ontarios', 'list', 'of', 'essential', '14'),\n",
       " ('list', 'of', 'essential', '14', 'Albertas'),\n",
       " ('of', 'essential', '14', 'Albertas', 'TV'),\n",
       " ('essential', '14', 'Albertas', 'TV', 'and'),\n",
       " ('14', 'Albertas', 'TV', 'and', 'movie'),\n",
       " ('Albertas', 'TV', 'and', 'movie', 'industry'),\n",
       " ('TV', 'and', 'movie', 'industry', 'is'),\n",
       " ('and', 'movie', 'industry', 'is', 'completely'),\n",
       " ('movie', 'industry', 'is', 'completely', 's'),\n",
       " ('industry', 'is', 'completely', 's', '15'),\n",
       " ('is', 'completely', 's', '15', 'The'),\n",
       " ('completely', 's', '15', 'The', 'first'),\n",
       " ('s', '15', 'The', 'first', 'wave'),\n",
       " ('15', 'The', 'first', 'wave', 'hit'),\n",
       " ('The', 'first', 'wave', 'hit', 'last'),\n",
       " ('first', 'wave', 'hit', 'last', 'week'),\n",
       " ('wave', 'hit', 'last', 'week', 'The'),\n",
       " ('hit', 'last', 'week', 'The', 'ER'),\n",
       " ('last', 'week', 'The', 'ER', 'at'),\n",
       " ('week', 'The', 'ER', 'at', 'NYU'),\n",
       " ('The', 'ER', 'at', 'NYU', 'Lan'),\n",
       " ('ER', 'at', 'NYU', 'Lan', '16'),\n",
       " ('at', 'NYU', 'Lan', '16', 'A'),\n",
       " ('NYU', 'Lan', '16', 'A', 'Memorial'),\n",
       " ('Lan', '16', 'A', 'Memorial', 'University'),\n",
       " ('16', 'A', 'Memorial', 'University', 'professor'),\n",
       " ('A', 'Memorial', 'University', 'professor', 'is'),\n",
       " ('Memorial', 'University', 'professor', 'is', 'hiring'),\n",
       " ('University', 'professor', 'is', 'hiring', 'cash'),\n",
       " ('professor', 'is', 'hiring', 'cash', '17'),\n",
       " ('is', 'hiring', 'cash', '17', 'Manitoba'),\n",
       " ('hiring', 'cash', '17', 'Manitoba', 'is'),\n",
       " ('cash', '17', 'Manitoba', 'is', 'under'),\n",
       " ('17', 'Manitoba', 'is', 'under', 'a'),\n",
       " ('Manitoba', 'is', 'under', 'a', 'state'),\n",
       " ('is', 'under', 'a', 'state', 'of'),\n",
       " ('under', 'a', 'state', 'of', 'emergency'),\n",
       " ('a', 'state', 'of', 'emergency', 'as'),\n",
       " ('state', 'of', 'emergency', 'as', 'the'),\n",
       " ('of', 'emergency', 'as', 'the', '18'),\n",
       " ('emergency', 'as', 'the', '18', 'Medical'),\n",
       " ('as', 'the', '18', 'Medical', 'experts'),\n",
       " ('the', '18', 'Medical', 'experts', 'are'),\n",
       " ('18', 'Medical', 'experts', 'are', 'warning'),\n",
       " ('Medical', 'experts', 'are', 'warning', 'Canadians'),\n",
       " ('experts', 'are', 'warning', 'Canadians', 'not'),\n",
       " ('are', 'warning', 'Canadians', 'not', 'to'),\n",
       " ('warning', 'Canadians', 'not', 'to', 'b'),\n",
       " ('Canadians', 'not', 'to', 'b', '19'),\n",
       " ('not', 'to', 'b', '19', 'New'),\n",
       " ('to', 'b', '19', 'New', 'Brunswick'),\n",
       " ('b', '19', 'New', 'Brunswick', 'has'),\n",
       " ('19', 'New', 'Brunswick', 'has', 'lost'),\n",
       " ('New', 'Brunswick', 'has', 'lost', 'its'),\n",
       " ('Brunswick', 'has', 'lost', 'its', 'chance'),\n",
       " ('has', 'lost', 'its', 'chance', 'to'),\n",
       " ('lost', 'its', 'chance', 'to', 'use'),\n",
       " ('its', 'chance', 'to', 'use', 'testi'),\n",
       " ('chance', 'to', 'use', 'testi', '20'),\n",
       " ('to', 'use', 'testi', '20', 'Parliament'),\n",
       " ('use', 'testi', '20', 'Parliament', 'passes'),\n",
       " ('testi', '20', 'Parliament', 'passes', '107'),\n",
       " ('20', 'Parliament', 'passes', '107', 'billion'),\n",
       " ('Parliament', 'passes', '107', 'billion', 'COVID19'),\n",
       " ('passes', '107', 'billion', 'COVID19', 'aid'),\n",
       " ('107', 'billion', 'COVID19', 'aid', '21'),\n",
       " ('billion', 'COVID19', 'aid', '21', 'Prince'),\n",
       " ('COVID19', 'aid', '21', 'Prince', 'Charles'),\n",
       " ('aid', '21', 'Prince', 'Charles', 'the'),\n",
       " ('21', 'Prince', 'Charles', 'the', 'heir'),\n",
       " ('Prince', 'Charles', 'the', 'heir', 'to'),\n",
       " ('Charles', 'the', 'heir', 'to', 'the'),\n",
       " ('the', 'heir', 'to', 'the', 'British'),\n",
       " ('heir', 'to', 'the', 'British', 'throne'),\n",
       " ('to', 'the', 'British', 'throne', '22'),\n",
       " ('the', 'British', 'throne', '22', 'The'),\n",
       " ('British', 'throne', '22', 'The', 'recent'),\n",
       " ('throne', '22', 'The', 'recent', 'news'),\n",
       " ('22', 'The', 'recent', 'news', 'may'),\n",
       " ('The', 'recent', 'news', 'may', 'have'),\n",
       " ('recent', 'news', 'may', 'have', 'you'),\n",
       " ('news', 'may', 'have', 'you', 'worried'),\n",
       " ('may', 'have', 'you', 'worried', 'about'),\n",
       " ('have', 'you', 'worried', 'about', 'cat'),\n",
       " ('you', 'worried', 'about', 'cat', '23'),\n",
       " ('worried', 'about', 'cat', '23', 'Medical'),\n",
       " ('about', 'cat', '23', 'Medical', 'regulators'),\n",
       " ('cat', '23', 'Medical', 'regulators', 'in'),\n",
       " ('23', 'Medical', 'regulators', 'in', 'Canada'),\n",
       " ('Medical', 'regulators', 'in', 'Canada', 'suspect'),\n",
       " ('regulators', 'in', 'Canada', 'suspect', 'some'),\n",
       " ('in', 'Canada', 'suspect', 'some', 'doct'),\n",
       " ('Canada', 'suspect', 'some', 'doct', '24'),\n",
       " ('suspect', 'some', 'doct', '24', 'Life'),\n",
       " ('some', 'doct', '24', 'Life', 'has'),\n",
       " ('doct', '24', 'Life', 'has', 'changed'),\n",
       " ('24', 'Life', 'has', 'changed', 'on'),\n",
       " ('Life', 'has', 'changed', 'on', 'Selkirk'),\n",
       " ('has', 'changed', 'on', 'Selkirk', 'Avenue'),\n",
       " ('changed', 'on', 'Selkirk', 'Avenue', 'Social'),\n",
       " ('on', 'Selkirk', 'Avenue', 'Social', 'assi'),\n",
       " ('Selkirk', 'Avenue', 'Social', 'assi', '25'),\n",
       " ('Avenue', 'Social', 'assi', '25', 'The'),\n",
       " ('Social', 'assi', '25', 'The', 'black'),\n",
       " ('assi', '25', 'The', 'black', 'swan'),\n",
       " ('25', 'The', 'black', 'swan', 'has'),\n",
       " ('The', 'black', 'swan', 'has', 'landed'),\n",
       " ('black', 'swan', 'has', 'landed', 'The'),\n",
       " ('swan', 'has', 'landed', 'The', 'novel'),\n",
       " ('has', 'landed', 'The', 'novel', 'coronavir'),\n",
       " ('landed', 'The', 'novel', 'coronavir', '26'),\n",
       " ('The', 'novel', 'coronavir', '26', 'Jackson'),\n",
       " ('novel', 'coronavir', '26', 'Jackson', 'Browne'),\n",
       " ('coronavir', '26', 'Jackson', 'Browne', 'has'),\n",
       " ('26', 'Jackson', 'Browne', 'has', 'tested'),\n",
       " ('Jackson', 'Browne', 'has', 'tested', 'positive'),\n",
       " ('Browne', 'has', 'tested', 'positive', 'for'),\n",
       " ('has', 'tested', 'positive', 'for', 'coronav'),\n",
       " ('tested', 'positive', 'for', 'coronav', '27'),\n",
       " ('positive', 'for', 'coronav', '27', 'From'),\n",
       " ('for', 'coronav', '27', 'From', 'shuttered'),\n",
       " ('coronav', '27', 'From', 'shuttered', 'businesses'),\n",
       " ('27', 'From', 'shuttered', 'businesses', 'and'),\n",
       " ('From', 'shuttered', 'businesses', 'and', 'empty'),\n",
       " ('shuttered', 'businesses', 'and', 'empty', 'offices'),\n",
       " ('businesses', 'and', 'empty', 'offices', 'to'),\n",
       " ('and', 'empty', 'offices', 'to', '28'),\n",
       " ('empty', 'offices', 'to', '28', 'For'),\n",
       " ('offices', 'to', '28', 'For', 'the'),\n",
       " ('to', '28', 'For', 'the', 'numerous'),\n",
       " ('28', 'For', 'the', 'numerous', 'expats'),\n",
       " ('For', 'the', 'numerous', 'expats', 'and'),\n",
       " ('the', 'numerous', 'expats', 'and', 'foreign'),\n",
       " ('numerous', 'expats', 'and', 'foreign', 'workers'),\n",
       " ('expats', 'and', 'foreign', 'workers', 'th'),\n",
       " ('and', 'foreign', 'workers', 'th', '29'),\n",
       " ('foreign', 'workers', 'th', '29', 'New'),\n",
       " ('workers', 'th', '29', 'New', 'York'),\n",
       " ('th', '29', 'New', 'York', 'which'),\n",
       " ('29', 'New', 'York', 'which', 'is'),\n",
       " ('New', 'York', 'which', 'is', 'experiencing'),\n",
       " ('York', 'which', 'is', 'experiencing', 'more'),\n",
       " ('which', 'is', 'experiencing', 'more', 'coronaviru'),\n",
       " ('is', 'experiencing', 'more', 'coronaviru', '30'),\n",
       " ('experiencing', 'more', 'coronaviru', '30', 'When'),\n",
       " ('more', 'coronaviru', '30', 'When', 'Sunwing'),\n",
       " ('coronaviru', '30', 'When', 'Sunwing', 'pilot'),\n",
       " ('30', 'When', 'Sunwing', 'pilot', 'Derek'),\n",
       " ('When', 'Sunwing', 'pilot', 'Derek', 'Butcher'),\n",
       " ('Sunwing', 'pilot', 'Derek', 'Butcher', 'recovers'),\n",
       " ('pilot', 'Derek', 'Butcher', 'recovers', 'from'),\n",
       " ('Derek', 'Butcher', 'recovers', 'from', '31'),\n",
       " ('Butcher', 'recovers', 'from', '31', 'The'),\n",
       " ('recovers', 'from', '31', 'The', 'federal'),\n",
       " ('from', '31', 'The', 'federal', 'government'),\n",
       " ('31', 'The', 'federal', 'government', 'is'),\n",
       " ('The', 'federal', 'government', 'is', 'shutting'),\n",
       " ('federal', 'government', 'is', 'shutting', 'down'),\n",
       " ('government', 'is', 'shutting', 'down', 'the'),\n",
       " ('is', 'shutting', 'down', 'the', 'ne'),\n",
       " ('shutting', 'down', 'the', 'ne', '32'),\n",
       " ('down', 'the', 'ne', '32', 'The'),\n",
       " ('the', 'ne', '32', 'The', 'plan'),\n",
       " ('ne', '32', 'The', 'plan', 'for'),\n",
       " ('32', 'The', 'plan', 'for', 'an'),\n",
       " ('The', 'plan', 'for', 'an', 'ambitious'),\n",
       " ('plan', 'for', 'an', 'ambitious', 'reforestation'),\n",
       " ('for', 'an', 'ambitious', 'reforestation', 'season'),\n",
       " ('an', 'ambitious', 'reforestation', 'season', '33'),\n",
       " ('ambitious', 'reforestation', 'season', '33', 'Chinese'),\n",
       " ('reforestation', 'season', '33', 'Chinese', 'authorities'),\n",
       " ('season', '33', 'Chinese', 'authorities', 'said'),\n",
       " ('33', 'Chinese', 'authorities', 'said', 'Tuesday'),\n",
       " ('Chinese', 'authorities', 'said', 'Tuesday', 'they'),\n",
       " ('authorities', 'said', 'Tuesday', 'they', 'will'),\n",
       " ('said', 'Tuesday', 'they', 'will', 'end'),\n",
       " ('Tuesday', 'they', 'will', 'end', '34'),\n",
       " ('they', 'will', 'end', '34', 'The'),\n",
       " ('will', 'end', '34', 'The', 'latest'),\n",
       " ('end', '34', 'The', 'latest', 'House'),\n",
       " ('34', 'The', 'latest', 'House', 'of'),\n",
       " ('The', 'latest', 'House', 'of', 'Commons'),\n",
       " ('latest', 'House', 'of', 'Commons', 'suspends'),\n",
       " ('House', 'of', 'Commons', 'suspends', 'proceedi'),\n",
       " ('of', 'Commons', 'suspends', 'proceedi', '35'),\n",
       " ('Commons', 'suspends', 'proceedi', '35', 'One'),\n",
       " ('suspends', 'proceedi', '35', 'One', 'of'),\n",
       " ('proceedi', '35', 'One', 'of', 'the'),\n",
       " ('35', 'One', 'of', 'the', 'most'),\n",
       " ('One', 'of', 'the', 'most', 'persistent'),\n",
       " ('of', 'the', 'most', 'persistent', 'and'),\n",
       " ('the', 'most', 'persistent', 'and', 'widespread'),\n",
       " ('most', 'persistent', 'and', 'widespread', 'piec'),\n",
       " ('persistent', 'and', 'widespread', 'piec', '36'),\n",
       " ('and', 'widespread', 'piec', '36', 'Kirstin'),\n",
       " ('widespread', 'piec', '36', 'Kirstin', 'Knight'),\n",
       " ('piec', '36', 'Kirstin', 'Knight', 'is'),\n",
       " ('36', 'Kirstin', 'Knight', 'is', 'still'),\n",
       " ('Kirstin', 'Knight', 'is', 'still', 'apprehensive'),\n",
       " ('Knight', 'is', 'still', 'apprehensive', 'at'),\n",
       " ('is', 'still', 'apprehensive', 'at', 'the'),\n",
       " ('still', 'apprehensive', 'at', 'the', 'th'),\n",
       " ('apprehensive', 'at', 'the', 'th', '37'),\n",
       " ('at', 'the', 'th', '37', 'The'),\n",
       " ('the', 'th', '37', 'The', 'White'),\n",
       " ('th', '37', 'The', 'White', 'House'),\n",
       " ('37', 'The', 'White', 'House', 'and'),\n",
       " ('The', 'White', 'House', 'and', 'Senate'),\n",
       " ('White', 'House', 'and', 'Senate', 'leaders'),\n",
       " ('House', 'and', 'Senate', 'leaders', 'of'),\n",
       " ('and', 'Senate', 'leaders', 'of', 'both'),\n",
       " ('Senate', 'leaders', 'of', 'both', 'par'),\n",
       " ('leaders', 'of', 'both', 'par', '38'),\n",
       " ('of', 'both', 'par', '38', 'House'),\n",
       " ('both', 'par', '38', 'House', 'of'),\n",
       " ('par', '38', 'House', 'of', 'Commons'),\n",
       " ('38', 'House', 'of', 'Commons', 'suspended'),\n",
       " ('House', 'of', 'Commons', 'suspended', 'amid'),\n",
       " ('of', 'Commons', 'suspended', 'amid', 'COVID19'),\n",
       " ('Commons', 'suspended', 'amid', 'COVID19', 'ai'),\n",
       " ('suspended', 'amid', 'COVID19', 'ai', '39'),\n",
       " ('amid', 'COVID19', 'ai', '39', 'Chef'),\n",
       " ('COVID19', 'ai', '39', 'Chef', 'Floyd'),\n",
       " ('ai', '39', 'Chef', 'Floyd', 'Cardoz'),\n",
       " ('39', 'Chef', 'Floyd', 'Cardoz', 'who'),\n",
       " ('Chef', 'Floyd', 'Cardoz', 'who', 'competed'),\n",
       " ('Floyd', 'Cardoz', 'who', 'competed', 'on'),\n",
       " ('Cardoz', 'who', 'competed', 'on', 'Top'),\n",
       " ('who', 'competed', 'on', 'Top', 'Chef'),\n",
       " ('competed', 'on', 'Top', 'Chef', 'won'),\n",
       " ('on', 'Top', 'Chef', 'won', '40'),\n",
       " ('Top', 'Chef', 'won', '40', 'BCs'),\n",
       " ('Chef', 'won', '40', 'BCs', 'Ministry'),\n",
       " ('won', '40', 'BCs', 'Ministry', 'of'),\n",
       " ('40', 'BCs', 'Ministry', 'of', 'Health'),\n",
       " ('BCs', 'Ministry', 'of', 'Health', 'has'),\n",
       " ('Ministry', 'of', 'Health', 'has', 'released'),\n",
       " ('of', 'Health', 'has', 'released', 'a'),\n",
       " ('Health', 'has', 'released', 'a', 'new'),\n",
       " ('has', 'released', 'a', 'new', 'app'),\n",
       " ('released', 'a', 'new', 'app', '41'),\n",
       " ('a', 'new', 'app', '41', 'A'),\n",
       " ('new', 'app', '41', 'A', 'smallbatch'),\n",
       " ('app', '41', 'A', 'smallbatch', 'distillery'),\n",
       " ('41', 'A', 'smallbatch', 'distillery', 'in'),\n",
       " ('A', 'smallbatch', 'distillery', 'in', 'Prince'),\n",
       " ('smallbatch', 'distillery', 'in', 'Prince', 'Edward'),\n",
       " ('distillery', 'in', 'Prince', 'Edward', 'Count'),\n",
       " ('in', 'Prince', 'Edward', 'Count', '42'),\n",
       " ('Prince', 'Edward', 'Count', '42', 'A'),\n",
       " ('Edward', 'Count', '42', 'A', 'statement'),\n",
       " ('Count', '42', 'A', 'statement', 'from'),\n",
       " ('42', 'A', 'statement', 'from', 'G7'),\n",
       " ('A', 'statement', 'from', 'G7', 'finance'),\n",
       " ('statement', 'from', 'G7', 'finance', 'ministers'),\n",
       " ('from', 'G7', 'finance', 'ministers', 'and'),\n",
       " ('G7', 'finance', 'ministers', 'and', 'cent'),\n",
       " ('finance', 'ministers', 'and', 'cent', '43'),\n",
       " ('ministers', 'and', 'cent', '43', 'Harvey'),\n",
       " ('and', 'cent', '43', 'Harvey', 'Weinstein'),\n",
       " ('cent', '43', 'Harvey', 'Weinstein', 'tested'),\n",
       " ('43', 'Harvey', 'Weinstein', 'tested', 'positive'),\n",
       " ('Harvey', 'Weinstein', 'tested', 'positive', 'for'),\n",
       " ('Weinstein', 'tested', 'positive', 'for', 'the'),\n",
       " ('tested', 'positive', 'for', 'the', 'coron'),\n",
       " ('positive', 'for', 'the', 'coron', '44'),\n",
       " ('for', 'the', 'coron', '44', 'Democrats'),\n",
       " ('the', 'coron', '44', 'Democrats', 'and'),\n",
       " ('coron', '44', 'Democrats', 'and', 'Republicans'),\n",
       " ('44', 'Democrats', 'and', 'Republicans', 'said'),\n",
       " ('Democrats', 'and', 'Republicans', 'said', 'Tuesday'),\n",
       " ('and', 'Republicans', 'said', 'Tuesday', 'they'),\n",
       " ('Republicans', 'said', 'Tuesday', 'they', 'we'),\n",
       " ('said', 'Tuesday', 'they', 'we', '45'),\n",
       " ('Tuesday', 'they', 'we', '45', 'India'),\n",
       " ('they', 'we', '45', 'India', 'will'),\n",
       " ('we', '45', 'India', 'will', 'begin'),\n",
       " ('45', 'India', 'will', 'begin', 'the'),\n",
       " ('India', 'will', 'begin', 'the', 'worlds'),\n",
       " ('will', 'begin', 'the', 'worlds', 'largest'),\n",
       " ('begin', 'the', 'worlds', 'largest', 'lockdown'),\n",
       " ('the', 'worlds', 'largest', 'lockdown', 'o'),\n",
       " ('worlds', 'largest', 'lockdown', 'o', '46'),\n",
       " ('largest', 'lockdown', 'o', '46', 'A'),\n",
       " ('lockdown', 'o', '46', 'A', 'Phoenixarea'),\n",
       " ('o', '46', 'A', 'Phoenixarea', 'man'),\n",
       " ('46', 'A', 'Phoenixarea', 'man', 'has'),\n",
       " ('A', 'Phoenixarea', 'man', 'has', 'died'),\n",
       " ('Phoenixarea', 'man', 'has', 'died', 'and'),\n",
       " ('man', 'has', 'died', 'and', 'his'),\n",
       " ('has', 'died', 'and', 'his', 'wife'),\n",
       " ('died', 'and', 'his', 'wife', 'was'),\n",
       " ('and', 'his', 'wife', 'was', 'in'),\n",
       " ('his', 'wife', 'was', 'in', '47'),\n",
       " ('wife', 'was', 'in', '47', 'Main'),\n",
       " ('was', 'in', '47', 'Main', 'Street'),\n",
       " ('in', '47', 'Main', 'Street', 'Project'),\n",
       " ('47', 'Main', 'Street', 'Project', 'is'),\n",
       " ('Main', 'Street', 'Project', 'is', 'moving'),\n",
       " ('Street', 'Project', 'is', 'moving', 'fast'),\n",
       " ('Project', 'is', 'moving', 'fast', 'to'),\n",
       " ('is', 'moving', 'fast', 'to', 'create'),\n",
       " ('moving', 'fast', 'to', 'create', 's'),\n",
       " ('fast', 'to', 'create', 's', '48'),\n",
       " ('to', 'create', 's', '48', 'THE'),\n",
       " ('create', 's', '48', 'THE', 'LATEST'),\n",
       " ('s', '48', 'THE', 'LATEST', 'Go'),\n",
       " ('48', 'THE', 'LATEST', 'Go', 'home'),\n",
       " ('THE', 'LATEST', 'Go', 'home', 'and'),\n",
       " ('LATEST', 'Go', 'home', 'and', 'stay'),\n",
       " ('Go', 'home', 'and', 'stay', 'home'),\n",
       " ('home', 'and', 'stay', 'home', 'Trudeau'),\n",
       " ('and', 'stay', 'home', 'Trudeau', 'tell'),\n",
       " ('stay', 'home', 'Trudeau', 'tell', '49'),\n",
       " ('home', 'Trudeau', 'tell', '49', 'From'),\n",
       " ('Trudeau', 'tell', '49', 'From', 'trumpetplaying'),\n",
       " ('tell', '49', 'From', 'trumpetplaying', 'for'),\n",
       " ('49', 'From', 'trumpetplaying', 'for', 'dad'),\n",
       " ('From', 'trumpetplaying', 'for', 'dad', 'to'),\n",
       " ('trumpetplaying', 'for', 'dad', 'to', 'a'),\n",
       " ('for', 'dad', 'to', 'a', 'community'),\n",
       " ('dad', 'to', 'a', 'community', 'dan'),\n",
       " ('to', 'a', 'community', 'dan', '50'),\n",
       " ('a', 'community', 'dan', '50', 'Travellers'),\n",
       " ('community', 'dan', '50', 'Travellers', 'coming'),\n",
       " ('dan', '50', 'Travellers', 'coming', 'through'),\n",
       " ('50', 'Travellers', 'coming', 'through', 'the'),\n",
       " ('Travellers', 'coming', 'through', 'the', 'Calgary'),\n",
       " ('coming', 'through', 'the', 'Calgary', 'Internat'),\n",
       " ('through', 'the', 'Calgary', 'Internat', '51'),\n",
       " ('the', 'Calgary', 'Internat', '51', 'Two'),\n",
       " ('Calgary', 'Internat', '51', 'Two', 'researchers'),\n",
       " ('Internat', '51', 'Two', 'researchers', 'from'),\n",
       " ('51', 'Two', 'researchers', 'from', 'the'),\n",
       " ('Two', 'researchers', 'from', 'the', 'University'),\n",
       " ('researchers', 'from', 'the', 'University', 'of'),\n",
       " ('from', 'the', 'University', 'of', 'British'),\n",
       " ('the', 'University', 'of', 'British', '52'),\n",
       " ('University', 'of', 'British', '52', 'Spanish'),\n",
       " ('of', 'British', '52', 'Spanish', 'army'),\n",
       " ('British', '52', 'Spanish', 'army', 'troops'),\n",
       " ('52', 'Spanish', 'army', 'troops', 'disinfecting'),\n",
       " ('Spanish', 'army', 'troops', 'disinfecting', 'nursing'),\n",
       " ('army', 'troops', 'disinfecting', 'nursing', 'homes'),\n",
       " ('troops', 'disinfecting', 'nursing', 'homes', '53'),\n",
       " ('disinfecting', 'nursing', 'homes', '53', 'Top'),\n",
       " ('nursing', 'homes', '53', 'Top', 'congressional'),\n",
       " ('homes', '53', 'Top', 'congressional', 'and'),\n",
       " ('53', 'Top', 'congressional', 'and', 'White'),\n",
       " ('Top', 'congressional', 'and', 'White', 'House'),\n",
       " ('congressional', 'and', 'White', 'House', 'officials'),\n",
       " ('and', 'White', 'House', 'officials', 'em'),\n",
       " ('White', 'House', 'officials', 'em', '54'),\n",
       " ('House', 'officials', 'em', '54', 'Interior'),\n",
       " ('officials', 'em', '54', 'Interior', 'Health'),\n",
       " ('em', '54', 'Interior', 'Health', 'officials'),\n",
       " ('54', 'Interior', 'Health', 'officials', 'are'),\n",
       " ('Interior', 'Health', 'officials', 'are', 'asking'),\n",
       " ('Health', 'officials', 'are', 'asking', 'people'),\n",
       " ('officials', 'are', 'asking', 'people', 'wh'),\n",
       " ('are', 'asking', 'people', 'wh', '55'),\n",
       " ('asking', 'people', 'wh', '55', 'The'),\n",
       " ('people', 'wh', '55', 'The', 'latest'),\n",
       " ('wh', '55', 'The', 'latest', 'Yukon'),\n",
       " ('55', 'The', 'latest', 'Yukon', 'reports'),\n",
       " ('The', 'latest', 'Yukon', 'reports', 'first'),\n",
       " ('latest', 'Yukon', 'reports', 'first', '2'),\n",
       " ('Yukon', 'reports', 'first', '2', 'confirmed'),\n",
       " ('reports', 'first', '2', 'confirmed', 'ca'),\n",
       " ('first', '2', 'confirmed', 'ca', '56'),\n",
       " ('2', 'confirmed', 'ca', '56', 'Stock'),\n",
       " ('confirmed', 'ca', '56', 'Stock', 'markets'),\n",
       " ('ca', '56', 'Stock', 'markets', 'in'),\n",
       " ('56', 'Stock', 'markets', 'in', 'New'),\n",
       " ('Stock', 'markets', 'in', 'New', 'York'),\n",
       " ('markets', 'in', 'New', 'York', 'and'),\n",
       " ('in', 'New', 'York', 'and', 'Toronto'),\n",
       " ('New', 'York', 'and', 'Toronto', 'jumped'),\n",
       " ('York', 'and', 'Toronto', 'jumped', 's'),\n",
       " ('and', 'Toronto', 'jumped', 's', '57'),\n",
       " ('Toronto', 'jumped', 's', '57', 'Fiat'),\n",
       " ('jumped', 's', '57', 'Fiat', 'Chrysler'),\n",
       " ('s', '57', 'Fiat', 'Chrysler', 'Automobiles'),\n",
       " ('57', 'Fiat', 'Chrysler', 'Automobiles', 'FCA'),\n",
       " ('Fiat', 'Chrysler', 'Automobiles', 'FCA', 'announced'),\n",
       " ('Chrysler', 'Automobiles', 'FCA', 'announced', 'on'),\n",
       " ('Automobiles', 'FCA', 'announced', 'on', 'Mon'),\n",
       " ('FCA', 'announced', 'on', 'Mon', '58'),\n",
       " ('announced', 'on', 'Mon', '58', 'A'),\n",
       " ('on', 'Mon', '58', 'A', 'strong'),\n",
       " ('Mon', '58', 'A', 'strong', 'earthquake'),\n",
       " ('58', 'A', 'strong', 'earthquake', 'in'),\n",
       " ('A', 'strong', 'earthquake', 'in', 'Croatia'),\n",
       " ('strong', 'earthquake', 'in', 'Croatia', 'on'),\n",
       " ('earthquake', 'in', 'Croatia', 'on', 'Sunday'),\n",
       " ('in', 'Croatia', 'on', 'Sunday', 'cause'),\n",
       " ('Croatia', 'on', 'Sunday', 'cause', '59'),\n",
       " ('on', 'Sunday', 'cause', '59', 'The'),\n",
       " ('Sunday', 'cause', '59', 'The', 'City'),\n",
       " ('cause', '59', 'The', 'City', 'of'),\n",
       " ('59', 'The', 'City', 'of', 'Edmonton'),\n",
       " ('The', 'City', 'of', 'Edmonton', 'announced'),\n",
       " ('City', 'of', 'Edmonton', 'announced', 'it'),\n",
       " ('of', 'Edmonton', 'announced', 'it', 'will'),\n",
       " ('Edmonton', 'announced', 'it', 'will', 'close'),\n",
       " ('announced', 'it', 'will', 'close', 'o'),\n",
       " ('it', 'will', 'close', 'o', '60'),\n",
       " ('will', 'close', 'o', '60', 'Michigan'),\n",
       " ('close', 'o', '60', 'Michigan', 'Gov'),\n",
       " ('o', '60', 'Michigan', 'Gov', 'Gretchen'),\n",
       " ('60', 'Michigan', 'Gov', 'Gretchen', 'Whitmer'),\n",
       " ('Michigan', 'Gov', 'Gretchen', 'Whitmer', 'has'),\n",
       " ('Gov', 'Gretchen', 'Whitmer', 'has', 'issued'),\n",
       " ('Gretchen', 'Whitmer', 'has', 'issued', 'a'),\n",
       " ('Whitmer', 'has', 'issued', 'a', 'sta'),\n",
       " ('has', 'issued', 'a', 'sta', '61'),\n",
       " ('issued', 'a', 'sta', '61', 'Edoardo'),\n",
       " ('a', 'sta', '61', 'Edoardo', 'Spinosa'),\n",
       " ('sta', '61', 'Edoardo', 'Spinosa', 'has'),\n",
       " ('61', 'Edoardo', 'Spinosa', 'has', 'been'),\n",
       " ('Edoardo', 'Spinosa', 'has', 'been', 'sent'),\n",
       " ('Spinosa', 'has', 'been', 'sent', 'home'),\n",
       " ('has', 'been', 'sent', 'home', 'to'),\n",
       " ('been', 'sent', 'home', 'to', 'Milan'),\n",
       " ('sent', 'home', 'to', 'Milan', 'It'),\n",
       " ('home', 'to', 'Milan', 'It', '62'),\n",
       " ('to', 'Milan', 'It', '62', 'The'),\n",
       " ('Milan', 'It', '62', 'The', 'provincial'),\n",
       " ('It', '62', 'The', 'provincial', 'government'),\n",
       " ('62', 'The', 'provincial', 'government', 'announced'),\n",
       " ('The', 'provincial', 'government', 'announced', '15'),\n",
       " ('provincial', 'government', 'announced', '15', 'new'),\n",
       " ('government', 'announced', '15', 'new', 'pre'),\n",
       " ('announced', '15', 'new', 'pre', '63'),\n",
       " ('15', 'new', 'pre', '63', 'Ask'),\n",
       " ('new', 'pre', '63', 'Ask', 'Syrian'),\n",
       " ('pre', '63', 'Ask', 'Syrian', 'aid'),\n",
       " ('63', 'Ask', 'Syrian', 'aid', 'worker'),\n",
       " ('Ask', 'Syrian', 'aid', 'worker', 'Osama'),\n",
       " ('Syrian', 'aid', 'worker', 'Osama', 'alHussein'),\n",
       " ('aid', 'worker', 'Osama', 'alHussein', 'how'),\n",
       " ('worker', 'Osama', 'alHussein', 'how', 'hes'),\n",
       " ('Osama', 'alHussein', 'how', 'hes', '64'),\n",
       " ('alHussein', 'how', 'hes', '64', 'The'),\n",
       " ('how', 'hes', '64', 'The', 'possibility'),\n",
       " ('hes', '64', 'The', 'possibility', 'of'),\n",
       " ('64', 'The', 'possibility', 'of', 'having'),\n",
       " ('The', 'possibility', 'of', 'having', 'COVID19'),\n",
       " ('possibility', 'of', 'having', 'COVID19', 'started'),\n",
       " ('of', 'having', 'COVID19', 'started', 'to'),\n",
       " ('having', 'COVID19', 'started', 'to', 'b'),\n",
       " ('COVID19', 'started', 'to', 'b', '65'),\n",
       " ('started', 'to', 'b', '65', 'The'),\n",
       " ('to', 'b', '65', 'The', 'coronavirus'),\n",
       " ('b', '65', 'The', 'coronavirus', 'pandemic'),\n",
       " ('65', 'The', 'coronavirus', 'pandemic', 'will'),\n",
       " ('The', 'coronavirus', 'pandemic', 'will', 'cause'),\n",
       " ('coronavirus', 'pandemic', 'will', 'cause', 'a'),\n",
       " ('pandemic', 'will', 'cause', 'a', 'global'),\n",
       " ('will', 'cause', 'a', 'global', 'r'),\n",
       " ('cause', 'a', 'global', 'r', '66'),\n",
       " ('a', 'global', 'r', '66', 'British'),\n",
       " ('global', 'r', '66', 'British', 'Prime'),\n",
       " ('r', '66', 'British', 'Prime', 'Minister'),\n",
       " ('66', 'British', 'Prime', 'Minister', 'Boris'),\n",
       " ('British', 'Prime', 'Minister', 'Boris', 'Johnson'),\n",
       " ('Prime', 'Minister', 'Boris', 'Johnson', 'on'),\n",
       " ('Minister', 'Boris', 'Johnson', 'on', 'Monday'),\n",
       " ('Boris', 'Johnson', 'on', 'Monday', '67'),\n",
       " ('Johnson', 'on', 'Monday', '67', 'As'),\n",
       " ('on', 'Monday', '67', 'As', 'the'),\n",
       " ('Monday', '67', 'As', 'the', 'doors'),\n",
       " ('67', 'As', 'the', 'doors', 'of'),\n",
       " ('As', 'the', 'doors', 'of', 'planes'),\n",
       " ('the', 'doors', 'of', 'planes', 'landing'),\n",
       " ('doors', 'of', 'planes', 'landing', 'at'),\n",
       " ('of', 'planes', 'landing', 'at', 'Beijings'),\n",
       " ('planes', 'landing', 'at', 'Beijings', 'Cap'),\n",
       " ('landing', 'at', 'Beijings', 'Cap', '68'),\n",
       " ('at', 'Beijings', 'Cap', '68', 'The'),\n",
       " ('Beijings', 'Cap', '68', 'The', 'greatness'),\n",
       " ('Cap', '68', 'The', 'greatness', 'of'),\n",
       " ('68', 'The', 'greatness', 'of', 'the'),\n",
       " ('The', 'greatness', 'of', 'the', 'American'),\n",
       " ('greatness', 'of', 'the', 'American', 'character'),\n",
       " ('of', 'the', 'American', 'character', 'is'),\n",
       " ('the', 'American', 'character', 'is', 'shi'),\n",
       " ('American', 'character', 'is', 'shi', '69'),\n",
       " ('character', 'is', 'shi', '69', 'With'),\n",
       " ('is', 'shi', '69', 'With', 'live'),\n",
       " ('shi', '69', 'With', 'live', 'events'),\n",
       " ('69', 'With', 'live', 'events', 'being'),\n",
       " ('With', 'live', 'events', 'being', 'cancelled'),\n",
       " ('live', 'events', 'being', 'cancelled', 'due'),\n",
       " ('events', 'being', 'cancelled', 'due', 'to'),\n",
       " ('being', 'cancelled', 'due', 'to', 'concer'),\n",
       " ('cancelled', 'due', 'to', 'concer', '70'),\n",
       " ('due', 'to', 'concer', '70', 'The'),\n",
       " ('to', 'concer', '70', 'The', 'WindsorEssex'),\n",
       " ('concer', '70', 'The', 'WindsorEssex', 'County'),\n",
       " ('70', 'The', 'WindsorEssex', 'County', 'Health'),\n",
       " ('The', 'WindsorEssex', 'County', 'Health', 'Unit'),\n",
       " ('WindsorEssex', 'County', 'Health', 'Unit', 'confirmed'),\n",
       " ('County', 'Health', 'Unit', 'confirmed', '71'),\n",
       " ('Health', 'Unit', 'confirmed', '71', 'London'),\n",
       " ('Unit', 'confirmed', '71', 'London', 'area'),\n",
       " ('confirmed', '71', 'London', 'area', 'health'),\n",
       " ('71', 'London', 'area', 'health', 'professionals'),\n",
       " ('London', 'area', 'health', 'professionals', 'are'),\n",
       " ('area', 'health', 'professionals', 'are', 'the'),\n",
       " ('health', 'professionals', 'are', 'the', 'first'),\n",
       " ('professionals', 'are', 'the', 'first', '72'),\n",
       " ('are', 'the', 'first', '72', 'In'),\n",
       " ('the', 'first', '72', 'In', 'these'),\n",
       " ('first', '72', 'In', 'these', 'days'),\n",
       " ('72', 'In', 'these', 'days', 'of'),\n",
       " ('In', 'these', 'days', 'of', 'physical'),\n",
       " ('these', 'days', 'of', 'physical', 'distancing'),\n",
       " ('days', 'of', 'physical', 'distancing', 'grocery'),\n",
       " ('of', 'physical', 'distancing', 'grocery', 's'),\n",
       " ('physical', 'distancing', 'grocery', 's', '73'),\n",
       " ('distancing', 'grocery', 's', '73', 'As'),\n",
       " ('grocery', 's', '73', 'As', 'the'),\n",
       " ('s', '73', 'As', 'the', 'coronavirus'),\n",
       " ('73', 'As', 'the', 'coronavirus', 'infects'),\n",
       " ('As', 'the', 'coronavirus', 'infects', 'more'),\n",
       " ('the', 'coronavirus', 'infects', 'more', 'people'),\n",
       " ('coronavirus', 'infects', 'more', 'people', 'around'),\n",
       " ('infects', 'more', 'people', 'around', '74'),\n",
       " ('more', 'people', 'around', '74', 'Nine'),\n",
       " ('people', 'around', '74', 'Nine', 'workers'),\n",
       " ('around', '74', 'Nine', 'workers', 'will'),\n",
       " ('74', 'Nine', 'workers', 'will', 'stay'),\n",
       " ('Nine', 'workers', 'will', 'stay', 'indefinitely'),\n",
       " ('workers', 'will', 'stay', 'indefinitely', 'at'),\n",
       " ('will', 'stay', 'indefinitely', 'at', 'the'),\n",
       " ('stay', 'indefinitely', 'at', 'the', 'Cit'),\n",
       " ('indefinitely', 'at', 'the', 'Cit', '75'),\n",
       " ('at', 'the', 'Cit', '75', 'A'),\n",
       " ('the', 'Cit', '75', 'A', 'group'),\n",
       " ('Cit', '75', 'A', 'group', 'of'),\n",
       " ('75', 'A', 'group', 'of', 'eastern'),\n",
       " ('A', 'group', 'of', 'eastern', 'Ontario'),\n",
       " ('group', 'of', 'eastern', 'Ontario', 'municipal'),\n",
       " ('of', 'eastern', 'Ontario', 'municipal', 'leaders'),\n",
       " ('eastern', 'Ontario', 'municipal', 'leaders', 'i'),\n",
       " ('Ontario', 'municipal', 'leaders', 'i', '76'),\n",
       " ('municipal', 'leaders', 'i', '76', 'An'),\n",
       " ('leaders', 'i', '76', 'An', 'expanded'),\n",
       " ('i', '76', 'An', 'expanded', 'call'),\n",
       " ('76', 'An', 'expanded', 'call', 'centre'),\n",
       " ('An', 'expanded', 'call', 'centre', 'at'),\n",
       " ('expanded', 'call', 'centre', 'at', 'Global'),\n",
       " ('call', 'centre', 'at', 'Global', 'Affairs'),\n",
       " ('centre', 'at', 'Global', 'Affairs', 'Cana'),\n",
       " ('at', 'Global', 'Affairs', 'Cana', '77'),\n",
       " ('Global', 'Affairs', 'Cana', '77', 'Slaight'),\n",
       " ('Affairs', 'Cana', '77', 'Slaight', 'Music'),\n",
       " ('Cana', '77', 'Slaight', 'Music', 'is'),\n",
       " ('77', 'Slaight', 'Music', 'is', 'doubling'),\n",
       " ('Slaight', 'Music', 'is', 'doubling', 'a'),\n",
       " ('Music', 'is', 'doubling', 'a', 'performing'),\n",
       " ('is', 'doubling', 'a', 'performing', 'arts'),\n",
       " ('doubling', 'a', 'performing', 'arts', 'fu'),\n",
       " ('a', 'performing', 'arts', 'fu', '78'),\n",
       " ('performing', 'arts', 'fu', '78', 'Laurie'),\n",
       " ('arts', 'fu', '78', 'Laurie', 'Pushor'),\n",
       " ('fu', '78', 'Laurie', 'Pushor', 'Saskatchewans'),\n",
       " ('78', 'Laurie', 'Pushor', 'Saskatchewans', 'deputy'),\n",
       " ('Laurie', 'Pushor', 'Saskatchewans', 'deputy', 'minister'),\n",
       " ('Pushor', 'Saskatchewans', 'deputy', 'minister', 'of'),\n",
       " ('Saskatchewans', 'deputy', 'minister', 'of', '79'),\n",
       " ('deputy', 'minister', 'of', '79', 'BC'),\n",
       " ('minister', 'of', '79', 'BC', 'is'),\n",
       " ('of', '79', 'BC', 'is', 'ordering'),\n",
       " ('79', 'BC', 'is', 'ordering', 'all'),\n",
       " ('BC', 'is', 'ordering', 'all', 'restaurants'),\n",
       " ('is', 'ordering', 'all', 'restaurants', 'to'),\n",
       " ('ordering', 'all', 'restaurants', 'to', 'stop'),\n",
       " ('all', 'restaurants', 'to', 'stop', 'providi'),\n",
       " ('restaurants', 'to', 'stop', 'providi', '80'),\n",
       " ('to', 'stop', 'providi', '80', 'Whats'),\n",
       " ('stop', 'providi', '80', 'Whats', 'COVID19'),\n",
       " ('providi', '80', 'Whats', 'COVID19', 'Whats'),\n",
       " ('80', 'Whats', 'COVID19', 'Whats', 'isolation'),\n",
       " ('Whats', 'COVID19', 'Whats', 'isolation', 'Is'),\n",
       " ('COVID19', 'Whats', 'isolation', 'Is', 'there'),\n",
       " ('Whats', 'isolation', 'Is', 'there', 'a'),\n",
       " ('isolation', 'Is', 'there', 'a', 'cure'),\n",
       " ('Is', 'there', 'a', 'cure', '81'),\n",
       " ('there', 'a', 'cure', '81', 'A'),\n",
       " ('a', 'cure', '81', 'A', 'tentative'),\n",
       " ('cure', '81', 'A', 'tentative', 'agreement'),\n",
       " ('81', 'A', 'tentative', 'agreement', 'has'),\n",
       " ('A', 'tentative', 'agreement', 'has', 'been'),\n",
       " ('tentative', 'agreement', 'has', 'been', 'reached'),\n",
       " ('agreement', 'has', 'been', 'reached', 'with'),\n",
       " ('has', 'been', 'reached', 'with', 'Br'),\n",
       " ('been', 'reached', 'with', 'Br', '82'),\n",
       " ('reached', 'with', 'Br', '82', 'A'),\n",
       " ('with', 'Br', '82', 'A', 'survey'),\n",
       " ('Br', '82', 'A', 'survey', 'conducted'),\n",
       " ('82', 'A', 'survey', 'conducted', 'by'),\n",
       " ('A', 'survey', 'conducted', 'by', 'Dene'),\n",
       " ('survey', 'conducted', 'by', 'Dene', 'Nation'),\n",
       " ('conducted', 'by', 'Dene', 'Nation', 'suggests'),\n",
       " ('by', 'Dene', 'Nation', 'suggests', 'tha'),\n",
       " ('Dene', 'Nation', 'suggests', 'tha', '83'),\n",
       " ('Nation', 'suggests', 'tha', '83', 'Alberta'),\n",
       " ('suggests', 'tha', '83', 'Alberta', 'talk'),\n",
       " ('tha', '83', 'Alberta', 'talk', 'radio'),\n",
       " ('83', 'Alberta', 'talk', 'radio', 'host'),\n",
       " ('Alberta', 'talk', 'radio', 'host', 'and'),\n",
       " ('talk', 'radio', 'host', 'and', 'former'),\n",
       " ('radio', 'host', 'and', 'former', 'Wildrose'),\n",
       " ('host', 'and', 'former', 'Wildrose', 'Pa'),\n",
       " ('and', 'former', 'Wildrose', 'Pa', '84'),\n",
       " ('former', 'Wildrose', 'Pa', '84', 'The'),\n",
       " ('Wildrose', 'Pa', '84', 'The', 'Cannes'),\n",
       " ('Pa', '84', 'The', 'Cannes', 'Film'),\n",
       " ('84', 'The', 'Cannes', 'Film', 'Festival'),\n",
       " ('The', 'Cannes', 'Film', 'Festival', 'has'),\n",
       " ('Cannes', 'Film', 'Festival', 'has', 'been'),\n",
       " ('Film', 'Festival', 'has', 'been', 'postponed'),\n",
       " ('Festival', 'has', 'been', 'postponed', 'du'),\n",
       " ('has', 'been', 'postponed', 'du', '85'),\n",
       " ('been', 'postponed', 'du', '85', 'Like'),\n",
       " ('postponed', 'du', '85', 'Like', 'airports'),\n",
       " ('du', '85', 'Like', 'airports', 'around'),\n",
       " ('85', 'Like', 'airports', 'around', 'the'),\n",
       " ('Like', 'airports', 'around', 'the', 'world'),\n",
       " ('airports', 'around', 'the', 'world', 'the'),\n",
       " ('around', 'the', 'world', 'the', 'global'),\n",
       " ('the', 'world', 'the', 'global', 'pand'),\n",
       " ('world', 'the', 'global', 'pand', '86'),\n",
       " ('the', 'global', 'pand', '86', 'The'),\n",
       " ('global', 'pand', '86', 'The', 'latest'),\n",
       " ('pand', '86', 'The', 'latest', 'NWT'),\n",
       " ('86', 'The', 'latest', 'NWT', 'confirms'),\n",
       " ('The', 'latest', 'NWT', 'confirms', '1st'),\n",
       " ('latest', 'NWT', 'confirms', '1st', 'case'),\n",
       " ('NWT', 'confirms', '1st', 'case', 'in'),\n",
       " ('confirms', '1st', 'case', 'in', 'the'),\n",
       " ('1st', 'case', 'in', 'the', 'terri'),\n",
       " ('case', 'in', 'the', 'terri', '87'),\n",
       " ('in', 'the', 'terri', '87', 'Leaders'),\n",
       " ('the', 'terri', '87', 'Leaders', 'of'),\n",
       " ('terri', '87', 'Leaders', 'of', 'the'),\n",
       " ('87', 'Leaders', 'of', 'the', 'worlds'),\n",
       " ('Leaders', 'of', 'the', 'worlds', '20'),\n",
       " ('of', 'the', 'worlds', '20', 'biggest'),\n",
       " ('the', 'worlds', '20', 'biggest', 'economies'),\n",
       " ('worlds', '20', 'biggest', 'economies', 'met'),\n",
       " ('20', 'biggest', 'economies', 'met', '88'),\n",
       " ('biggest', 'economies', 'met', '88', 'A'),\n",
       " ('economies', 'met', '88', 'A', 'man'),\n",
       " ('met', '88', 'A', 'man', 'in'),\n",
       " ('88', 'A', 'man', 'in', 'his'),\n",
       " ('A', 'man', 'in', 'his', '50s'),\n",
       " ('man', 'in', 'his', '50s', 'who'),\n",
       " ('in', 'his', '50s', 'who', 'tested'),\n",
       " ('his', '50s', 'who', 'tested', 'positive'),\n",
       " ('50s', 'who', 'tested', 'positive', 'for'),\n",
       " ('who', 'tested', 'positive', 'for', 'COVID'),\n",
       " ('tested', 'positive', 'for', 'COVID', '89'),\n",
       " ('positive', 'for', 'COVID', '89', 'Confused'),\n",
       " ('for', 'COVID', '89', 'Confused', 'about'),\n",
       " ('COVID', '89', 'Confused', 'about', 'the'),\n",
       " ('89', 'Confused', 'about', 'the', 'language'),\n",
       " ('Confused', 'about', 'the', 'language', 'that'),\n",
       " ('about', 'the', 'language', 'that', 'health'),\n",
       " ('the', 'language', 'that', 'health', 'and'),\n",
       " ('language', 'that', 'health', 'and', 'go'),\n",
       " ('that', 'health', 'and', 'go', '90'),\n",
       " ('health', 'and', 'go', '90', 'Italys'),\n",
       " ('and', 'go', '90', 'Italys', 'death'),\n",
       " ('go', '90', 'Italys', 'death', 'toll'),\n",
       " ('90', 'Italys', 'death', 'toll', 'from'),\n",
       " ('Italys', 'death', 'toll', 'from', 'coronavirus'),\n",
       " ('death', 'toll', 'from', 'coronavirus', 'on'),\n",
       " ('toll', 'from', 'coronavirus', 'on', 'Thursday'),\n",
       " ('from', 'coronavirus', 'on', 'Thursday', '91'),\n",
       " ('coronavirus', 'on', 'Thursday', '91', 'The'),\n",
       " ('on', 'Thursday', '91', 'The', 'coronavirus'),\n",
       " ('Thursday', '91', 'The', 'coronavirus', 'outbreak'),\n",
       " ('91', 'The', 'coronavirus', 'outbreak', 'has'),\n",
       " ('The', 'coronavirus', 'outbreak', 'has', 'resulted'),\n",
       " ('coronavirus', 'outbreak', 'has', 'resulted', 'in'),\n",
       " ('outbreak', 'has', 'resulted', 'in', 'a'),\n",
       " ('has', 'resulted', 'in', 'a', 'del'),\n",
       " ('resulted', 'in', 'a', 'del', '92'),\n",
       " ('in', 'a', 'del', '92', 'BC'),\n",
       " ('a', 'del', '92', 'BC', 'is'),\n",
       " ('del', '92', 'BC', 'is', 'ordering'),\n",
       " ('92', 'BC', 'is', 'ordering', 'all'),\n",
       " ('BC', 'is', 'ordering', 'all', 'restaurants'),\n",
       " ('is', 'ordering', 'all', 'restaurants', 'to'),\n",
       " ('ordering', 'all', 'restaurants', 'to', 'stop'),\n",
       " ('all', 'restaurants', 'to', 'stop', 'providi'),\n",
       " ('restaurants', 'to', 'stop', 'providi', '93'),\n",
       " ('to', 'stop', 'providi', '93', 'Southwest'),\n",
       " ('stop', 'providi', '93', 'Southwest', 'Sounds'),\n",
       " ('providi', '93', 'Southwest', 'Sounds', 'is'),\n",
       " ('93', 'Southwest', 'Sounds', 'is', 'a'),\n",
       " ('Southwest', 'Sounds', 'is', 'a', 'weekly'),\n",
       " ('Sounds', 'is', 'a', 'weekly', 'feature'),\n",
       " ('is', 'a', 'weekly', 'feature', 'that'),\n",
       " ('a', 'weekly', 'feature', 'that', 'prof'),\n",
       " ('weekly', 'feature', 'that', 'prof', '94'),\n",
       " ('feature', 'that', 'prof', '94', 'Twothirds'),\n",
       " ('that', 'prof', '94', 'Twothirds', 'of'),\n",
       " ('prof', '94', 'Twothirds', 'of', 'Canadians'),\n",
       " ('94', 'Twothirds', 'of', 'Canadians', 'think'),\n",
       " ('Twothirds', 'of', 'Canadians', 'think', 'Prime'),\n",
       " ('of', 'Canadians', 'think', 'Prime', 'Minister'),\n",
       " ('Canadians', 'think', 'Prime', 'Minister', 'Ju'),\n",
       " ('think', 'Prime', 'Minister', 'Ju', '95'),\n",
       " ('Prime', 'Minister', 'Ju', '95', 'The'),\n",
       " ('Minister', 'Ju', '95', 'The', 'Alberta'),\n",
       " ('Ju', '95', 'The', 'Alberta', 'government'),\n",
       " ('95', 'The', 'Alberta', 'government', 'has'),\n",
       " ('The', 'Alberta', 'government', 'has', 'fished'),\n",
       " ('Alberta', 'government', 'has', 'fished', '153'),\n",
       " ('government', 'has', 'fished', '153', 'million'),\n",
       " ('has', 'fished', '153', 'million', '96'),\n",
       " ('fished', '153', 'million', '96', 'BC'),\n",
       " ('153', 'million', '96', 'BC', 'is'),\n",
       " ('million', '96', 'BC', 'is', 'ordering'),\n",
       " ('96', 'BC', 'is', 'ordering', 'all'),\n",
       " ('BC', 'is', 'ordering', 'all', 'restaurants'),\n",
       " ('is', 'ordering', 'all', 'restaurants', 'to'),\n",
       " ('ordering', 'all', 'restaurants', 'to', 'stop'),\n",
       " ('all', 'restaurants', 'to', 'stop', 'providi'),\n",
       " ('restaurants', 'to', 'stop', 'providi', '97'),\n",
       " ('to', 'stop', 'providi', '97', 'As'),\n",
       " ('stop', 'providi', '97', 'As', 'if'),\n",
       " ('providi', '97', 'As', 'if', 'there'),\n",
       " ('97', 'As', 'if', 'there', 'wasnt'),\n",
       " ('As', 'if', 'there', 'wasnt', 'enough'),\n",
       " ('if', 'there', 'wasnt', 'enough', 'COVID19'),\n",
       " ('there', 'wasnt', 'enough', 'COVID19', 'chaos'),\n",
       " ('wasnt', 'enough', 'COVID19', 'chaos', 'in'),\n",
       " ('enough', 'COVID19', 'chaos', 'in', 'the'),\n",
       " ('COVID19', 'chaos', 'in', 'the', '98'),\n",
       " ('chaos', 'in', 'the', '98', 'While'),\n",
       " ('in', 'the', '98', 'While', 'many'),\n",
       " ('the', '98', 'While', 'many', 'people'),\n",
       " ('98', 'While', 'many', 'people', 'are'),\n",
       " ('While', 'many', 'people', 'are', 'staying'),\n",
       " ('many', 'people', 'are', 'staying', 'home'),\n",
       " ('people', 'are', 'staying', 'home', 'amid'),\n",
       " ('are', 'staying', 'home', 'amid', 'COVID1'),\n",
       " ('staying', 'home', 'amid', 'COVID1', '99'),\n",
       " ('home', 'amid', 'COVID1', '99', 'The'),\n",
       " ('amid', 'COVID1', '99', 'The', 'latest'),\n",
       " ('COVID1', '99', 'The', 'latest', 'Ottawa'),\n",
       " ('99', 'The', 'latest', 'Ottawa', 'finalizing'),\n",
       " ('The', 'latest', 'Ottawa', 'finalizing', 'plan'),\n",
       " ('latest', 'Ottawa', 'finalizing', 'plan', 'to'),\n",
       " ('Ottawa', 'finalizing', 'plan', 'to', 'boost'),\n",
       " ('finalizing', 'plan', 'to', 'boost', 'pr'),\n",
       " ('plan', 'to', 'boost', 'pr', '100'),\n",
       " ('to', 'boost', 'pr', '100', 'Ford'),\n",
       " ('boost', 'pr', '100', 'Ford', 'General'),\n",
       " ('pr', '100', 'Ford', 'General', 'Motors'),\n",
       " ('100', 'Ford', 'General', 'Motors', 'Fiat'),\n",
       " ('Ford', 'General', 'Motors', 'Fiat', 'Chrysler'),\n",
       " ('General', 'Motors', 'Fiat', 'Chrysler', 'Honda'),\n",
       " ('Motors', 'Fiat', 'Chrysler', 'Honda', 'and'),\n",
       " ('Fiat', 'Chrysler', 'Honda', 'and', 'To'),\n",
       " ('Chrysler', 'Honda', 'and', 'To', '101'),\n",
       " ('Honda', 'and', 'To', '101', 'The'),\n",
       " ('and', 'To', '101', 'The', 'provincial'),\n",
       " ('To', '101', 'The', 'provincial', 'government'),\n",
       " ('101', 'The', 'provincial', 'government', 'says'),\n",
       " ('The', 'provincial', 'government', 'says', 'safe'),\n",
       " ('provincial', 'government', 'says', 'safe', 'prescripti'),\n",
       " ('government', 'says', 'safe', 'prescripti', '102'),\n",
       " ('says', 'safe', 'prescripti', '102', 'Starbucks'),\n",
       " ('safe', 'prescripti', '102', 'Starbucks', 'is'),\n",
       " ('prescripti', '102', 'Starbucks', 'is', 'joining'),\n",
       " ('102', 'Starbucks', 'is', 'joining', 'the'),\n",
       " ('Starbucks', 'is', 'joining', 'the', 'growing'),\n",
       " ('is', 'joining', 'the', 'growing', 'list'),\n",
       " ('joining', 'the', 'growing', 'list', 'of'),\n",
       " ('the', 'growing', 'list', 'of', 'compa'),\n",
       " ('growing', 'list', 'of', 'compa', '103'),\n",
       " ('list', 'of', 'compa', '103', 'COVID19'),\n",
       " ('of', 'compa', '103', 'COVID19', 'anxiety'),\n",
       " ('compa', '103', 'COVID19', 'anxiety', 'is'),\n",
       " ('103', 'COVID19', 'anxiety', 'is', 'real'),\n",
       " ('COVID19', 'anxiety', 'is', 'real', 'for'),\n",
       " ('anxiety', 'is', 'real', 'for', 'many'),\n",
       " ('is', 'real', 'for', 'many', 'people'),\n",
       " ('real', 'for', 'many', 'people', 'but'),\n",
       " ('for', 'many', 'people', 'but', 'it'),\n",
       " ('many', 'people', 'but', 'it', '104'),\n",
       " ('people', 'but', 'it', '104', 'Netflix'),\n",
       " ('but', 'it', '104', 'Netflix', 'said'),\n",
       " ('it', '104', 'Netflix', 'said', 'Friday'),\n",
       " ('104', 'Netflix', 'said', 'Friday', 'it'),\n",
       " ('Netflix', 'said', 'Friday', 'it', 'is'),\n",
       " ('said', 'Friday', 'it', 'is', 'establishing'),\n",
       " ('Friday', 'it', 'is', 'establishing', 'a'),\n",
       " ('it', 'is', 'establishing', 'a', '100'),\n",
       " ('is', 'establishing', 'a', '100', 'm'),\n",
       " ('establishing', 'a', '100', 'm', '105'),\n",
       " ('a', '100', 'm', '105', 'The'),\n",
       " ('100', 'm', '105', 'The', 'Ministry'),\n",
       " ('m', '105', 'The', 'Ministry', 'of'),\n",
       " ('105', 'The', 'Ministry', 'of', 'Health'),\n",
       " ('The', 'Ministry', 'of', 'Health', 'has'),\n",
       " ('Ministry', 'of', 'Health', 'has', 'quietly'),\n",
       " ('of', 'Health', 'has', 'quietly', 'launched'),\n",
       " ('Health', 'has', 'quietly', 'launched', 'a'),\n",
       " ('has', 'quietly', 'launched', 'a', '106'),\n",
       " ('quietly', 'launched', 'a', '106', 'UPDATE'),\n",
       " ('launched', 'a', '106', 'UPDATE', 'On'),\n",
       " ('a', '106', 'UPDATE', 'On', 'March'),\n",
       " ('106', 'UPDATE', 'On', 'March', '12'),\n",
       " ('UPDATE', 'On', 'March', '12', 'Hong'),\n",
       " ('On', 'March', '12', 'Hong', 'Kongs'),\n",
       " ('March', '12', 'Hong', 'Kongs', 'Agriculture'),\n",
       " ('12', 'Hong', 'Kongs', 'Agriculture', 'Fish'),\n",
       " ('Hong', 'Kongs', 'Agriculture', 'Fish', '107'),\n",
       " ('Kongs', 'Agriculture', 'Fish', '107', 'In'),\n",
       " ('Agriculture', 'Fish', '107', 'In', 'the'),\n",
       " ('Fish', '107', 'In', 'the', '25'),\n",
       " ('107', 'In', 'the', '25', 'years'),\n",
       " ('In', 'the', '25', 'years', 'hes'),\n",
       " ('the', '25', 'years', 'hes', 'owned'),\n",
       " ('25', 'years', 'hes', 'owned', 'his'),\n",
       " ('years', 'hes', 'owned', 'his', 'Ontario'),\n",
       " ('hes', 'owned', 'his', 'Ontario', 'gun'),\n",
       " ('owned', 'his', 'Ontario', 'gun', 'shop'),\n",
       " ('his', 'Ontario', 'gun', 'shop', '108'),\n",
       " ('Ontario', 'gun', 'shop', '108', 'Employees'),\n",
       " ('gun', 'shop', '108', 'Employees', 'at'),\n",
       " ('shop', '108', 'Employees', 'at', 'TD'),\n",
       " ('108', 'Employees', 'at', 'TD', 'Bank'),\n",
       " ('Employees', 'at', 'TD', 'Bank', 'say'),\n",
       " ('at', 'TD', 'Bank', 'say', 'hundreds'),\n",
       " ('TD', 'Bank', 'say', 'hundreds', 'of'),\n",
       " ('Bank', 'say', 'hundreds', 'of', 'people'),\n",
       " ('say', 'hundreds', 'of', 'people', 'ar'),\n",
       " ('hundreds', 'of', 'people', 'ar', '109'),\n",
       " ('of', 'people', 'ar', '109', 'Sarah'),\n",
       " ('people', 'ar', '109', 'Sarah', 'Swarks'),\n",
       " ('ar', '109', 'Sarah', 'Swarks', 'wedding'),\n",
       " ('109', 'Sarah', 'Swarks', 'wedding', 'is'),\n",
       " ('Sarah', 'Swarks', 'wedding', 'is', 'not'),\n",
       " ('Swarks', 'wedding', 'is', 'not', 'going'),\n",
       " ('wedding', 'is', 'not', 'going', 'ahead'),\n",
       " ('is', 'not', 'going', 'ahead', 'as'),\n",
       " ('not', 'going', 'ahead', 'as', 'pla'),\n",
       " ('going', 'ahead', 'as', 'pla', '110'),\n",
       " ('ahead', 'as', 'pla', '110', 'Canadas'),\n",
       " ('as', 'pla', '110', 'Canadas', 'hospitals'),\n",
       " ('pla', '110', 'Canadas', 'hospitals', 'and'),\n",
       " ('110', 'Canadas', 'hospitals', 'and', 'health'),\n",
       " ('Canadas', 'hospitals', 'and', 'health', 'officials'),\n",
       " ('hospitals', 'and', 'health', 'officials', 'are'),\n",
       " ('and', 'health', 'officials', 'are', 'loo'),\n",
       " ('health', 'officials', 'are', 'loo', '111'),\n",
       " ('officials', 'are', 'loo', '111', 'Extra'),\n",
       " ('are', 'loo', '111', 'Extra', 'resources'),\n",
       " ('loo', '111', 'Extra', 'resources', 'are'),\n",
       " ('111', 'Extra', 'resources', 'are', 'being'),\n",
       " ('Extra', 'resources', 'are', 'being', 'added'),\n",
       " ('resources', 'are', 'being', 'added', 'to'),\n",
       " ('are', 'being', 'added', 'to', 'the'),\n",
       " ('being', 'added', 'to', 'the', 'Tele–Ca'),\n",
       " ('added', 'to', 'the', 'Tele–Ca', '112'),\n",
       " ('to', 'the', 'Tele–Ca', '112', 'The'),\n",
       " ('the', 'Tele–Ca', '112', 'The', 'Eurovision'),\n",
       " ('Tele–Ca', '112', 'The', 'Eurovision', 'song'),\n",
       " ('112', 'The', 'Eurovision', 'song', 'contest'),\n",
       " ('The', 'Eurovision', 'song', 'contest', 'one'),\n",
       " ('Eurovision', 'song', 'contest', 'one', 'of'),\n",
       " ('song', 'contest', 'one', 'of', 'the'),\n",
       " ('contest', 'one', 'of', 'the', 'worlds'),\n",
       " ('one', 'of', 'the', 'worlds', '113'),\n",
       " ('of', 'the', 'worlds', '113', 'Bans'),\n",
       " ('the', 'worlds', '113', 'Bans', 'on'),\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_gram=ngrams(tokens,5)\n",
    "[x for x in five_gram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. Prediction of all the wrods that will follow the certain word in search. \n",
    "    ** example : \"Government has\" is entered. then it would display the list of words that follow the co \n",
    "\n",
    "* 2. Plotter chart : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install TensorFlow Library Work Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "var = 0\n",
    "def countWords(text):\n",
    "    v = 0\n",
    "    for i in text:\n",
    "        v = v + 1\n",
    "    print(v)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59935"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemmed vectors are taken as input. \n",
    "# Article size: 5 articles are taken.\n",
    "\n",
    "articles = df.body_text_stemmed.tolist()\n",
    "for article in articles[0:5]:\n",
    "    for word in article:\n",
    "        words.append(word)\n",
    "        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pharmaci'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(words) # gives the total number of unique words\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6650"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word2int['pharmaci'])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTF = []\n",
    "\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "# based on the window size, the neighbouring word or context words is considered for the current word.\n",
    "# So if the window size is 2, the surrounding words which are at a distance of two words from the current word is processed.\n",
    "\n",
    "for article in articles[0:5]:\n",
    "    for word_index, word in enumerate(article):\n",
    "        for nb_word in article[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(article)) + 1] : \n",
    "            if nb_word != word:\n",
    "                dataTF.append([word, nb_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['canadian', 'pharmaci'],\n",
       " ['canadian', 'limit'],\n",
       " ['pharmaci', 'canadian'],\n",
       " ['pharmaci', 'limit'],\n",
       " ['pharmaci', 'much']]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTF[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['canadian', 'pharmaci']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5879"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int[\"canadian\"]  # word2int[ data_word[0] ] = word2int[\"canadian\"] = word2int[dataTF[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5523"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int[\"pharmaci\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int['covid19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)     # Initializing the temp array with Zeros till the vocab size. \n",
    "    temp[data_point_index] = 1    # assigning one value to the data point index. \n",
    "    return temp\n",
    "x_train = [] # input word\n",
    "y_train = [] # output word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6650"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_word in dataTF:\n",
    "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n",
    "# convert them to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in order to make tensor flow placeholder run on the machine\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9272, 6650) (9272, 6650)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# meaning 9272 training points, where each point has 1101 dimensions\n",
    "# or 9272 rows and each row has 1101 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 5 # you can choose your own number\n",
    "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM])) #bias\n",
    "hidden_representation = tf.add(tf.matmul(x,W1), b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
    "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is :  13.643272\n",
      "loss is :  13.299753\n",
      "loss is :  13.015816\n",
      "loss is :  12.780971\n",
      "loss is :  12.586647\n",
      "loss is :  12.4258175\n",
      "loss is :  12.292683\n",
      "loss is :  12.182464\n",
      "loss is :  12.091197\n",
      "loss is :  12.015605\n",
      "loss is :  11.952971\n",
      "loss is :  11.901046\n",
      "loss is :  11.857963\n",
      "loss is :  11.822178\n",
      "loss is :  11.792411\n",
      "loss is :  11.767607\n",
      "loss is :  11.746886\n",
      "loss is :  11.729528\n",
      "loss is :  11.71494\n",
      "loss is :  11.702629\n",
      "loss is :  11.692192\n",
      "loss is :  11.683293\n",
      "loss is :  11.675658\n",
      "loss is :  11.669065\n",
      "loss is :  11.663329\n",
      "loss is :  11.658294\n",
      "loss is :  11.653835\n",
      "loss is :  11.649851\n",
      "loss is :  11.646258\n",
      "loss is :  11.642989\n",
      "loss is :  11.639983\n",
      "loss is :  11.637195\n",
      "loss is :  11.634585\n",
      "loss is :  11.632122\n",
      "loss is :  11.629783\n",
      "loss is :  11.6275425\n",
      "loss is :  11.625387\n",
      "loss is :  11.6233015\n",
      "loss is :  11.621271\n",
      "loss is :  11.619291\n",
      "loss is :  11.617351\n",
      "loss is :  11.615442\n",
      "loss is :  11.613567\n",
      "loss is :  11.611709\n",
      "loss is :  11.609874\n",
      "loss is :  11.608054\n",
      "loss is :  11.606253\n",
      "loss is :  11.604461\n",
      "loss is :  11.602684\n",
      "loss is :  11.600912\n",
      "loss is :  11.599152\n",
      "loss is :  11.5974\n",
      "loss is :  11.595649\n",
      "loss is :  11.593912\n",
      "loss is :  11.592176\n",
      "loss is :  11.59045\n",
      "loss is :  11.588726\n",
      "loss is :  11.5870075\n",
      "loss is :  11.585292\n",
      "loss is :  11.583583\n",
      "loss is :  11.581876\n",
      "loss is :  11.580175\n",
      "loss is :  11.578478\n",
      "loss is :  11.576783\n",
      "loss is :  11.575093\n",
      "loss is :  11.573406\n",
      "loss is :  11.571723\n",
      "loss is :  11.570043\n",
      "loss is :  11.56837\n",
      "loss is :  11.566696\n",
      "loss is :  11.565029\n",
      "loss is :  11.563363\n",
      "loss is :  11.561698\n",
      "loss is :  11.56004\n",
      "loss is :  11.558383\n",
      "loss is :  11.55673\n",
      "loss is :  11.55508\n",
      "loss is :  11.553433\n",
      "loss is :  11.55179\n",
      "loss is :  11.550149\n",
      "loss is :  11.548513\n",
      "loss is :  11.546879\n",
      "loss is :  11.545245\n",
      "loss is :  11.543619\n",
      "loss is :  11.541996\n",
      "loss is :  11.54037\n",
      "loss is :  11.538753\n",
      "loss is :  11.537136\n",
      "loss is :  11.535523\n",
      "loss is :  11.533915\n",
      "loss is :  11.532307\n",
      "loss is :  11.530699\n",
      "loss is :  11.529099\n",
      "loss is :  11.527501\n",
      "loss is :  11.525905\n",
      "loss is :  11.524312\n",
      "loss is :  11.522721\n",
      "loss is :  11.521135\n",
      "loss is :  11.519549\n",
      "loss is :  11.517969\n",
      "loss is :  11.516391\n",
      "loss is :  11.5148115\n",
      "loss is :  11.513238\n",
      "loss is :  11.511668\n",
      "loss is :  11.510102\n",
      "loss is :  11.508535\n",
      "loss is :  11.506974\n",
      "loss is :  11.505413\n",
      "loss is :  11.503854\n",
      "loss is :  11.502298\n",
      "loss is :  11.500748\n",
      "loss is :  11.499198\n",
      "loss is :  11.497654\n",
      "loss is :  11.496106\n",
      "loss is :  11.494566\n",
      "loss is :  11.493026\n",
      "loss is :  11.491488\n",
      "loss is :  11.489955\n",
      "loss is :  11.488422\n",
      "loss is :  11.486896\n",
      "loss is :  11.485368\n",
      "loss is :  11.483844\n",
      "loss is :  11.482323\n",
      "loss is :  11.480804\n",
      "loss is :  11.479286\n",
      "loss is :  11.477773\n",
      "loss is :  11.476261\n",
      "loss is :  11.4747505\n",
      "loss is :  11.473244\n",
      "loss is :  11.471738\n",
      "loss is :  11.470236\n",
      "loss is :  11.468739\n",
      "loss is :  11.467238\n",
      "loss is :  11.465744\n",
      "loss is :  11.464251\n",
      "loss is :  11.462759\n",
      "loss is :  11.461271\n",
      "loss is :  11.4597845\n",
      "loss is :  11.458301\n",
      "loss is :  11.456819\n",
      "loss is :  11.455341\n",
      "loss is :  11.453864\n",
      "loss is :  11.452387\n",
      "loss is :  11.450917\n",
      "loss is :  11.449447\n",
      "loss is :  11.447976\n",
      "loss is :  11.446512\n",
      "loss is :  11.445048\n",
      "loss is :  11.443587\n",
      "loss is :  11.442128\n",
      "loss is :  11.440671\n",
      "loss is :  11.439218\n",
      "loss is :  11.437764\n",
      "loss is :  11.436314\n",
      "loss is :  11.434865\n",
      "loss is :  11.433418\n",
      "loss is :  11.431975\n",
      "loss is :  11.430532\n",
      "loss is :  11.4290905\n",
      "loss is :  11.427652\n",
      "loss is :  11.426218\n",
      "loss is :  11.424784\n",
      "loss is :  11.42335\n",
      "loss is :  11.421922\n",
      "loss is :  11.420494\n",
      "loss is :  11.419069\n",
      "loss is :  11.417644\n",
      "loss is :  11.4162245\n",
      "loss is :  11.4148035\n",
      "loss is :  11.4133835\n",
      "loss is :  11.411971\n",
      "loss is :  11.410555\n",
      "loss is :  11.409145\n",
      "loss is :  11.407735\n",
      "loss is :  11.406326\n",
      "loss is :  11.404921\n",
      "loss is :  11.403518\n",
      "loss is :  11.402114\n",
      "loss is :  11.400713\n",
      "loss is :  11.399314\n",
      "loss is :  11.397921\n",
      "loss is :  11.396524\n",
      "loss is :  11.395129\n",
      "loss is :  11.393741\n",
      "loss is :  11.392352\n",
      "loss is :  11.390965\n",
      "loss is :  11.38958\n",
      "loss is :  11.388197\n",
      "loss is :  11.386816\n",
      "loss is :  11.385435\n",
      "loss is :  11.384056\n",
      "loss is :  11.382681\n",
      "loss is :  11.381306\n",
      "loss is :  11.379937\n",
      "loss is :  11.378567\n",
      "loss is :  11.377195\n",
      "loss is :  11.375829\n",
      "loss is :  11.374464\n",
      "loss is :  11.373099\n",
      "loss is :  11.371737\n",
      "loss is :  11.370379\n",
      "loss is :  11.3690195\n",
      "loss is :  11.367662\n",
      "loss is :  11.366309\n",
      "loss is :  11.364956\n",
      "loss is :  11.363605\n",
      "loss is :  11.362256\n",
      "loss is :  11.360908\n",
      "loss is :  11.359562\n",
      "loss is :  11.358217\n",
      "loss is :  11.356874\n",
      "loss is :  11.355535\n",
      "loss is :  11.354194\n",
      "loss is :  11.352857\n",
      "loss is :  11.35152\n",
      "loss is :  11.350185\n",
      "loss is :  11.348853\n",
      "loss is :  11.347523\n",
      "loss is :  11.346191\n",
      "loss is :  11.344864\n",
      "loss is :  11.343537\n",
      "loss is :  11.342213\n",
      "loss is :  11.340889\n",
      "loss is :  11.339569\n",
      "loss is :  11.338249\n",
      "loss is :  11.336932\n",
      "loss is :  11.335615\n",
      "loss is :  11.334301\n",
      "loss is :  11.332987\n",
      "loss is :  11.331674\n",
      "loss is :  11.330364\n",
      "loss is :  11.329054\n",
      "loss is :  11.327747\n",
      "loss is :  11.326443\n",
      "loss is :  11.325139\n",
      "loss is :  11.323834\n",
      "loss is :  11.3225355\n",
      "loss is :  11.321236\n",
      "loss is :  11.319937\n",
      "loss is :  11.318643\n",
      "loss is :  11.3173485\n",
      "loss is :  11.316053\n",
      "loss is :  11.314763\n",
      "loss is :  11.313471\n",
      "loss is :  11.312182\n",
      "loss is :  11.310896\n",
      "loss is :  11.30961\n",
      "loss is :  11.308325\n",
      "loss is :  11.30704\n",
      "loss is :  11.30576\n",
      "loss is :  11.304481\n",
      "loss is :  11.303202\n",
      "loss is :  11.301923\n",
      "loss is :  11.300649\n",
      "loss is :  11.299374\n",
      "loss is :  11.298102\n",
      "loss is :  11.296829\n",
      "loss is :  11.295562\n",
      "loss is :  11.294292\n",
      "loss is :  11.293026\n",
      "loss is :  11.29176\n",
      "loss is :  11.290497\n",
      "loss is :  11.289232\n",
      "loss is :  11.287972\n",
      "loss is :  11.286711\n",
      "loss is :  11.285453\n",
      "loss is :  11.284194\n",
      "loss is :  11.28294\n",
      "loss is :  11.281685\n",
      "loss is :  11.28043\n",
      "loss is :  11.279179\n",
      "loss is :  11.277931\n",
      "loss is :  11.276682\n",
      "loss is :  11.275432\n",
      "loss is :  11.274186\n",
      "loss is :  11.2729435\n",
      "loss is :  11.2717\n",
      "loss is :  11.270456\n",
      "loss is :  11.269217\n",
      "loss is :  11.267974\n",
      "loss is :  11.266737\n",
      "loss is :  11.265498\n",
      "loss is :  11.264264\n",
      "loss is :  11.263032\n",
      "loss is :  11.261797\n",
      "loss is :  11.260566\n",
      "loss is :  11.259335\n",
      "loss is :  11.258107\n",
      "loss is :  11.25688\n",
      "loss is :  11.255652\n",
      "loss is :  11.254427\n",
      "loss is :  11.253203\n",
      "loss is :  11.25198\n",
      "loss is :  11.25076\n",
      "loss is :  11.249538\n",
      "loss is :  11.248319\n",
      "loss is :  11.247103\n",
      "loss is :  11.245888\n",
      "loss is :  11.244672\n",
      "loss is :  11.243457\n",
      "loss is :  11.242243\n",
      "loss is :  11.241032\n",
      "loss is :  11.239825\n",
      "loss is :  11.238613\n",
      "loss is :  11.237407\n",
      "loss is :  11.2362\n",
      "loss is :  11.234995\n",
      "loss is :  11.233792\n",
      "loss is :  11.232589\n",
      "loss is :  11.231387\n",
      "loss is :  11.230187\n",
      "loss is :  11.22899\n",
      "loss is :  11.227792\n",
      "loss is :  11.226593\n",
      "loss is :  11.225398\n",
      "loss is :  11.224203\n",
      "loss is :  11.223011\n",
      "loss is :  11.221821\n",
      "loss is :  11.220631\n",
      "loss is :  11.219438\n",
      "loss is :  11.218251\n",
      "loss is :  11.217065\n",
      "loss is :  11.215879\n",
      "loss is :  11.214693\n",
      "loss is :  11.21351\n",
      "loss is :  11.212329\n",
      "loss is :  11.211146\n",
      "loss is :  11.209967\n",
      "loss is :  11.208786\n",
      "loss is :  11.207607\n",
      "loss is :  11.206432\n",
      "loss is :  11.205256\n",
      "loss is :  11.2040825\n",
      "loss is :  11.202909\n",
      "loss is :  11.201738\n",
      "loss is :  11.200565\n",
      "loss is :  11.199397\n",
      "loss is :  11.198227\n",
      "loss is :  11.19706\n",
      "loss is :  11.195892\n",
      "loss is :  11.194727\n",
      "loss is :  11.193563\n",
      "loss is :  11.192401\n",
      "loss is :  11.1912365\n",
      "loss is :  11.190078\n",
      "loss is :  11.188916\n",
      "loss is :  11.187758\n",
      "loss is :  11.186602\n",
      "loss is :  11.185446\n",
      "loss is :  11.184289\n",
      "loss is :  11.183135\n",
      "loss is :  11.18198\n",
      "loss is :  11.180828\n",
      "loss is :  11.179677\n",
      "loss is :  11.178528\n",
      "loss is :  11.177378\n",
      "loss is :  11.1762295\n",
      "loss is :  11.175085\n",
      "loss is :  11.173938\n",
      "loss is :  11.172795\n",
      "loss is :  11.171649\n",
      "loss is :  11.170506\n",
      "loss is :  11.169364\n",
      "loss is :  11.168226\n",
      "loss is :  11.167086\n",
      "loss is :  11.165945\n",
      "loss is :  11.164809\n",
      "loss is :  11.163672\n",
      "loss is :  11.162539\n",
      "loss is :  11.161403\n",
      "loss is :  11.160269\n",
      "loss is :  11.159137\n",
      "loss is :  11.158004\n",
      "loss is :  11.156876\n",
      "loss is :  11.155747\n",
      "loss is :  11.15462\n",
      "loss is :  11.153492\n",
      "loss is :  11.152367\n",
      "loss is :  11.15124\n",
      "loss is :  11.150118\n",
      "loss is :  11.1489935\n",
      "loss is :  11.147871\n",
      "loss is :  11.146751\n",
      "loss is :  11.145629\n",
      "loss is :  11.144512\n",
      "loss is :  11.143392\n",
      "loss is :  11.142274\n",
      "loss is :  11.14116\n",
      "loss is :  11.140043\n",
      "loss is :  11.138931\n",
      "loss is :  11.137817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is :  11.136707\n",
      "loss is :  11.135594\n",
      "loss is :  11.134484\n",
      "loss is :  11.133375\n",
      "loss is :  11.132265\n",
      "loss is :  11.13116\n",
      "loss is :  11.130053\n",
      "loss is :  11.128946\n",
      "loss is :  11.127843\n",
      "loss is :  11.126739\n",
      "loss is :  11.125637\n",
      "loss is :  11.124534\n",
      "loss is :  11.123433\n",
      "loss is :  11.1223345\n",
      "loss is :  11.121238\n",
      "loss is :  11.120138\n",
      "loss is :  11.11904\n",
      "loss is :  11.117944\n",
      "loss is :  11.116849\n",
      "loss is :  11.115757\n",
      "loss is :  11.114662\n",
      "loss is :  11.11357\n",
      "loss is :  11.112481\n",
      "loss is :  11.111389\n",
      "loss is :  11.1103\n",
      "loss is :  11.109212\n",
      "loss is :  11.108125\n",
      "loss is :  11.107038\n",
      "loss is :  11.10595\n",
      "loss is :  11.104869\n",
      "loss is :  11.103782\n",
      "loss is :  11.1027\n",
      "loss is :  11.101618\n",
      "loss is :  11.100537\n",
      "loss is :  11.099456\n",
      "loss is :  11.098376\n",
      "loss is :  11.097298\n",
      "loss is :  11.09622\n",
      "loss is :  11.095143\n",
      "loss is :  11.094069\n",
      "loss is :  11.092994\n",
      "loss is :  11.091919\n",
      "loss is :  11.090847\n",
      "loss is :  11.089774\n",
      "loss is :  11.088699\n",
      "loss is :  11.087632\n",
      "loss is :  11.086563\n",
      "loss is :  11.085494\n",
      "loss is :  11.084426\n",
      "loss is :  11.083359\n",
      "loss is :  11.082293\n",
      "loss is :  11.081229\n",
      "loss is :  11.080162\n",
      "loss is :  11.079099\n",
      "loss is :  11.078037\n",
      "loss is :  11.076974\n",
      "loss is :  11.075913\n",
      "loss is :  11.074856\n",
      "loss is :  11.073794\n",
      "loss is :  11.072736\n",
      "loss is :  11.071679\n",
      "loss is :  11.070621\n",
      "loss is :  11.069566\n",
      "loss is :  11.068511\n",
      "loss is :  11.067456\n",
      "loss is :  11.066402\n",
      "loss is :  11.065352\n",
      "loss is :  11.064298\n",
      "loss is :  11.063249\n",
      "loss is :  11.0622\n",
      "loss is :  11.061149\n",
      "loss is :  11.060101\n",
      "loss is :  11.059054\n",
      "loss is :  11.058007\n",
      "loss is :  11.056962\n",
      "loss is :  11.055918\n",
      "loss is :  11.054872\n",
      "loss is :  11.053828\n",
      "loss is :  11.052787\n",
      "loss is :  11.0517435\n",
      "loss is :  11.050705\n",
      "loss is :  11.049664\n",
      "loss is :  11.048626\n",
      "loss is :  11.047586\n",
      "loss is :  11.046549\n",
      "loss is :  11.045512\n",
      "loss is :  11.044477\n",
      "loss is :  11.043442\n",
      "loss is :  11.042407\n",
      "loss is :  11.041373\n",
      "loss is :  11.040339\n",
      "loss is :  11.039309\n",
      "loss is :  11.038278\n",
      "loss is :  11.037248\n",
      "loss is :  11.036219\n",
      "loss is :  11.03519\n",
      "loss is :  11.034162\n",
      "loss is :  11.033133\n",
      "loss is :  11.032107\n",
      "loss is :  11.03108\n",
      "loss is :  11.030056\n",
      "loss is :  11.029033\n",
      "loss is :  11.028009\n",
      "loss is :  11.026985\n",
      "loss is :  11.025962\n",
      "loss is :  11.024943\n",
      "loss is :  11.023923\n",
      "loss is :  11.022902\n",
      "loss is :  11.021884\n",
      "loss is :  11.020866\n",
      "loss is :  11.019849\n",
      "loss is :  11.018833\n",
      "loss is :  11.017818\n",
      "loss is :  11.016803\n",
      "loss is :  11.015787\n",
      "loss is :  11.014774\n",
      "loss is :  11.013762\n",
      "loss is :  11.01275\n",
      "loss is :  11.01174\n",
      "loss is :  11.010728\n",
      "loss is :  11.009719\n",
      "loss is :  11.00871\n",
      "loss is :  11.007703\n",
      "loss is :  11.006695\n",
      "loss is :  11.00569\n",
      "loss is :  11.004684\n",
      "loss is :  11.003676\n",
      "loss is :  11.002677\n",
      "loss is :  11.001672\n",
      "loss is :  11.000669\n",
      "loss is :  10.999664\n",
      "loss is :  10.998664\n",
      "loss is :  10.997663\n",
      "loss is :  10.996664\n",
      "loss is :  10.995664\n",
      "loss is :  10.994665\n",
      "loss is :  10.993667\n",
      "loss is :  10.99267\n",
      "loss is :  10.991676\n",
      "loss is :  10.990678\n",
      "loss is :  10.989685\n",
      "loss is :  10.988692\n",
      "loss is :  10.987698\n",
      "loss is :  10.986704\n",
      "loss is :  10.985713\n",
      "loss is :  10.984722\n",
      "loss is :  10.983729\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) #make sure you do this!\n",
    "# define the loss function:\n",
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
    "# define the training step:\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
    "n_iters = 10000\n",
    "# train for n_iter iterations\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
    "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Articles = 100, Window Size = 5\n",
    "# Started at 12.55 AM\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74582875  0.7793943   0.07386164  0.15888414 -1.0550942 ]\n",
      " [ 0.98273414  0.0811931   0.0202823   0.3914135  -0.6963007 ]\n",
      " [ 0.01152561 -0.315974   -0.21288878  0.15460855  0.8525657 ]\n",
      " ...\n",
      " [-0.5787782   2.55173    -0.3985736   0.58246446  0.26849777]\n",
      " [-0.8640642   0.09151337  0.37342748  0.8094642   0.5006471 ]\n",
      " [ 2.7362478  -0.53771824 -1.2462976   1.5780292  -0.5305438 ]]\n",
      "----------\n",
      "[0.2118817  0.09580352 0.28877154 0.22681047 0.16917028]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(W1))\n",
    "print('----------')\n",
    "print(sess.run(b1))\n",
    "print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = sess.run(W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(vec1, vec2):\n",
    "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
    "def find_closest(word_index, vectors):\n",
    "    min_dist = 10000 # to act like positive infinity\n",
    "    min_index = -1\n",
    "    query_vector = vectors[word_index]\n",
    "    for index, vector in enumerate(vectors):\n",
    "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
    "            min_dist = euclidean_dist(vector, query_vector)\n",
    "            min_index = index\n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packag\n",
      "disappoint\n",
      "follow\n"
     ]
    }
   ],
   "source": [
    "# We will now query these vectors with ‘king’, ‘queen’ and ‘royal’\n",
    "print(int2word[find_closest(word2int['canadian'], vectors)])\n",
    "print(int2word[find_closest(word2int['pharmaci'], vectors)])\n",
    "print(int2word[find_closest(word2int['covid19'], vectors)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -3.8947728\n",
      "face -15.572499\n",
      "anim 1.0498935\n",
      "analysi -27.109291\n",
      "market 22.697393\n",
      "ship 2.409625\n",
      "1000 16.15856\n",
      "could 9.423725\n",
      "critic 33.66415\n",
      "remot -1.252983\n",
      "leader 4.5464296\n",
      "tumult -13.851024\n",
      "afford -8.124293\n",
      "entertain -0.89187616\n",
      "warn -9.086381\n",
      "forc -7.2234974\n",
      "cap -25.375395\n",
      "respiratori -10.305653\n",
      "toxic 9.459612\n",
      "10000 33.244785\n",
      "spong -28.22298\n",
      "start 24.725822\n",
      "justin -29.294842\n",
      "anyth -17.52146\n",
      "basebal 28.959248\n",
      "initi 29.42309\n",
      "addit -10.913372\n",
      "brief 16.302504\n",
      "option -16.439035\n",
      "specialist 28.440205\n",
      "coronaviru 16.817432\n",
      "pressur 25.393217\n",
      "view -2.5587611\n",
      "ordersanyon -17.755936\n",
      "six 30.785965\n",
      "kanopi -1.4266641\n",
      "dispens 21.57296\n",
      "deputi 17.981155\n",
      "equal -1.5556762\n",
      "blast -10.843041\n",
      "stress -16.035044\n",
      "right -19.541338\n",
      "spiral 18.063726\n",
      "wish -11.98849\n",
      "treatment -31.669596\n",
      "biotech 26.972506\n",
      "whose -35.80998\n",
      "alcohol 6.4318314\n",
      "settl 0.11116588\n",
      "trick 19.133835\n",
      "journal 22.785318\n",
      "suppli 21.73817\n",
      "work 26.32507\n",
      "permanent 16.523457\n",
      "confin 29.671194\n",
      "break 27.993616\n",
      "attent -20.050459\n",
      "appear -5.8178678\n",
      "600 -9.580401\n",
      "world 17.346323\n",
      "show 31.455109\n",
      "late 32.553104\n",
      "urg -11.114392\n",
      "reason 30.615229\n",
      "chang -33.11709\n",
      "ongo 17.960701\n",
      "downtim 6.918359\n",
      "death 23.673939\n",
      "real -10.1678295\n",
      "15 6.459705\n",
      "indigen 5.1748877\n",
      "outsid 16.793238\n",
      "aid -33.100456\n",
      "prioriti 10.72185\n",
      "build -6.19005\n",
      "new 23.305\n",
      "wave -4.552723\n",
      "accord -5.7945614\n",
      "handl -18.53722\n",
      "player -18.449028\n",
      "fear -29.932814\n",
      "recal -7.2523494\n",
      "stockpil -34.20797\n",
      "steven -5.2140117\n",
      "activ -17.218107\n",
      "effect -5.9528055\n",
      "plasma -6.820815\n",
      "got -31.68079\n",
      "groceri -6.2828646\n",
      "took 25.35496\n",
      "herb 27.751522\n",
      "school -15.071505\n",
      "liber 32.577076\n",
      "provid 0.48099956\n",
      "academi -17.981722\n",
      "system -7.9690113\n",
      "chri 3.4714596\n",
      "whether -19.074064\n",
      "plu -33.59223\n",
      "rama 1.66822\n",
      "unparallel 22.030396\n",
      "confid -35.85128\n",
      "serious 3.6065392\n",
      "frequenc 1.5122845\n",
      "deliv 30.648716\n",
      "daili -18.07945\n",
      "medicin 9.691555\n",
      "told -34.343742\n",
      "cent -12.515008\n",
      "parti 6.5599093\n",
      "militari 11.418939\n",
      "assur -18.601418\n",
      "closer -35.06082\n",
      "abroad 20.77212\n",
      "wipe 3.5424101\n",
      "america -15.642555\n",
      "26 26.71067\n",
      "rule 4.8976274\n",
      "stori 4.9675593\n",
      "rather 31.700907\n",
      "thursday -15.517552\n",
      "countri -18.377651\n",
      "uber -33.360844\n",
      "flood 4.161202\n",
      "chines -15.07502\n",
      "guojian -7.276832\n",
      "program 4.5937657\n",
      "usual 19.12232\n",
      "recess -18.57307\n",
      "stay 16.364798\n",
      "hrefhttpstwittercomhashtagcovid19srchashamprefsrctwsrc5etfwcovid19a -15.826045\n",
      "away 2.6416929\n",
      "clinic 16.153465\n",
      "modifi 21.104181\n",
      "professor 13.609203\n",
      "23 0.5475135\n",
      "dr -28.544533\n",
      "arduou -21.093592\n",
      "via -25.529757\n",
      "colleg -7.9589224\n",
      "mutual 32.850803\n",
      "detect -14.391002\n",
      "someth -1.5780535\n",
      "hadfield -15.724577\n",
      "along 32.149727\n",
      "2000 -14.118692\n",
      "social -1.7205174\n",
      "must -17.4777\n",
      "either -7.8551292\n",
      "367 1.3996584\n",
      "match 2.6769483\n",
      "money -16.381195\n",
      "act -6.646839\n",
      "18775366837 28.494816\n",
      "youv -14.823979\n",
      "move 7.4113984\n",
      "differ 28.505821\n",
      "hrefhttpstwittercommountsinainycrefsrctwsrc5etfwmountsinainyca -18.377415\n",
      "minist -4.8454866\n",
      "hoard 17.616692\n",
      "fortun 2.2432811\n",
      "fight -19.75196\n",
      "pandem 16.249748\n",
      "soap -5.8119373\n",
      "addon -33.815514\n",
      "werent 31.607344\n",
      "greatest 32.458065\n",
      "chief -17.533113\n",
      "ever -3.5584967\n",
      "practic -1.9969277\n",
      "reveal -2.2101555\n",
      "showcas -25.922194\n",
      "tag -5.367168\n",
      "62 -18.013254\n",
      "latex -33.90543\n",
      "identifi -16.346977\n",
      "delay 8.912364\n",
      "jason -16.257595\n",
      "advertis 14.312098\n",
      "spring -7.7615986\n",
      "low -19.035254\n",
      "apart 22.99572\n",
      "reach -16.431496\n",
      "toronto 29.867691\n",
      "test 16.216919\n",
      "array 33.434837\n",
      "came 27.12673\n",
      "like 25.374546\n",
      "exist -32.648\n",
      "opportun -18.46584\n",
      "disinfect 8.601661\n",
      "maneuv 15.75424\n",
      "confront 31.294985\n",
      "territori 24.755753\n",
      "kid -2.8793895\n",
      "date -15.290702\n",
      "500 -20.949568\n",
      "infus 30.395721\n",
      "offici 0.5206058\n",
      "local -25.90369\n",
      "proven 29.734962\n",
      "need 23.562151\n",
      "recogn 1.2393029\n",
      "shortag 1.4261906\n",
      "primarili 4.46437\n",
      "us 20.738022\n",
      "say 25.030178\n",
      "lie -12.1113205\n",
      "phone 5.980362\n",
      "nation -18.386213\n",
      "place -12.425347\n",
      "member -14.507787\n",
      "visitor 23.279999\n",
      "fail -1.6972376\n",
      "distanc -14.240138\n",
      "capitol 9.671462\n",
      "indic -18.721016\n",
      "thing 9.457739\n",
      "month -11.505751\n",
      "ad -16.911913\n",
      "stairway -9.22552\n",
      "trust 26.276707\n",
      "recov -1.3804914\n",
      "tax -27.33242\n",
      "recreat -1.5652854\n",
      "europ 4.714832\n",
      "sheer -8.944153\n",
      "trillion 25.066608\n",
      "mediterranean -19.332047\n",
      "chronic 26.829876\n",
      "govern 2.1987731\n",
      "claim -14.970053\n",
      "pig -29.800701\n",
      "go -30.346943\n",
      "organ -19.54984\n",
      "march 19.418058\n",
      "canada 21.11102\n",
      "would 20.612234\n",
      "grow 32.779957\n",
      "measur 1.4026223\n",
      "annual 5.3779836\n",
      "entir 30.04874\n",
      "domin -14.088696\n",
      "httpswwwcbccanewsentertainmentfreefamilystreamingcovid19stayathome15509556 7.5320745\n",
      "tea -4.6992326\n",
      "cardiac -10.922562\n",
      "paid 28.698858\n",
      "near -18.204117\n",
      "therapist 18.23942\n",
      "size -8.60597\n",
      "promin -5.460238\n",
      "risk -33.25693\n",
      "hotspot 1.7265948\n",
      "york 11.529317\n",
      "sweep -4.938977\n",
      "strict 33.19513\n",
      "yukon 17.443993\n",
      "someon -18.454906\n",
      "20 -16.262749\n",
      "viru -5.558914\n",
      "arthriti -3.9727733\n",
      "drive 30.3938\n",
      "trial -33.926437\n",
      "ventil 27.491957\n",
      "mitig 5.0479207\n",
      "tadrou -17.076666\n",
      "driver 22.351284\n",
      "share 0.08465342\n",
      "furlough -3.3723373\n",
      "grim 0.12969416\n",
      "22 29.0373\n",
      "polic -13.798709\n",
      "compani 25.436533\n",
      "find 2.6911027\n",
      "import -2.68041\n",
      "inform -4.635953\n",
      "border 17.768269\n",
      "far 17.443775\n",
      "institut -2.6355493\n",
      "trevor -7.1767035\n",
      "avail 20.119516\n",
      "toll 16.71203\n",
      "progress 23.30644\n",
      "lawmak 27.457792\n",
      "riskiest -13.785322\n",
      "timet 8.806904\n",
      "amount -14.117776\n",
      "possibl -24.220577\n",
      "circul -14.931178\n",
      "lifetim -33.333652\n",
      "current -16.542831\n",
      "louisiana -6.005495\n",
      "mental -18.7818\n",
      "network 21.860498\n",
      "pelosi -25.626558\n",
      "though 3.6115518\n",
      "produc 0.878551\n",
      "mnuchin -18.406988\n",
      "20000 -11.885727\n",
      "nanci -25.963097\n",
      "crossbord 1.8401834\n",
      "wholesal -15.559371\n",
      "negoti -14.6727915\n",
      "firststag 23.551878\n",
      "nonessenti -11.521752\n",
      "product 15.479489\n",
      "expect -18.310598\n",
      "titl -20.017532\n",
      "univers -16.355003\n",
      "cuomo -4.197407\n",
      "alberta -28.425741\n",
      "pend -19.618538\n",
      "payrol 6.151725\n",
      "uncheck -29.204702\n",
      "kill -18.635353\n",
      "canadian 19.94369\n",
      "enact -19.276293\n",
      "polit -8.237077\n",
      "travel 26.902248\n",
      "desper 23.313187\n",
      "float 17.22472\n",
      "region -10.492998\n",
      "approv 14.796206\n",
      "loan -3.054853\n",
      "caution 32.23266\n",
      "economi 17.71659\n",
      "huge -27.986616\n",
      "process -6.5082216\n",
      "even -4.6037507\n",
      "assiniboin -25.640913\n",
      "alaska 5.837435\n",
      "inhal -32.89969\n",
      "individu 29.165283\n",
      "servic -5.079104\n",
      "weve 27.589882\n",
      "hrefhttpstcobpsb2husqrhttpstcobpsb2husqra -30.941404\n",
      "final 11.496814\n",
      "impact 2.0386727\n",
      "clean -1.4072748\n",
      "open 33.302288\n",
      "hydroxychloroquin 11.439013\n",
      "that -4.829257\n",
      "premier 17.12394\n",
      "blood 15.6708355\n",
      "close -31.733343\n",
      "last -18.31042\n",
      "emerg -12.7511015\n",
      "minor -8.204013\n",
      "controversi 16.057272\n",
      "classic 5.797779\n",
      "medic 1.2536595\n",
      "one 25.598104\n",
      "report 16.371956\n",
      "malaria -5.2234235\n",
      "payment -18.905922\n",
      "treasuri 30.77355\n",
      "unemploy 17.250877\n",
      "illeg -26.622173\n",
      "prescript -12.787328\n",
      "inflammatori 27.236485\n",
      "speaker -9.514521\n",
      "respons -1.3081603\n",
      "criteria 23.683147\n",
      "damag -16.342306\n",
      "certainli -15.140767\n",
      "hypertens 29.825144\n",
      "treat 14.620481\n",
      "8891kilometrelong -5.402519\n",
      "amid -15.941983\n",
      "riskier -1.3305794\n",
      "winnipeg -3.3831804\n",
      "increasingli 5.8020163\n",
      "retent -10.107691\n",
      "million 6.6984973\n",
      "investig -3.774707\n",
      "ocasiocortez -17.58061\n",
      "surfac -16.212107\n",
      "trudeau 20.085588\n",
      "use 32.079464\n",
      "laid 7.810582\n",
      "well 13.411316\n",
      "scatter -4.356191\n",
      "wealth -7.974658\n",
      "drugmak -9.57427\n",
      "news 4.5450816\n",
      "time -17.152477\n",
      "small -9.6388035\n",
      "set 1.0846041\n",
      "race 16.559793\n",
      "readili -26.202202\n",
      "research -27.32291\n",
      "prior -6.947305\n",
      "sourc 16.442179\n",
      "anoth -18.342169\n",
      "2400 -26.849384\n",
      "nearli 26.804974\n",
      "tradit -11.560839\n",
      "tension -17.200674\n",
      "written 3.860871\n",
      "offic 10.911667\n",
      "transfer -8.507994\n",
      "decad -12.514435\n",
      "rocket -8.660947\n",
      "disappoint -20.440636\n",
      "access 2.0908635\n",
      "coverag 7.6388507\n",
      "trip 18.667084\n",
      "strongli 10.676129\n",
      "effort -19.150816\n",
      "power -5.6368117\n",
      "case 21.211636\n",
      "billion -9.948006\n",
      "announc 11.562534\n",
      "abl -17.50064\n",
      "partner 32.63433\n",
      "secretari 32.103817\n",
      "space 31.642511\n",
      "faucet 0.48586193\n",
      "life 6.113346\n",
      "went -2.674951\n",
      "infect 25.652922\n",
      "fallout 8.567117\n",
      "tom 7.7804418\n",
      "third 28.632456\n",
      "director -9.109525\n",
      "80 -9.717181\n",
      "tend -19.607021\n",
      "precaut -12.160216\n",
      "avoid -26.596395\n",
      "engulf 28.344849\n",
      "north 19.567972\n",
      "washington -1.5562186\n",
      "imag -36.839283\n",
      "miss -11.289054\n",
      "conjunct -32.73305\n",
      "hiscox -8.655226\n",
      "tubi -12.842979\n",
      "democrat 3.7125235\n",
      "doctor -20.127865\n",
      "dental 3.7006128\n",
      "ground 15.512758\n",
      "275 -30.433779\n",
      "order -13.194137\n",
      "mice -12.688151\n",
      "sunday -13.423932\n",
      "present -34.14183\n",
      "meant -25.309553\n",
      "seen -18.869022\n",
      "huang 25.42939\n",
      "caus -5.8687363\n",
      "educ 15.788202\n",
      "benefit -14.34495\n",
      "think 25.698496\n",
      "worker 19.70712\n",
      "failur -13.601567\n",
      "acupunctur 23.224648\n",
      "behçet -17.70636\n",
      "fiveday 28.206226\n",
      "airlin 0.7400691\n",
      "4 -12.35232\n",
      "peopl 16.857944\n",
      "acetaminophen 30.838657\n",
      "enrich 8.436592\n",
      "bureau 19.11621\n",
      "media -2.4767628\n",
      "part -3.6305208\n",
      "potenti 1.4640381\n",
      "soar -15.0428505\n",
      "guarante -9.471508\n",
      "onetim 9.439838\n",
      "pharmaci -20.315845\n",
      "lupu 31.432587\n",
      "roussycbc -9.014131\n",
      "wont 16.123583\n",
      "saskatoon 22.10305\n",
      "disrupt 3.423729\n",
      "purpos -17.713696\n",
      "unfold 2.9799395\n",
      "idl 28.615005\n",
      "associ -9.08896\n",
      "atop -14.4117985\n",
      "repurpos 0.7455985\n",
      "sensor 24.996725\n",
      "fund 25.563194\n",
      "pay -10.325695\n",
      "packag 19.600466\n",
      "provinci 1.7944487\n",
      "commun -16.70147\n",
      "involv -0.06718115\n",
      "mcgill 2.28947\n",
      "anybodi 19.193462\n",
      "commerc 18.114134\n",
      "children -14.95899\n",
      "ardent 3.6228259\n",
      "protect -35.020664\n",
      "relief 27.568869\n",
      "agenc 17.759882\n",
      "period 18.634798\n",
      "mayb -4.7147384\n",
      "cart -17.49977\n",
      "mlb 28.375269\n",
      "acceler 20.963974\n",
      "ask -20.624182\n",
      "gareth 25.832184\n",
      "troop 24.955914\n",
      "159 16.86389\n",
      "live -11.585336\n",
      "shot 5.08312\n",
      "cash 2.3218265\n",
      "stayathom 6.3452897\n",
      "child -1.215031\n",
      "elia -6.8393126\n",
      "particip -5.063104\n",
      "kaiser 28.417892\n",
      "white -32.74773\n",
      "china 17.03693\n",
      "craft -9.231749\n",
      "tukkercbc 8.064554\n",
      "congress -15.45315\n",
      "mani 10.0599785\n",
      "leagu -0.9899088\n",
      "actual -30.129282\n",
      "destin 25.80644\n",
      "game -31.313816\n",
      "physician 5.1861663\n",
      "rescu 4.920507\n",
      "ford -29.27632\n",
      "send 27.479183\n",
      "learn 28.1085\n",
      "wors -33.739296\n",
      "challeng -14.534145\n",
      "still -2.0695899\n",
      "clear -9.29977\n",
      "remov -16.09877\n",
      "17 -13.991721\n",
      "step 33.758762\n",
      "gig -5.2130976\n",
      "promis -8.12028\n",
      "cloth -4.2516284\n",
      "profession -31.001968\n",
      "respond 33.51765\n",
      "000 6.885783\n",
      "50 3.2419953\n",
      "infecti -2.964026\n",
      "rough 31.75429\n",
      "spent 23.008886\n",
      "uniqu -3.4245002\n",
      "squar 5.748646\n",
      "histor 0.6784004\n",
      "return 19.683466\n",
      "sombr 30.972498\n",
      "marri -29.646135\n",
      "intend -36.512665\n",
      "top -15.116587\n",
      "free -13.922956\n",
      "worri -27.444128\n",
      "believ -10.416401\n",
      "content -17.25126\n",
      "state 33.46067\n",
      "feder -19.055223\n",
      "enforc -2.5882108\n",
      "earn -6.9162116\n",
      "disclos -9.742575\n",
      "stimul 3.29236\n",
      "choos 6.142628\n",
      "grew 18.159847\n",
      "get 21.488766\n",
      "road -17.526188\n",
      "three 18.180328\n",
      "morn -13.076427\n",
      "manitoba -26.843935\n",
      "station 17.782831\n",
      "unlimit 24.616518\n",
      "dig -15.673651\n",
      "safeti -9.106284\n",
      "may -15.547993\n",
      "made 23.914413\n",
      "film 29.972021\n",
      "side -14.680193\n",
      "foolish -30.685654\n",
      "permit 7.95462\n",
      "job 21.46437\n",
      "demand -2.3249133\n",
      "andrew -24.162825\n",
      "seri 4.118215\n",
      "intern 16.57349\n",
      "idea 12.4947405\n",
      "colchicin -34.10447\n",
      "hidden 32.3176\n",
      "recent 30.71777\n",
      "today -13.223642\n",
      "expos -29.24593\n",
      "none -12.78919\n",
      "realiti -10.450256\n",
      "legisl 16.483448\n",
      "help 21.488348\n",
      "timelin 22.356125\n",
      "further -14.464768\n",
      "ont -22.135565\n",
      "optimist -12.8739\n",
      "sar -13.187524\n",
      "doorknob 30.176352\n",
      "lab -9.858175\n",
      "inclus 11.9714575\n",
      "sprawl 1.3591675\n",
      "latest -8.484853\n",
      "interview -33.06669\n",
      "peter -12.711999\n",
      "zone -15.945154\n",
      "intercept 10.1022005\n",
      "16 -17.719698\n",
      "alexandria -9.238867\n",
      "2nd 24.92055\n",
      "danger -8.9199915\n",
      "refillsnew 0.1466083\n",
      "studi 22.260529\n",
      "difficulti -17.035416\n",
      "implement -16.934446\n",
      "plastic -23.792915\n",
      "coronavirus 4.4263544\n",
      "click 1.2136499\n",
      "forth -16.833132\n",
      "publichealth -10.391845\n",
      "incent -8.150625\n",
      "lin -18.83995\n",
      "way 23.866896\n",
      "digit 33.97264\n",
      "ensur 30.867874\n",
      "duffin 31.266972\n",
      "paul -15.649566\n",
      "ryan 12.042307\n",
      "hill -25.355774\n",
      "quarantin -13.13255\n",
      "four -7.6349006\n",
      "covid19 18.344332\n",
      "exhaust 4.5867405\n",
      "spread -11.870212\n",
      "export 19.234625\n",
      "hope -18.223974\n",
      "theyr -17.240114\n",
      "eye 15.5648365\n",
      "antibodyrich 24.956993\n",
      "necessari -33.222885\n",
      "isol -6.804373\n",
      "unlik -13.460129\n",
      "among 16.327162\n",
      "selfisol 31.839714\n",
      "virus 3.8275561\n",
      "friday 5.3864594\n",
      "american 1.5239727\n",
      "internet 23.784576\n",
      "fever -18.992514\n",
      "talk 23.51098\n",
      "subscript 24.351318\n",
      "agent 0.7456504\n",
      "presid 29.976793\n",
      "porou -4.6514935\n",
      "insist 1.61358\n",
      "cough 17.395372\n",
      "senat 14.755989\n",
      "speed -6.961537\n",
      "water -19.963717\n",
      "stand 16.42913\n",
      "select -14.9763565\n",
      "long 25.808804\n",
      "volunt 5.544979\n",
      "goe -11.571717\n",
      "react 27.233957\n",
      "plasmapheresi -6.6998863\n",
      "stuff 30.563356\n",
      "adsupport -21.027283\n",
      "alreadi 20.635565\n",
      "releas -1.3038877\n",
      "control -1.7891725\n",
      "togeth -10.464483\n",
      "season 2.647071\n",
      "keep 23.590977\n",
      "adult -18.934694\n",
      "healthi -20.580042\n",
      "tell 24.264835\n",
      "employe 29.623692\n",
      "variou 1.334846\n",
      "regulatori -8.150837\n",
      "object 30.260185\n",
      "chamber -22.964468\n",
      "im -12.537375\n",
      "rise -15.6260195\n",
      "migrant 6.194014\n",
      "read 26.863983\n",
      "given -20.151218\n",
      "diseas 14.212749\n",
      "130 26.54631\n",
      "halt 10.528675\n",
      "dont -32.117283\n",
      "minnesota 23.251085\n",
      "slow -14.41109\n",
      "experiment 31.699501\n",
      "vast -21.986443\n",
      "sinc -27.039385\n",
      "later -13.250293\n",
      "origin 4.528752\n",
      "heavili -1.1339645\n",
      "drug -30.093702\n",
      "epidemiologist -33.36337\n",
      "gener 21.261997\n",
      "mouth -22.516342\n",
      "scientist -35.873505\n",
      "subscrib 4.737094\n",
      "larger -12.482239\n",
      "ka -3.9261026\n",
      "recommend 18.843178\n",
      "doug -19.647247\n",
      "antibiot -17.249355\n",
      "antibodi -16.374819\n",
      "afloat 16.075285\n",
      "toilet 2.8550787\n",
      "also 20.672037\n",
      "vulner -32.548874\n",
      "see -13.120522\n",
      "ban 33.431263\n",
      "subject 29.791315\n",
      "ottawa 30.45169\n",
      "best -12.205437\n",
      "anticip -21.21187\n",
      "much 3.9843097\n",
      "misgiv -6.95119\n",
      "conserv 0.660898\n",
      "coupl 2.0004418\n",
      "sport -12.3013735\n",
      "herd 20.390612\n",
      "inflamm 11.29848\n",
      "address 1.2051905\n",
      "context -26.786682\n",
      "queen -15.342745\n",
      "around 22.91658\n",
      "although -9.324275\n",
      "earli 5.9822173\n",
      "copleygetti 28.424747\n",
      "catalogu -16.895721\n",
      "writer -15.799599\n",
      "symptom -5.26743\n",
      "wednesday 5.244253\n",
      "bordercross -34.23805\n",
      "montreal -30.304932\n",
      "concern 19.15063\n",
      "tri 29.185349\n",
      "paychequ -2.4197903\n",
      "industri -7.688231\n",
      "sign 6.134816\n",
      "arent 27.364927\n",
      "freeland -34.784477\n",
      "drama -17.578344\n",
      "manufactur 11.111184\n",
      "remain 4.3483324\n",
      "becom -19.61015\n",
      "worldwid 34.01367\n",
      "pass -12.60759\n",
      "quickli 18.36034\n",
      "budget -13.933162\n",
      "6000 28.87408\n",
      "cbc -0.5986937\n",
      "platform 26.129534\n",
      "goahead -27.707893\n",
      "seriou -19.5339\n",
      "curiou -18.991585\n",
      "requir -10.158467\n",
      "salari -12.165679\n",
      "pharmaceut -18.890993\n",
      "expand 18.505241\n",
      "launch -11.064249\n",
      "safe -16.512468\n",
      "articl -15.061017\n",
      "allow -30.296923\n",
      "unauthor 24.05967\n",
      "mcconnel -14.80554\n",
      "action 15.632787\n",
      "811 -26.356482\n",
      "crisi -29.367746\n",
      "fingertip -11.899186\n",
      "kenney -7.4881864\n",
      "year -6.3183413\n",
      "45 -33.815784\n",
      "goal -6.741038\n",
      "residenti -9.245554\n",
      "restless -0.3423008\n",
      "come 2.450402\n",
      "daybreak 6.2411795\n",
      "india 8.033243\n",
      "interact -19.476255\n",
      "unnecessari 28.023136\n",
      "center 25.6469\n",
      "frequent -3.6357782\n",
      "expert -17.763004\n",
      "pharmacist -9.224574\n",
      "major -9.467506\n",
      "difficult 5.3674173\n",
      "mina -24.782946\n",
      "number -18.047256\n",
      "posit -15.072075\n",
      "supplier -13.66142\n",
      "scene -16.243608\n",
      "shut 4.4828553\n",
      "econom 31.867954\n",
      "copay -16.440952\n",
      "popul 11.821174\n",
      "retain -26.41266\n",
      "battl -9.307753\n",
      "drink 24.95379\n",
      "cannot 21.799768\n",
      "vaccin 17.66803\n",
      "public 23.523039\n",
      "eventu -5.0493736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000 11.814204\n",
      "begin -5.1323147\n",
      "trade -9.847184\n",
      "sick -3.5123818\n",
      "cover 31.386969\n",
      "track -11.5770645\n",
      "blend 26.81797\n",
      "mislead 4.4110937\n",
      "here 22.17565\n",
      "focus -20.241213\n",
      "outbreak 3.22317\n",
      "per 15.683399\n",
      "base -18.966576\n",
      "compli 19.06111\n",
      "14 -16.657051\n",
      "secur -4.1326256\n",
      "rheumatoid -36.39707\n",
      "ill -2.0389738\n",
      "second 26.279608\n",
      "cattl 29.944613\n",
      "whitehors 21.54646\n",
      "centuryold 8.104972\n",
      "astronaut -31.792763\n",
      "broad 28.730446\n",
      "8 27.615168\n",
      "4000 5.9088907\n",
      "unwash -29.632307\n",
      "includ 15.738359\n",
      "burden -35.552666\n",
      "quebec 28.910887\n",
      "spokesperson 18.724125\n",
      "prevent -17.98592\n",
      "april -28.35252\n",
      "fee 27.535082\n",
      "deal 5.777824\n",
      "especi 14.885817\n",
      "old 29.056107\n",
      "hurt 10.017166\n",
      "unclear -1.3694985\n",
      "request 23.889174\n",
      "rich 7.2149005\n",
      "back 33.600864\n",
      "essenti 29.069126\n",
      "misinform 10.14035\n",
      "glove 32.008663\n",
      "globe 34.785057\n",
      "encourag -34.277042\n",
      "parent -3.536217\n",
      "watch 3.7644677\n",
      "wasnt -29.145367\n",
      "expertis 33.435978\n",
      "prepar 10.283645\n",
      "despit -0.68040794\n",
      "herbal 16.936924\n",
      "propos -13.624949\n",
      "big -0.78120065\n",
      "13 21.351345\n",
      "sanit 2.8905737\n",
      "famili 7.733819\n",
      "anyon 31.139454\n",
      "refil 8.370261\n",
      "church 22.483494\n",
      "subsid -34.44644\n",
      "often 13.764066\n",
      "gov 28.65405\n",
      "lifesav -4.639816\n",
      "know -27.59845\n",
      "price -8.054366\n",
      "cure -29.481346\n",
      "monitor 0.61042094\n",
      "mount 1.0475926\n",
      "call -30.506243\n",
      "voic 5.099595\n",
      "unanim 14.831766\n",
      "meet -32.234203\n",
      "die 31.628153\n",
      "hasnt -35.461697\n",
      "despond -12.301587\n",
      "stop 14.90086\n",
      "short -31.722277\n",
      "bill 4.2003856\n",
      "administ 5.3417273\n",
      "comput -19.578548\n",
      "zarychanski -0.21901968\n",
      "might -32.34897\n",
      "lot 1.5671622\n",
      "limit 30.26902\n",
      "inexpens -30.355667\n",
      "smooth 3.2745845\n",
      "familyfriendli 26.140095\n",
      "attribut -18.723997\n",
      "breath -18.894825\n",
      "heart 0.36949787\n",
      "end 10.95723\n",
      "take -29.96544\n",
      "complic -18.103033\n",
      "knowledg -3.050934\n",
      "therapi -11.793388\n",
      "lung -17.852203\n",
      "certain 16.126308\n",
      "rapid -36.470036\n",
      "chain -0.77275074\n",
      "kingston -0.7317434\n",
      "documentari 28.66791\n",
      "signal -9.543333\n",
      "75000 5.5050864\n",
      "steer 26.053679\n",
      "relationship 29.910303\n",
      "mitch -18.396368\n",
      "hand 17.889376\n",
      "kilometr -12.469393\n",
      "ahead -8.72563\n",
      "nair 10.77036\n",
      "patch -1.6968119\n",
      "librari 33.811916\n",
      "make 5.173717\n",
      "matter -13.675254\n",
      "nose 3.0385387\n",
      "ontario 3.0072162\n",
      "largest 9.694927\n",
      "agreement -7.2701316\n",
      "sold -19.529985\n",
      "confirm -11.897038\n",
      "ingredi 17.147892\n",
      "bipartisan 14.044764\n",
      "scienc -30.571108\n",
      "1325 -27.245216\n",
      "ignor 6.285882\n",
      "full 28.405983\n",
      "oppos 20.146822\n",
      "hous 28.82809\n",
      "depth 23.73648\n",
      "trump 19.270702\n",
      "give 0.6376863\n",
      "client 30.96847\n",
      "mar 22.707613\n",
      "other 28.161776\n",
      "almost 21.076271\n",
      "histori -12.609159\n",
      "patient 1.3026972\n",
      "mind -7.947359\n",
      "1218 20.46387\n",
      "camera -18.869518\n",
      "wakeup 20.871012\n",
      "neutral -34.64673\n",
      "earlier -23.897842\n",
      "wide -6.950249\n",
      "gear -4.478115\n",
      "factori 2.2868881\n",
      "jacalyn -28.048223\n",
      "9 33.362488\n",
      "acupuncturist -8.176975\n",
      "magnitud -5.988417\n",
      "brinecbc -33.27124\n",
      "said 17.39328\n",
      "antiinflammatori -22.947401\n",
      "person -19.428497\n",
      "human 1.0708736\n",
      "donald -24.96009\n",
      "realli -30.17023\n",
      "exposur -27.117147\n",
      "25 -5.7458334\n",
      "half 4.743243\n",
      "creat 29.06485\n",
      "fals 24.280756\n",
      "particular 24.644295\n",
      "discuss 9.227274\n",
      "bethani -28.798447\n",
      "manag 31.334667\n",
      "newslett -10.167983\n",
      "reduc -3.3735647\n",
      "store -10.999636\n",
      "first -2.2421536\n",
      "lowwag -1.7452968\n",
      "seemingli -11.568828\n",
      "recruit 25.62768\n",
      "follow 17.88647\n",
      "instead -17.405798\n",
      "40 -31.37228\n",
      "brunswick 8.790305\n",
      "urgent -6.471865\n",
      "home -20.5244\n",
      "decis 6.060975\n",
      "leav -5.321039\n",
      "jeanclaud -14.657361\n",
      "mandatori -6.825587\n",
      "sooner -6.605658\n",
      "30day -10.321042\n",
      "estim 27.61538\n",
      "brennerreut 29.074606\n",
      "gout -28.299522\n",
      "site -30.819107\n",
      "command -7.1687274\n",
      "signatur -23.548916\n",
      "tardif 4.812214\n",
      "clerk 30.466366\n",
      "increas -30.816761\n",
      "visit 22.687803\n",
      "park 22.307154\n",
      "email 24.190449\n",
      "credit -13.54431\n",
      "week -30.555353\n",
      "spend -6.1079745\n",
      "coppercontain -7.6975765\n",
      "chrystia -19.266233\n",
      "irregular 5.5015306\n",
      "plenti -5.1321707\n",
      "highway 22.413334\n",
      "behind 29.070435\n",
      "1609 -14.774031\n",
      "60 27.938046\n",
      "question -7.1137476\n",
      "republican 1.6452045\n",
      "antimicrobi 34.40666\n",
      "1200 8.837398\n",
      "paper -28.604992\n",
      "provinc 0.5809646\n",
      "financ -18.38561\n",
      "enough -9.909388\n",
      "busi 24.163889\n",
      "whatev -2.5424306\n",
      "sight -19.674543\n",
      "your 18.52019\n",
      "replac -28.019009\n",
      "wash 21.883062\n",
      "sever 32.7655\n",
      "psycholog -24.89329\n",
      "swung 6.229654\n",
      "centr -4.050283\n",
      "least -15.235255\n",
      "piec 34.152798\n",
      "covidcbcca 9.591919\n",
      "sinai 15.828254\n",
      "direct -1.7521113\n",
      "introduc 19.7038\n",
      "distributor -21.228828\n",
      "foreign -5.485772\n",
      "food 2.229073\n",
      "surviv 30.724573\n",
      "chuck -6.7475853\n",
      "provis -10.015209\n",
      "transmiss -26.797262\n",
      "health 20.447643\n",
      "democraticcontrol -24.001017\n",
      "novel -2.789692\n",
      "hospit 21.681131\n",
      "prime -3.9378242\n",
      "patent -10.645904\n",
      "invinc -1.9859153\n",
      "heather -5.82365\n",
      "success 12.691189\n",
      "signific -6.309644\n",
      "pandemiccovid19 3.6164627\n",
      "schumer 34.168423\n",
      "metal 27.123547\n",
      "touch 18.728933\n",
      "underscor 8.796048\n",
      "known -32.88112\n",
      "sideeffect -5.6260023\n",
      "hrefhttpstcogpehoheem6pictwittercomgpehoheem6amdashicahnmountsinai -8.377054\n",
      "continu 3.2851818\n",
      "evict 28.703934\n",
      "look -13.939879\n",
      "longterm 0.16669647\n",
      "rush -12.778448\n",
      "guidelin 2.6124458\n",
      "develop -10.575764\n",
      "care 2.903183\n",
      "across -2.1147811\n",
      "defer -0.49456954\n",
      "vote 32.918488\n",
      "anywher 0.4651918\n",
      "880page -2.5608847\n",
      "day 23.556643\n",
      "mean -35.344666\n",
      "seattl 20.575691\n",
      "technolog -11.521113\n",
      "stream -17.302238\n",
      "offer 11.357911\n",
      "two -17.67875\n",
      "age 33.14762\n",
      "run 32.636024\n",
      "immun -14.33609\n",
      "sell 22.773413\n",
      "board 6.589963\n",
      "attend -8.9534855\n",
      "without 18.203278\n",
      "rep 22.762814\n",
      "passag -29.84073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "for word in words:\n",
    "    print(word, vectors[word2int[word]][1])\n",
    "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
