{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Fall Quarter : Natural Language Processing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective - Our model should convert any input string into a vector as accurately as possible. It will act as a pipeline for our further NLP analysis.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen Dataset - Covid-19 releated news is collected from various articles.  The dataset consists of the following columns: authors, title, publish_date, description, text and URL. We are mainly going to concentrate on the text column for our NLP analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our dataset as a dataframe using pandas \n",
    "df = pd.read_csv('news.csv', delimiter =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus a 'wake-up call' for Canada's pres...</td>\n",
       "      <td>2020-03-27 08:00:00</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>https://www.cbc.ca/news/health/covid-19-drug-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Yukon gov't names 2 possible sources of corona...</td>\n",
       "      <td>2020-03-27 01:45:00</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/north/yukon-cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Associated Press']</td>\n",
       "      <td>U.S. Senate passes $2T coronavirus relief package</td>\n",
       "      <td>2020-03-26 05:13:00</td>\n",
       "      <td>The Senate has passed an unparalleled $2.2 tri...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>https://www.cbc.ca/news/world/senate-coronavir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   authors  \\\n",
       "0           0              ['Cbc News']   \n",
       "1           1              ['Cbc News']   \n",
       "2           2  ['The Associated Press']   \n",
       "\n",
       "                                               title         publish_date  \\\n",
       "0  Coronavirus a 'wake-up call' for Canada's pres...  2020-03-27 08:00:00   \n",
       "1  Yukon gov't names 2 possible sources of corona...  2020-03-27 01:45:00   \n",
       "2  U.S. Senate passes $2T coronavirus relief package  2020-03-26 05:13:00   \n",
       "\n",
       "                                         description  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate has passed an unparalleled $2.2 tri...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.cbc.ca/news/health/covid-19-drug-s...  \n",
       "1  https://www.cbc.ca/news/canada/north/yukon-cor...  \n",
       "2  https://www.cbc.ca/news/world/senate-coronavir...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3566, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3566.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2455.649748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1298.529450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1473.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2496.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3569.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4608.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0\n",
       "count  3566.000000\n",
       "mean   2455.649748\n",
       "std    1298.529450\n",
       "min       0.000000\n",
       "25%    1473.250000\n",
       "50%    2496.500000\n",
       "75%    3569.750000\n",
       "max    4608.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns from the dataset\n",
    "df.drop([\"Unnamed: 0\",'publish_date','url','title','description'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['The Associated Press']</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    authors                                               text\n",
       "0              ['Cbc News']  Canadian pharmacies are limiting how much medi...\n",
       "1              ['Cbc News']  The Yukon government has identified two places...\n",
       "2  ['The Associated Press']  The Senate late Wednesday passed an unparallel...\n",
       "3              ['Cbc News']  Scientists around the world are racing to find...\n",
       "4              ['Cbc News']      Trudeau says rules of Quarantine Act will ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stripping the authors column from special characters \n",
    "\n",
    "df['authors'] = df['authors'].str.strip('[]')\n",
    "df['authors'] = df['authors'].str.strip('  ''')\n",
    "df['authors'] = df.authors.str.replace(\"[({':]\", \"\")\n",
    "df['authors'] = df['authors'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the associated press</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc news</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors                                               text\n",
       "0              cbc news  Canadian pharmacies are limiting how much medi...\n",
       "1              cbc news  The Yukon government has identified two places...\n",
       "2  the associated press  The Senate late Wednesday passed an unparallel...\n",
       "3              cbc news  Scientists around the world are racing to find...\n",
       "4              cbc news      Trudeau says rules of Quarantine Act will ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['authors'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Authors Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['authors'].replace(to_replace = [r'cbcs?\\b.*',r'.*\\bcbcs?', r'.*cbcnews.*'], value='cbc', regex=True, inplace=True)\n",
    "df['authors'].replace(to_replace = ['the associated press'], value='associated press', inplace=True)\n",
    "df['authors'].replace(to_replace = [r'canadian?\\b.*',r'.*\\bcanadian?'], value='canadian', regex=True, inplace=True)\n",
    "df['authors'].replace(to_replace = [r'freelancer?\\b.*',r'.*\\bfreelancer?'], value='freelancer', regex=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Basics: Implementing a pipeline to clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing text data\n",
    "\n",
    "Cleaning up the text data is necessary to highlight attributes. These would be loaded to machine learning system to pick up on. Cleaning (or pre-processing) the data typically consists of a number of steps:\n",
    "1. **Remove punctuation**\n",
    "2. **Tokenization**\n",
    "3. **Remove stopwords**\n",
    "4. **Lemmatize/Stem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                               text\n",
       "0               cbc  Canadian pharmacies are limiting how much medi...\n",
       "1               cbc  The Yukon government has identified two places...\n",
       "2  associated press  The Senate late Wednesday passed an unparallel...\n",
       "3               cbc  Scientists around the world are racing to find...\n",
       "4               cbc      Trudeau says rules of Quarantine Act will ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_clean'] = df['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                               text  \\\n",
       "0               cbc  Canadian pharmacies are limiting how much medi...   \n",
       "1               cbc  The Yukon government has identified two places...   \n",
       "2  associated press  The Senate late Wednesday passed an unparallel...   \n",
       "3               cbc  Scientists around the world are racing to find...   \n",
       "4               cbc      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  Canadian pharmacies are limiting how much medi...  \n",
       "1  The Yukon government has identified two places...  \n",
       "2  The Senate late Wednesday passed an unparallel...  \n",
       "3  Scientists around the world are racing to find...  \n",
       "4      Trudeau says rules of Quarantine Act will ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\\\W+', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_tokenized'] = df['body_text_clean'].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                               text  \\\n",
       "0               cbc  Canadian pharmacies are limiting how much medi...   \n",
       "1               cbc  The Yukon government has identified two places...   \n",
       "2  associated press  The Senate late Wednesday passed an unparallel...   \n",
       "3               cbc  Scientists around the world are racing to find...   \n",
       "4               cbc      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \n",
       "0  [canadian, pharmacies, are, limiting, how, muc...  \n",
       "1  [the, yukon, government, has, identified, two,...  \n",
       "2  [the, senate, late, wednesday, passed, an, unp...  \n",
       "3  [scientists, around, the, world, are, racing, ...  \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_nostop'] = df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplemental Data Cleaning: Using Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "ps = nltk.PorterStemmer()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_stemmed'] = df['body_text_nostop'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>associated press</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>The Senate late Wednesday passed an unparallel...</td>\n",
       "      <td>[the, senate, late, wednesday, passed, an, unp...</td>\n",
       "      <td>[senate, late, wednesday, passed, unparalleled...</td>\n",
       "      <td>[senat, late, wednesday, pass, unparallel, 22,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>Scientists around the world are racing to find...</td>\n",
       "      <td>[scientists, around, the, world, are, racing, ...</td>\n",
       "      <td>[scientists, around, world, racing, find, nove...</td>\n",
       "      <td>[scientist, around, world, race, find, novel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>Trudeau says rules of Quarantine Act will ...</td>\n",
       "      <td>[, trudeau, says, rules, of, quarantine, act, ...</td>\n",
       "      <td>[, trudeau, says, rules, quarantine, act, enfo...</td>\n",
       "      <td>[, trudeau, say, rule, quarantin, act, enforc,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            authors                                               text  \\\n",
       "0               cbc  Canadian pharmacies are limiting how much medi...   \n",
       "1               cbc  The Yukon government has identified two places...   \n",
       "2  associated press  The Senate late Wednesday passed an unparallel...   \n",
       "3               cbc  Scientists around the world are racing to find...   \n",
       "4               cbc      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "2  The Senate late Wednesday passed an unparallel...   \n",
       "3  Scientists around the world are racing to find...   \n",
       "4      Trudeau says rules of Quarantine Act will ...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "2  [the, senate, late, wednesday, passed, an, unp...   \n",
       "3  [scientists, around, the, world, are, racing, ...   \n",
       "4  [, trudeau, says, rules, of, quarantine, act, ...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "2  [senate, late, wednesday, passed, unparalleled...   \n",
       "3  [scientists, around, world, racing, find, nove...   \n",
       "4  [, trudeau, says, rules, quarantine, act, enfo...   \n",
       "\n",
       "                                   body_text_stemmed  \n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...  \n",
       "1  [yukon, govern, identifi, two, place, whitehor...  \n",
       "2  [senat, late, wednesday, pass, unparallel, 22,...  \n",
       "3  [scientist, around, world, race, find, novel, ...  \n",
       "4  [, trudeau, say, rule, quarantin, act, enforc,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplemental Data Cleaning: Using a Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "import nltk\n",
    "\n",
    "# https://wordnet.princeton.edu/|\n",
    "wn = nltk.WordNetLemmatizer()   \n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text_lemmatized'] = df['body_text_nostop'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "      <td>[canadian, pharmacy, limiting, much, medicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbc</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>The Yukon government has identified two places...</td>\n",
       "      <td>[the, yukon, government, has, identified, two,...</td>\n",
       "      <td>[yukon, government, identified, two, places, w...</td>\n",
       "      <td>[yukon, govern, identifi, two, place, whitehor...</td>\n",
       "      <td>[yukon, government, identified, two, place, wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authors                                               text  \\\n",
       "0     cbc  Canadian pharmacies are limiting how much medi...   \n",
       "1     cbc  The Yukon government has identified two places...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "1  The Yukon government has identified two places...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "1  [the, yukon, government, has, identified, two,...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "1  [yukon, government, identified, two, places, w...   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...   \n",
       "1  [yukon, govern, identifi, two, place, whitehor...   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [canadian, pharmacy, limiting, much, medicatio...  \n",
       "1  [yukon, government, identified, two, place, wh...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['body_text_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in first row i.e row 0: 242\n",
      "Total words in first row i.e row 1: 179\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words in first row i.e row 0:\",len(df['body_text_lemmatized'][0]))\n",
    "print(\"Total words in first row i.e row 1:\",len(df['body_text_lemmatized'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec using Infer Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>Canadian pharmacies are limiting how much medi...</td>\n",
       "      <td>[canadian, pharmacies, are, limiting, how, muc...</td>\n",
       "      <td>[canadian, pharmacies, limiting, much, medicat...</td>\n",
       "      <td>[canadian, pharmaci, limit, much, medic, dispe...</td>\n",
       "      <td>[canadian, pharmacy, limiting, much, medicatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authors                                               text  \\\n",
       "0     cbc  Canadian pharmacies are limiting how much medi...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  Canadian pharmacies are limiting how much medi...   \n",
       "\n",
       "                                 body_text_tokenized  \\\n",
       "0  [canadian, pharmacies, are, limiting, how, muc...   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [canadian, pharmacies, limiting, much, medicat...   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [canadian, pharmaci, limit, much, medic, dispe...   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [canadian, pharmacy, limiting, much, medicatio...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE The Lemmatized Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['body_text_lemmatized'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['canadian', 'pharmacy', 'limiting', 'much', 'medication', 'dispensed', 'try', 'prevent', 'shortage', 'recognizing', 'active', 'ingredient', 'drug', 'come', 'india', 'china', 'medical', 'supply', 'chain', 'disrupted', 'spread', 'covid19', 'provincial', 'regulatory', 'college', 'complying', 'canadian', 'pharmacist', 'association', 'call', 'limit', 'amount', 'medication', 'given', 'patient', '30day', 'supply', 'goal', 'stop', 'people', 'refilling', 'prescription', 'early', 'ensure', 'lifesaving', 'drug', 'dont', 'run', 'short', 'supply', 'chain', 'vulnerable', 'mina', 'tadrous', 'pharmacist', 'researcher', 'toronto', 'monitor', 'pharmaceutical', 'supply', 'worried', 'canadian', 'start', 'stockpiling', 'drug', 'watching', 'unfolding', 'u', 'region', 'virus', 'spread', 'said', 'pharmacist', 'concerned', 'drug', 'lifesaving', 'inhaler', 'people', 'might', 'stockpile', 'based', 'misinformation', 'circulating', 'potential', 'treatment', 'covid19', 'relationship', 'people', 'reacting', 'rather', 'actual', 'supply', 'medication', 'said', 'tadrous', 'said', 'pharmacy', 'get', 'medication', 'supply', 'wholesaler', 'get', 'distributor', 'source', 'manufacturer', 'outside', 'wholesaler', 'supply', 'chain', 'outside', 'canada', 'ongoing', 'shortage', 'dr', 'jacalyn', 'duffin', 'queen', 'university', 'kingston', 'ont', 'long', 'warned', 'increasing', 'frequency', 'drug', 'shortage', 'including', 'nearly', '2000', 'ongoing', 'shortage', 'none', 'attribute', 'coronavirus', 'china', 'india', 'produce', '80', 'per', 'cent', 'active', 'ingredient', 'prescription', 'drug', 'sold', 'north', 'america', 'said', 'dr', 'jacalyn', 'duffin', 'ka', 'roussycbc', 'given', 'china', 'india', 'produce', '80', 'per', 'cent', 'active', 'ingredient', 'prescription', 'drug', 'sold', 'north', 'america', 'supply', 'disruption', 'expected', 'eventually', 'duffin', 'said', 'think', 'coronavirus', 'outbreak', 'big', 'wakeup', 'call', 'u', 'pay', 'attention', 'drug', 'shortage', 'exist', 'already', 'pay', 'attention', 'drug', 'come', 'said', 'need', 'know', 'getting', 'new', 'prescription', 'refillsnew', 'brunswick', 'offer', 'relief', 'prescription', 'copays', 'outbreak', 'india', 'major', 'supplier', 'generic', 'drug', 'europe', 'already', 'shut', 'export', 'antibiotic', 'drug', 'hypertension', 'blood', 'pressure', 'acetaminophen', 'duffin', 'said', 'precaution', 'federal', 'government', 'enacted', 'sweeping', 'legislation', 'give', 'right', 'force', 'patented', 'drugmakers', 'make', 'medicine', 'necessary', 'remove', 'patent', 'part', 'response', 'public', 'health', 'emergency', ''], tags=[0]),\n",
       " TaggedDocument(words=['yukon', 'government', 'identified', 'two', 'place', 'whitehorse', 'church', 'dental', 'clinic', 'people', 'may', 'exposed', 'coronavirus', 'recent', 'week', 'news', 'release', 'thursday', 'evening', 'government', 'said', 'anybody', 'went', 'either', 'place', 'certain', 'day', 'monitor', 'symptom', 'may', 'indicate', 'covid19', 'fever', 'cough', 'difficulty', 'breathing', '14', 'day', 'call', '811', 'symptom', 'develop', 'possible', 'source', 'exposure', 'sunday', 'morning', 'service', 'bethany', 'church', 'alaska', 'highway', 'march', '8', 'march', '15', 'church', 'kid', 'zone', 'march', '8', 'elia', 'dental', 'clinic', 'march', '9', '13', 'march', '16', 'according', 'news', 'release', 'place', 'visited', 'date', 'person', 'person', 'tested', 'positive', 'covid19', 'also', 'say', 'people', 'attended', 'place', 'identified', 'time', 'need', 'selfisolate', 'long', 'remain', 'healthy', 'develop', 'symptom', 'risk', 'individual', 'possible', 'exposure', 'low', 'release', 'say', 'bethany', 'church', 'whitehorse', 'according', 'yukon', 'government', 'someone', 'later', 'tested', 'positive', 'covid19', 'attended', 'sunday', 'morning', 'service', 'church', 'mar', '8', '15', 'paul', 'tukkercbc', 'wednesday', 'yukon', 'three', 'confirmed', 'case', 'covid19', 'health', 'official', 'announced', 'first', 'two', 'case', 'sunday', 'saying', 'couple', 'whitehorse', 'third', 'person', 'community', 'disclosed', 'yukon', 'ban', 'residential', 'eviction', 'offer', 'paid', 'sick', 'leave', 'covid19', 'pandemiccovid19', 'testing', 'centre', 'running', 'whitehorse', 'person', 'people', 'attended', 'bethany', 'church', 'elia', 'dental', 'recovering', 'home', 'according', 'government', 'news', 'release', 'also', 'say', 'ongoing', 'risk', 'community', 'associated', 'either', 'church', 'dental', 'clinic'], tags=[1])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Approach For Tuning The Model\n",
    "\n",
    "* used FOR LOOP Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Take some sample data in the wordsExcel and pass the synonyms list to the String2Vec function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data \n",
    "\n",
    "data = [\"the quick brown fox\",\\\n",
    "        \"Corona is spreading\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrases = pd.read_excel('wordsExcel.xlsx')\n",
    "data = df_phrases['Synonyms_List']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Government, Administration, executive, regime,...\n",
       "1    Healthy, Hefty, alright, in good shape, salubr...\n",
       "2                  Family, menage, household, ancestry\n",
       "3    Symptoms, Manifestation, indication, indicator...\n",
       "4    Home, place, dwelling_house, menage, household...\n",
       "Name: Synonyms_List, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: User-defined Function : String2vec():\n",
    "\n",
    "    1. We use the Doc2vec Model in order to convert the sentences to a vector. \n",
    "    2. This function takes in excel data and computes the similiarity scores between the sentences\n",
    "    3. Display the hyperparamters of the best model, based on the highest score that String2Vec() function   \n",
    "       returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "\n",
    "def clean_cos(cos_angle):\n",
    "    return min(1,max(cos_angle,-1))\n",
    "\n",
    "def String2vec(data, new_model):\n",
    "    \n",
    "    print(\"\\n Started\") \n",
    "    model = new_model\n",
    "    \n",
    "    vectors = []\n",
    "    pair_list = []\n",
    "    cosine_degree = []\n",
    "    dot_product_score = []\n",
    "\n",
    "    #to find the vector of a document which is not in training data\n",
    "    for i in data:\n",
    "        test_data = word_tokenize(i.lower())\n",
    "        #print(\"Tokenized data:  \",test_data)\n",
    "        vec = model.infer_vector(test_data)  ### here we are using model and calling the test data(which is 50 excel words) \n",
    "        vectors.append(vec)\n",
    "    \n",
    "    for i in range(len(vectors)):\n",
    "        for j in range(len(vectors)):\n",
    "            import math\n",
    "            vec1 = vectors[i]\n",
    "            vec2 = vectors[j]\n",
    "            sim = (np.dot(vec1,vec2) / (np.linalg.norm(vec2) * np.linalg.norm(vec2)))\n",
    "            # # The dot product divided by the product magnitude of the two vectors\n",
    "            #print(\"Similarity of \\\"{}\\\" and \\\"{}\\\" is {}\" .format(data[i],data[j],sim))\n",
    "            dot_product_score.append(sim)\n",
    "            \n",
    "            pair = data[i],data[j]\n",
    "            pair_list.append(pair)\n",
    "            \n",
    "            cos_sim = clean_cos(sim)\n",
    "            angle_in_radians = math.acos(cos_sim)\n",
    "            #print(\"Degrees: \",math.degrees(angle_in_radians))\n",
    "            cosine_degree.append(math.degrees(angle_in_radians))\n",
    "\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(pd.DataFrame({'pair': pair_list, 'similarity_degrees': cosine_degree, 'dot_product_score': dot_product_score}))\n",
    "    \n",
    "    res = sum(map(lambda i : i * i, dot_product_score))\n",
    "    print(\"Sum of squares scores: \", res)\n",
    "    \n",
    "    return (res)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: FOR LOOP or Manual Approach For Model Building\n",
    "\n",
    "    * Consider Two hyperparameters vector_size, min_alpha and initiate different values.\n",
    "    * Create a model for each set of vector_size, min_alpha value and pass it to String2Vec() function. \n",
    "    * Identify the hyperparameters vector size and min_aplha of a model that has the highest score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for loop - one iteration of this loop is one iteration of GridSearch for parameter tuning\n",
    "# 4 * 4 values => 16 iterations . 0 to 15\n",
    "\n",
    "min_alpha = [0.50, 0.075, 0.1, 0.2]\n",
    "vector_size = [2,5,10,20]               # 50, 150, 250, 300\n",
    "\n",
    "#min_alpha = [0.1, 0.2]\n",
    "#vector_size = [10,20]\n",
    "\n",
    "max_square = 0\n",
    "Iteration_number = 0\n",
    "\n",
    "# Change variable names.\n",
    "for i in vector_size:\n",
    "    for j in min_alpha:\n",
    "        new_model = Doc2Vec(tagged_data, vector_size=i, min_alpha= j, window=2, min_count=4, workers=5, epochs =10)\n",
    "\n",
    "        print(\"\\n Iteration\", Iteration_number)\n",
    "        \n",
    "        sum_of_squares= String2vec(data, new_model)  # Function call\n",
    "        \n",
    "        print(\"********* Hyperparameter values, sum & Mean metrics for this model are ******** \")\n",
    "        print(\"Vector Size: \", i)\n",
    "        print(\"min_alpha: \", j)\n",
    "        print(\"Sum of Squares: \", sum_of_squares)\n",
    "        \n",
    "        Iteration_number = Iteration_number+1\n",
    "        \n",
    "        \n",
    "        #To find the best parameters for the most accurate model\n",
    "        if (sum_of_squares >= max_square):\n",
    "            max_square = sum_of_squares\n",
    "            vecsize = i\n",
    "            alpha_value = j\n",
    "            \n",
    "        print(\"##########  Next loop    ###############\")\n",
    "\n",
    "print(\"\\n All Iterations Completed\")            \n",
    "print(\"Best sum of squares : \",max_square)\n",
    "print(\"Best vec size: \",vecsize)\n",
    "print(\"Best Alpha value: \",alpha_value)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total : 16 Iterations.  All Iterations Completed\n",
    "    \n",
    "Best sum of squares :  265271.4051018052\n",
    "Best vec size:  10\n",
    "Best Alpha value:  0.5  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH METHOD FOR TUNING THE MODEL\n",
    "\n",
    "\n",
    "Reference Links:\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "    \n",
    "grid_search: Run a function iteratively using a grid search approach - R is available\n",
    "https://rdrr.io/cran/paramtest/man/grid_search.html\n",
    "\n",
    "https://stackoverflow.com/questions/38064637/pass-estimator-to-custom-score-function-via-sklearn-metrics-make-scorer\n",
    "\n",
    "Feed paramters to the scoring function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a separate function mb_gridsearch() to build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb_gridsearch():\n",
    "    print(\"\\n Entered the Function To  Build The Model for each of the Hyperparameters: \")\n",
    "    print(\"Vector size and alpha values has to be assigned\")\n",
    "    \n",
    "    model =  Doc2Vec(tagged_data, vector_size=vec_size, min_alpha=0.5 , window=2, min_count=4, workers=5, epochs =3)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = [2,5,10]\n",
    "\n",
    "# param_grid = dict(vector_size=[2,5,10])\n",
    "\n",
    "param_grid= { \"min_alpha\" : [0.50, 0.075, 0.1, 0.2],\n",
    "                      \"vector_size\" : [2,5,10,20] }, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Started\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-5c246645ccd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mString2vec_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# The model that is returned from estimator has to be considered in Sting2vec function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-61-c3bdea8b4e55>\u001b[0m in \u001b[0;36mString2vec_new\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(\"Tokenized data:  \",test_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m### here we are using model and calling the test data(which is 50 excel words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(\n",
    "        estimator= mb_gridsearch, # mb_gridsearch(param_grid)\n",
    "        param_grid = param_grid,\n",
    "        cv=5, \n",
    "        n_jobs=-1, \n",
    "        scoring=String2vec_new(data),  # The model that is returned from estimator has to be considered in Sting2vec function.\n",
    "        verbose=2\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Currently stuck at creating different models for each vector size and alpha values in grid search.\n",
    "\n",
    "* Each model that is built out of those hyperparametrs is used in String2Vec() function to convert the excel data or random data to vectors using infer vector method.\n",
    "\n",
    "* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def String2vec_new(data):\n",
    "   \n",
    "    print(\"\\n Started\") \n",
    "    \n",
    "    #model = \n",
    "    \n",
    "    vectors = []\n",
    "    pair_list = []\n",
    "    cosine_degree = []\n",
    "    dot_product_score = []\n",
    "\n",
    "    for i in data:\n",
    "        test_data = word_tokenize(i.lower())\n",
    "    \n",
    "        vec = model.infer_vector(test_data)  ### here we are using model and calling the test data(which is 50 excel words) \n",
    "        vectors.append(vec)\n",
    "    \n",
    "    for i in range(len(vectors)):\n",
    "        for j in range(len(vectors)):\n",
    "            import math\n",
    "            vec1 = vectors[i]\n",
    "            vec2 = vectors[j]\n",
    "            sim = (np.dot(vec1,vec2) / (np.linalg.norm(vec2) * np.linalg.norm(vec2)))\n",
    "            # # The dot product divided by the product magnitude of the two vectors\n",
    "            #print(\"Similarity of \\\"{}\\\" and \\\"{}\\\" is {}\" .format(data[i],data[j],sim))\n",
    "            dot_product_score.append(sim)\n",
    "            \n",
    "            pair = data[i],data[j]\n",
    "            pair_list.append(pair)\n",
    "            \n",
    "            cos_sim = clean_cos(sim)\n",
    "            angle_in_radians = math.acos(cos_sim)\n",
    "            #print(\"Degrees: \",math.degrees(angle_in_radians))\n",
    "            cosine_degree.append(math.degrees(angle_in_radians))\n",
    "\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(pd.DataFrame({'pair': pair_list, 'similarity_degrees': cosine_degree, 'dot_product_score': dot_product_score}))\n",
    "    \n",
    "    res = sum(map(lambda i : i * i, dot_product_score))\n",
    "    print(\"Sum of squares scores: \", res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Started\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-73db606ee355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                         param_grid= { \"min_alpha\" : [0.50, 0.075, 0.1, 0.2],\n\u001b[1;32m      3\u001b[0m                                       \"vector_size\" : [2,5,10,20] },\n\u001b[0;32m----> 4\u001b[0;31m                         \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mString2vec_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                         cv =5)\n",
      "\u001b[0;32m<ipython-input-61-c3bdea8b4e55>\u001b[0m in \u001b[0;36mString2vec_new\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(\"Tokenized data:  \",test_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m### here we are using model and calling the test data(which is 50 excel words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "log_grid = GridSearchCV(Doc2Vec(tagged_data),\n",
    "                        param_grid= { \"min_alpha\" : [0.50, 0.075, 0.1, 0.2],\n",
    "                                      \"vector_size\" : [2,5,10,20] },\n",
    "                        scoring=String2vec_new(data), \n",
    "                        cv =5)\n",
    "\n",
    "# How to pass the model to String2Vec_new function ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_grid.scoring  # Should display the sum of squares score :  265271.4051018052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_grid.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "print(\"Best Parameters: {}\\n\".format(log_grid.best_params_))\n",
    "print(\"Best accuracy: {}\\n\".format(log_grid.best_score_))\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
